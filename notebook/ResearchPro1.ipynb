{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c9f53c-5fc2-4eee-9000-3cfae300122e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "# Improving DB with Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445904a8-9cd7-48a0-ab9e-093cfb9bd1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FoundationalKnowledgeManager:\n",
    "    def __init__(self, vector_db, embedding_model):\n",
    "        self.vector_db = vector_db\n",
    "        self.embedding_model = embedding_model\n",
    "        self.github_sources = {\n",
    "            \"algorithms\": \"TheAlgorithms/Python\",\n",
    "            \"os\": \"tuhdo/os01\",\n",
    "            \"system_design\": \"donnemartin/system-design-primer\",\n",
    "            \"python\": \"jakevdp/PythonDataScienceHandbook\",\n",
    "            \"ml\": \"microsoft/ML-For-Beginners\",\n",
    "            \"database\": \"pingcap/awesome-database-learning\",\n",
    "            \"networks\": \"leandromoreira/linux-network-performance-parameters\"\n",
    "        }\n",
    "        \n",
    "    def load_from_github(self, topic_key):\n",
    "        \"\"\"Load content from predefined GitHub repositories with foundational CS knowledge\"\"\"\n",
    "        if topic_key not in self.github_sources:\n",
    "            return f\"Topic {topic_key} not found in available sources\"\n",
    "            \n",
    "        repo = self.github_sources[topic_key]\n",
    "        # Implement GitHub content fetching logic here\n",
    "        # Use GitHub API to get markdown/text content from README files and other docs\n",
    "        \n",
    "        # Process content and add to vector DB with metadata\n",
    "        # Important: Tag these documents as foundational knowledge\n",
    "        # self.vector_db.add_texts(texts, metadatas=[{\"chunk_type\": \"foundational\", \"topic\": topic_key}])\n",
    "        \n",
    "        return f\"Loaded foundational knowledge for {topic_key} from {repo}\"\n",
    "        \n",
    "    def load_from_file(self, file_path, topic_name):\n",
    "        \"\"\"Load content from local file\"\"\"\n",
    "        # Implement file loading logic\n",
    "        # Process content and add to vector DB with metadata \n",
    "        # self.vector_db.add_texts(texts, metadatas=[{\"chunk_type\": \"foundational\", \"topic\": topic_name}])\n",
    "        \n",
    "    def load_standard_cs_topics(self):\n",
    "        \"\"\"Load all standard CS topics\"\"\"\n",
    "        results = []\n",
    "        for topic in self.github_sources:\n",
    "            results.append(self.load_from_github(topic))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c0eec-dacb-4b49-81ad-dac04a9beac3",
   "metadata": {},
   "source": [
    "# Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b354f4-0b65-4e2e-8c7e-ad6f57c0271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file into os.environ\n",
    "load_dotenv()\n",
    "\n",
    "# Access them\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "project_name = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "endpoint = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f6906f-0a67-4bde-ac97-8d6e3cfeede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import necessary packages\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser, StrOutputParser\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "from typing import List, Literal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67465538-9a43-4952-9d20-79b8be8800d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/8m4t00412h97v592vh5y0pgc0000gn/T/ipykernel_34907/1083623630.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/var/folders/5n/8m4t00412h97v592vh5y0pgc0000gn/T/ipykernel_34907/1083623630.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory=DB_DIR, embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "PDF_DIR = \"../Database/arxiv_data\" \n",
    "DB_DIR =\"../Database/Vector-DB-New\"\n",
    "# Embedding & Vector DB\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = Chroma(persist_directory=DB_DIR, embedding_function=embedding_model)\n",
    "\n",
    "# Load embedding model once for scoring\n",
    "semantic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8b0a28-080f-4747-8d32-274b5cb6fbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Initializing SageRAG Research Assistant...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mInitializing SageRAG Research Assistant\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading embedding model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading embedding model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading language model <span style=\"font-weight: bold\">(</span>LLaMA-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span><span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading language model \u001b[1m(\u001b[0mLLaMA-\u001b[1;36m3.2\u001b[0m\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connecting to vector database at: ..<span style=\"color: #800080; text-decoration-color: #800080\">/Database/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Vector-DB-New...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connecting to vector database at: ..\u001b[35m/Database/\u001b[0m\u001b[95mVector-DB-New...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Initialization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mInitialization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 00:23:46,247 - SageRAG - INFO - Initializing default embedding model\n",
      "2025-11-06 00:23:50,077 - SageRAG - INFO - Research Assistant initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────────────── Welcome ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┃                                         <span style=\"font-weight: bold\">SageRAG Research Assistant</span>                                          ┃ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> Ask questions about scientific papers in the database.                                                          <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m Welcome \u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┃                                         \u001b[1mSageRAG Research Assistant\u001b[0m                                          ┃ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m Ask questions about scientific papers in the database.                                                          \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Options:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mOptions:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Ask a question <span style=\"font-weight: bold\">(</span>Human-in-the-Loop Mode<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m. Ask a question \u001b[1m(\u001b[0mHuman-in-the-Loop Mode\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. View conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m. View conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Clear conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m. Clear conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Go for Advanced Research <span style=\"font-weight: bold\">(</span>arXiv<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m. Go for Advanced Research \u001b[1m(\u001b[0marXiv\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m. Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-5):  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 00:23:52,980 - backoff - INFO - Backing off send_request(...) for 1.0s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Read timed out. (read timeout=15))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[bold]Enter your query:[/bold]  gpu vs cpu for training?\n",
      "Use conversation memory? (y/n):  n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, with a specific focus on comparing GPU vs CPU for training purposes. \n",
       "It contains relevant technical terms <span style=\"font-weight: bold\">(</span>GPU, CPU<span style=\"font-weight: bold\">)</span> and is focused on retrieving scientific content related to machine \n",
       "learning or deep learning. However, it lacks specificity regarding the type of training <span style=\"font-weight: bold\">(</span>e.g., neural networks, \n",
       "natural language processing<span style=\"font-weight: bold\">)</span>, which might limit its retrievability with vector search.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, with a specific focus on comparing GPU vs CPU for training purposes. \n",
       "It contains relevant technical terms \u001b[1m(\u001b[0mGPU, CPU\u001b[1m)\u001b[0m and is focused on retrieving scientific content related to machine \n",
       "learning or deep learning. However, it lacks specificity regarding the type of training \u001b[1m(\u001b[0me.g., neural networks, \n",
       "natural language processing\u001b[1m)\u001b[0m, which might limit its retrievability with vector search.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: gpu vs cpu for training?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: gpu vs cpu for training?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How do GPUs compare to CPUs in terms of memory </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">bandwidth, computational power, and energy consumption during neural network training? What are the implications </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for training speed and accuracy in machine learning models?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How do GPUs compare to CPUs in terms of memory \u001b[0m\n",
       "\u001b[32mbandwidth, computational power, and energy consumption during neural network training? What are the implications \u001b[0m\n",
       "\u001b[32mfor training speed and accuracy in machine learning models?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.68</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.68\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the differences in performance and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency between using Graphics Processing Units (GPUs) versus Central Processing Units (CPUs) for deep learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model training?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the differences in performance and \u001b[0m\n",
       "\u001b[32mefficiency between using Graphics Processing Units \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGPUs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m versus Central Processing Units \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCPUs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for deep learning \u001b[0m\n",
       "\u001b[32mmodel training?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.67</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.67\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of GPU acceleration versus </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">CPU-based training on the stability, convergence, and generalization capabilities of deep neural networks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including considerations for data partitioning and model parallelism.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of GPU acceleration versus \u001b[0m\n",
       "\u001b[32mCPU-based training on the stability, convergence, and generalization capabilities of deep neural networks, \u001b[0m\n",
       "\u001b[32mincluding considerations for data partitioning and model parallelism.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do the differences in memory access </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">patterns and computational efficiency between GPUs and CPUs influence the trade-off between model training speed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and accuracy in deep learning architectures?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do the differences in memory access \u001b[0m\n",
       "\u001b[32mpatterns and computational efficiency between GPUs and CPUs influence the trade-off between model training speed \u001b[0m\n",
       "\u001b[32mand accuracy in deep learning architectures?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.58</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.58\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between GPU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture (e.g., NVIDIA Tesla, AMD Radeon), CPU type (e.g., Intel Core i9, AMD Ryzen 9), and optimization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithms (e.g., mixed precision training, gradient checkpointing) on the convergence of training objectives and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model performance metrics in deep learning models.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between GPU \u001b[0m\n",
       "\u001b[32marchitecture \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., NVIDIA Tesla, AMD Radeon\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, CPU type \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Intel Core i9, AMD Ryzen 9\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and optimization \u001b[0m\n",
       "\u001b[32malgorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., mixed precision training, gradient checkpointing\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the convergence of training objectives and \u001b[0m\n",
       "\u001b[32mmodel performance metrics in deep learning models.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.51</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.51\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app.py\n",
    "# --- This file is your \"demo\" ---\n",
    "from langsmith import traceable\n",
    "# import os\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "from sagerag import ResearchAssistant, OllamaLLM, Chroma, HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, BaseOutputParser\n",
    "from langchain.schema import Document, HumanMessage, AIMessage\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# from langchain.llms.base import BaseLLM\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pydantic import BaseModel, Field\n",
    "import logging\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# Initialize Rich Console\n",
    "console = Console()\n",
    "\n",
    "# Define your database path\n",
    "DB_DIR = \"../Database/Vector-DB-New\" # or \"./Database/Vector-DB-New\" depending on your folder\n",
    "\n",
    "def main(): \n",
    "    \"\"\"Main function to run the research assistant.\"\"\"\n",
    "    try:\n",
    "        # --- This block is your setup ---\n",
    "        console.print(\"[bold cyan]Initializing SageRAG Research Assistant...[/bold cyan]\")\n",
    "        \n",
    "        console.print(\"Loading embedding model...\")\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        console.print(\"Loading language model (LLaMA-3.2)...\")\n",
    "        llm = OllamaLLM(model=\"llama3.2\", temperature=0.2)\n",
    "        \n",
    "        console.print(f\"Connecting to vector database at: {DB_DIR}...\")\n",
    "        vector_db = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)\n",
    "        \n",
    "        console.print(\"[bold green]Initialization complete![/bold green]\")\n",
    "        \n",
    "        # Initialize the research assistant\n",
    "        assistant = ResearchAssistant(llm=llm, vector_db=vector_db)\n",
    "        \n",
    "        console.print(Panel.fit(\n",
    "            Markdown(\"# SageRAG Research Assistant\\n\\nAsk questions about scientific papers in the database.\"),\n",
    "            title=\"Welcome\",\n",
    "            border_style=\"cyan\"\n",
    "        ))\n",
    "        \n",
    "        # --- Main interaction loop ---\n",
    "        while True:\n",
    "            console.print(\"\\n[bold cyan]Options:[/bold cyan]\")\n",
    "            console.print(\"1. Ask a question (Human-in-the-Loop Mode)\")\n",
    "            console.print(\"2. View conversation history\")\n",
    "            console.print(\"3. Clear conversation history\")\n",
    "            console.print(\"4. Go for Advanced Research (arXiv)\")\n",
    "            console.print(\"5. Exit\")\n",
    "            \n",
    "            choice = input(\"\\nEnter your choice (1-5): \").strip()\n",
    "            \n",
    "            if choice == \"1\":\n",
    "                query = input(f\"\\n[bold]Enter your query:[/bold] \")\n",
    "                if not query.strip():\n",
    "                    console.print(f\"[yellow]Empty query. Please try again.[/yellow]\")\n",
    "                    continue\n",
    "                \n",
    "                # Ask the user whether to use memory mode\n",
    "                use_memory_input = input(\"Use conversation memory? (y/n): \").lower()\n",
    "                use_memory = use_memory_input.startswith('y')\n",
    "                \n",
    "                # Process the query\n",
    "                console.print(f\"\\n[bold cyan]Processing your query...[/bold cyan]\")\n",
    "                # This method is your System D pipeline\n",
    "                answer = assistant.process_query(query, use_memory=use_memory)\n",
    "                \n",
    "                # Display the final answer\n",
    "                console.print(Panel(\n",
    "                    Markdown(answer),\n",
    "                    title=\"Answer\",\n",
    "                    border_style=\"green\",\n",
    "                    width=100\n",
    "                ))\n",
    "            \n",
    "            elif choice == \"2\":\n",
    "                history = assistant.get_chat_history()\n",
    "                console.print(Panel(\n",
    "                    history if history else \"No conversation history.\",\n",
    "                    title=\"Conversation History\",\n",
    "                    border_style=\"blue\"\n",
    "                ))\n",
    "                \n",
    "            elif choice == \"3\":\n",
    "                assistant.clear_memory()\n",
    "                console.print(\"[bold green]Conversation memory cleared.[/bold green]\")\n",
    "\n",
    "            elif choice == \"4\":\n",
    "                # (This is your advanced arXiv research flow)\n",
    "                query = input(f\"\\n[bold]Enter your arXiv query:[/bold] \")\n",
    "                if not query.strip():\n",
    "                    console.print(f\"[yellow]Empty query. Please try again.[/yellow]\")\n",
    "                    continue\n",
    "                \n",
    "                # Create a temporary assistant for the new arXiv DB\n",
    "                console.print(\"Initializing temporary vector database for arXiv...\")\n",
    "                vector_db_temp = Chroma(persist_directory=\"./tempDB\", embedding_function=embeddings)\n",
    "                advAssistant = ResearchAssistant(llm=llm, vector_db=vector_db_temp)\n",
    "                \n",
    "                # This workflow is also your System D (Human-in-the-Loop) pipeline\n",
    "                selected_query = advAssistant.search_with_query_feedback(query) # Simplified this flow\n",
    "                \n",
    "                console.print(f\"\\n[bold cyan]Loading papers for query: '{selected_query}'...[/bold cyan]\")\n",
    "                paper_ids = advAssistant.Load_query(selected_query)\n",
    "                \n",
    "                if paper_ids:\n",
    "                    while True:\n",
    "                        research_question = input(\"\\n[bold]Ask a question about these papers (or type 'exit' to return):[/bold] \")\n",
    "                        if research_question.lower() in ['exit', 'quit', 'back']:\n",
    "                            break\n",
    "                        # ... (rest of your loop logic) ...\n",
    "                        answer = advAssistant.process_query(research_question, use_memory=True)\n",
    "                        console.print(Panel(Markdown(answer), title=\"Answer\", border_style=\"green\", width=100))\n",
    "                else:\n",
    "                    console.print(\"[yellow]No papers were loaded. Please try a different query.[/yellow]\")\n",
    "            \n",
    "            elif choice == \"5\":\n",
    "                console.print(\"[bold green]Thank you for using SageRAG. Goodbye![/bold green]\")\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                console.print(\"[yellow]Invalid choice. Please enter a number from 1-5.[/yellow]\")\n",
    "                \n",
    "    except ImportError as e:\n",
    "        console.print(f\"[bold red]Error: Missing required packages: {e}[/bold red]\")\n",
    "        console.print(\"Please install the required packages: pip install -r requirements.txt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]An unexpected error occurred: {e}[/bold red]\")\n",
    "        import traceback\n",
    "        console.print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159752bc-c497-4436-87d5-9e735a2da17b",
   "metadata": {},
   "source": [
    "# tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1147e1-8f56-4252-9548-e110c0bd7a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Initializing SageRAG Research Assistant...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mInitializing SageRAG Research Assistant\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading embedding model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading embedding model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading language model <span style=\"font-weight: bold\">(</span>LLaMA-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span><span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading language model \u001b[1m(\u001b[0mLLaMA-\u001b[1;36m3.2\u001b[0m\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connecting to vector database at: ..<span style=\"color: #800080; text-decoration-color: #800080\">/Database/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Vector-DB-New...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connecting to vector database at: ..\u001b[35m/Database/\u001b[0m\u001b[95mVector-DB-New...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Initialization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mInitialization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 05:24:42,037 - SageRAG - INFO - Initializing default embedding model\n",
      "/Users/aditi/ResearchPro/SageRAG/notebook/tracing.py:119: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferMemory(\n",
      "2025-11-06 05:24:46,352 - SageRAG - INFO - Research Assistant initialized successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────────────── Welcome ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┃                                         <span style=\"font-weight: bold\">SageRAG Research Assistant</span>                                          ┃ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> Ask questions about scientific papers in the database.                                                          <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m Welcome \u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┃                                         \u001b[1mSageRAG Research Assistant\u001b[0m                                          ┃ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m Ask questions about scientific papers in the database.                                                          \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, using specific technical terms <span style=\"color: #008000; text-decoration-color: #008000\">'GPU'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'CPU'</span>, which indicates a good\n",
       "understanding of the context. However, it lacks specificity regarding the type of training <span style=\"font-weight: bold\">(</span>e.g., deep learning, \n",
       "machine learning<span style=\"font-weight: bold\">)</span> and the desired outcome <span style=\"font-weight: bold\">(</span>e.g., accuracy, speed<span style=\"font-weight: bold\">)</span>, which could lead to less relevant results. The \n",
       "query is also focused on retrieving scientific content, making it relevant for a research database.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, using specific technical terms \u001b[32m'GPU'\u001b[0m and \u001b[32m'CPU'\u001b[0m, which indicates a good\n",
       "understanding of the context. However, it lacks specificity regarding the type of training \u001b[1m(\u001b[0me.g., deep learning, \n",
       "machine learning\u001b[1m)\u001b[0m and the desired outcome \u001b[1m(\u001b[0me.g., accuracy, speed\u001b[1m)\u001b[0m, which could lead to less relevant results. The \n",
       "query is also focused on retrieving scientific content, making it relevant for a research database.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: gpu vs cpu what to use for training?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: gpu vs cpu what to use for training?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the advantages and disadvantages of using</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPUs versus CPUs for deep learning model training in terms of computational efficiency, memory usage, and energy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consumption?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the advantages and disadvantages of using\u001b[0m\n",
       "\u001b[32mGPUs versus CPUs for deep learning model training in terms of computational efficiency, memory usage, and energy \u001b[0m\n",
       "\u001b[32mconsumption?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.64</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.64\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do the differences between GPU and CPU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architectures influence the trade-off between model training speed, memory usage, and energy efficiency in deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning applications? How can these trade-offs be optimized for specific use cases?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do the differences between GPU and CPU \u001b[0m\n",
       "\u001b[32marchitectures influence the trade-off between model training speed, memory usage, and energy efficiency in deep \u001b[0m\n",
       "\u001b[32mlearning applications? How can these trade-offs be optimized for specific use cases?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.63</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.63\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How do the performance characteristics of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPU-accelerated versus CPU-based neural network training differ in terms of training time, model accuracy, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory requirements? What are the implications for large-scale deep learning applications?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How do the performance characteristics of \u001b[0m\n",
       "\u001b[32mGPU-accelerated versus CPU-based neural network training differ in terms of training time, model accuracy, and \u001b[0m\n",
       "\u001b[32mmemory requirements? What are the implications for large-scale deep learning applications?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between the choice of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPU versus CPU for neural network training, the type of optimization algorithm used (e.g., Adam, SGD), and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture of the model (e.g., convolutional neural networks, recurrent neural networks) on the convergence of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training objectives and model performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between the choice of\u001b[0m\n",
       "\u001b[32mGPU versus CPU for neural network training, the type of optimization algorithm used \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and the \u001b[0m\n",
       "\u001b[32marchitecture of the model \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., convolutional neural networks, recurrent neural networks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the convergence of \u001b[0m\n",
       "\u001b[32mtraining objectives and model performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.54</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.54\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of using GPUs versus CPUs on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convergence rates, optimization algorithms (e.g., Adam, SGD), and regularization techniques used in deep learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models, particularly in the context of batch normalization and data augmentation.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of using GPUs versus CPUs on the \u001b[0m\n",
       "\u001b[32mconvergence rates, optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and regularization techniques used in deep learning \u001b[0m\n",
       "\u001b[32mmodels, particularly in the context of batch normalization and data augmentation.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.45</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.45\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the advantages and disadvantages of using GPUs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">versus CPUs for deep learning model training in terms of computational efficiency, memory usage, and energy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consumption?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the advantages and disadvantages of using GPUs \u001b[0m\n",
       "\u001b[32mversus CPUs for deep learning model training in terms of computational efficiency, memory usage, and energy \u001b[0m\n",
       "\u001b[32mconsumption?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4620</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4620\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and retrains the whole network, while the accuracy is not com promised. Accelerator computes     │\n",
       "│ convolutions or multi-                                                                           │\n",
       "│ channel operations in parallel or ...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and retrains the whole network, while the accuracy is not com promised. Accelerator computes     │\n",
       "│ convolutions or multi-                                                                           │\n",
       "│ channel operations in parallel or ...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1907.02217v1_FusionAccel:_A_General_Re-configurable_Deep_Learni</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1907.02217v1_FusionAccel:_A_General_Re-configurable_Deep_Learni\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4416</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4416\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ [9] Chao-Tung Yang, Chih-Lin Huang, and Cheng-Fang Lin. Hybrid                                   │\n",
       "│ cuda, openmp, and mpi parallel programming on multicore gpu                                      │\n",
       "│ clusters. Computer Physics ...                                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ [9] Chao-Tung Yang, Chih-Lin Huang, and Cheng-Fang Lin. Hybrid                                   │\n",
       "│ cuda, openmp, and mpi parallel programming on multicore gpu                                      │\n",
       "│ clusters. Computer Physics ...                                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4403</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4403\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ reconsider its plans to let European companies participate in the advancement of AI.             │\n",
       "│ 6 ENVIRONMENTAL IMPACT                                                                           │\n",
       "│ While machine learning algorithms are not ...                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ reconsider its plans to let European companies participate in the advancement of AI.             │\n",
       "│ 6 ENVIRONMENTAL IMPACT                                                                           │\n",
       "│ While machine learning algorithms are not ...                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2311.17228v1_Survey_on_AI_Ethics:_A_Socio-technical_Perspective</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2311.17228v1_Survey_on_AI_Ethics:_A_Socio-technical_Perspective\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4273</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4273\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ increasing power of GPUs in passing gradients through deep NNs.                                  │\n",
       "│ In fact, one lingering disadvantage in NE compared to the rest                                   │\n",
       "│ of deep learning has be...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ increasing power of GPUs in passing gradients through deep NNs.                                  │\n",
       "│ In fact, one lingering disadvantage in NE compared to the rest                                   │\n",
       "│ of deep learning has be...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1712.06563v3_Safe_Mutations_for_Deep_and_Recurrent_Neural_Netwo</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1712.06563v3_Safe_Mutations_for_Deep_and_Recurrent_Neural_Netwo\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4234</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4234\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ recent FPGA-based accelerator designs for the ResNet-50 [7], [18]                                │\n",
       "│ and BERT [3] (or RoBERTa [19] same architecture with BERT).                                      │\n",
       "│ For the GNN, we can only...                                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ recent FPGA-based accelerator designs for the ResNet-50 [7], [18]                                │\n",
       "│ and BERT [3] (or RoBERTa [19] same architecture with BERT).                                      │\n",
       "│ For the GNN, we can only...                                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2402.00395v1_ONE-SA:_Enabling_Nonlinear_Operations_in_Systolic_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2402.00395v1_ONE-SA:_Enabling_Nonlinear_Operations_in_Systolic_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> When it comes to training machine learning models, the choice between using a GPU (Graphics      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Processing Unit) or a CPU (Central Processing Unit) depends on several factors. According to     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Document 1, GPUs are one type of general deep learning accelerators that can be used for         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> accelerated computation, reducing memory access times and elapsed time in inference [Document    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 1]. However, this does not necessarily mean that GPUs are always better than CPUs for training.  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In fact, Document 3 highlights the environmental impact of using GPUs for machine learning,      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> particularly in terms of energy consumption and carbon emissions [Document 3]. This is because   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> machine learning algorithms, especially deep learning models, require extensive computational    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> resources for training, which can lead to high energy consumption [Patterson et al. (2021);      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Schwartz et al. (2020); Zhong et al. (2023)].                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> On the other hand, Document 4 suggests that GPUs have a disadvantage in reinforcement learning   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> compared to explicit gradient information, which can be capitalized on when available [Document  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 4]. However, this does not necessarily mean that CPUs are better for training machine learning   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> models.                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In terms of performance, Document 5 presents recent FPGA-based accelerator designs for the       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ResNet-50 and BERT models, which achieve significant improvements in computation efficiency      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> compared to general-purpose processors and GPUs [Document 5]. This suggests that specialized     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> accelerators like FPGAs or ASICs may be more efficient than GPUs for certain types of machine    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning workloads.                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The choice between using a GPU or a CPU for training machine learning models depends on various  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> factors, including the specific requirements of the model, the available computational           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> resources, and the environmental impact of energy consumption. While GPUs are often preferred    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for their acceleration capabilities, they do come with environmental costs. In contrast, CPUs    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> may be more suitable for certain types of machine learning workloads that require explicit       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> gradient information.                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> It's also worth noting that the field of machine learning is rapidly evolving, and new           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> technologies like FPGAs and ASICs are being developed to improve computation efficiency and      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> reduce energy consumption. As such, the choice between using a GPU or a CPU may depend on the    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> specific use case and the availability of specialized accelerators.                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1907.02217v1_FusionAccel:_A_General_Re-configurable_Deep_Learni         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2311.17228v1_Survey_on_AI_Ethics:_A_Socio-technical_Perspective         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1712.06563v3_Safe_Mutations_for_Deep_and_Recurrent_Neural_Netwo         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2402.00395v1_ONE-SA:<span style=\"font-style: italic\">Enabling_Nonlinear_Operations_in_Systolic</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m When it comes to training machine learning models, the choice between using a GPU (Graphics      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Processing Unit) or a CPU (Central Processing Unit) depends on several factors. According to     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Document 1, GPUs are one type of general deep learning accelerators that can be used for         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m accelerated computation, reducing memory access times and elapsed time in inference [Document    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 1]. However, this does not necessarily mean that GPUs are always better than CPUs for training.  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In fact, Document 3 highlights the environmental impact of using GPUs for machine learning,      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m particularly in terms of energy consumption and carbon emissions [Document 3]. This is because   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m machine learning algorithms, especially deep learning models, require extensive computational    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m resources for training, which can lead to high energy consumption [Patterson et al. (2021);      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Schwartz et al. (2020); Zhong et al. (2023)].                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m On the other hand, Document 4 suggests that GPUs have a disadvantage in reinforcement learning   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m compared to explicit gradient information, which can be capitalized on when available [Document  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 4]. However, this does not necessarily mean that CPUs are better for training machine learning   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m models.                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In terms of performance, Document 5 presents recent FPGA-based accelerator designs for the       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m ResNet-50 and BERT models, which achieve significant improvements in computation efficiency      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m compared to general-purpose processors and GPUs [Document 5]. This suggests that specialized     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m accelerators like FPGAs or ASICs may be more efficient than GPUs for certain types of machine    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning workloads.                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The choice between using a GPU or a CPU for training machine learning models depends on various  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m factors, including the specific requirements of the model, the available computational           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m resources, and the environmental impact of energy consumption. While GPUs are often preferred    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for their acceleration capabilities, they do come with environmental costs. In contrast, CPUs    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m may be more suitable for certain types of machine learning workloads that require explicit       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m gradient information.                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m It's also worth noting that the field of machine learning is rapidly evolving, and new           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m technologies like FPGAs and ASICs are being developed to improve computation efficiency and      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m reduce energy consumption. As such, the choice between using a GPU or a CPU may depend on the    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m specific use case and the availability of specialized accelerators.                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1907.02217v1_FusionAccel:_A_General_Re-configurable_Deep_Learni         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2311.17228v1_Survey_on_AI_Ethics:_A_Socio-technical_Perspective         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1712.06563v3_Safe_Mutations_for_Deep_and_Recurrent_Neural_Netwo         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2402.00395v1_ONE-SA:\u001b[3mEnabling_Nonlinear_Operations_in_Systolic\u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query <span style=\"color: #008000; text-decoration-color: #008000\">'What attention mechanism do?'</span> is rated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> due to its clarity and relevance. \n",
       "However, it lacks specificity, as the term <span style=\"color: #008000; text-decoration-color: #008000\">'attention'</span> can refer to multiple concepts in NLP and AI. Adding more \n",
       "context or specifying a particular type of attention mechanism <span style=\"font-weight: bold\">(</span>e.g., self-attention, multi-head attention<span style=\"font-weight: bold\">)</span> would \n",
       "improve the query's effectiveness.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query \u001b[32m'What attention mechanism do?'\u001b[0m is rated \u001b[1;36m4\u001b[0m out of \u001b[1;36m5\u001b[0m due to its clarity and relevance. \n",
       "However, it lacks specificity, as the term \u001b[32m'attention'\u001b[0m can refer to multiple concepts in NLP and AI. Adding more \n",
       "context or specifying a particular type of attention mechanism \u001b[1m(\u001b[0me.g., self-attention, multi-head attention\u001b[1m)\u001b[0m would \n",
       "improve the query's effectiveness.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What attention mechanism do?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What attention mechanism do?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanism design (e.g., spatial attention, channel attention), neural network architecture, and optimization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithms (e.g., Adam, SGD) on the convergence of training objectives and model performance metrics in computer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vision applications.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between attention \u001b[0m\n",
       "\u001b[32mmechanism design \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., spatial attention, channel attention\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, neural network architecture, and optimization \u001b[0m\n",
       "\u001b[32malgorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the convergence of training objectives and model performance metrics in computer \u001b[0m\n",
       "\u001b[32mvision applications.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.60</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.60\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the choice of attention mechanism influence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the design of recurrent neural networks? What impact does it have on the training time and accuracy of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sequence-to-sequence models?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the choice of attention mechanism influence \u001b[0m\n",
       "\u001b[32mthe design of recurrent neural networks? What impact does it have on the training time and accuracy of \u001b[0m\n",
       "\u001b[32msequence-to-sequence models?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.55</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.55\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do different attention mechanisms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., additive, multiplicative) affect the trade-off between model interpretability and computational efficiency </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in natural language processing tasks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do different attention mechanisms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., additive, multiplicative\u001b[0m\u001b[32m)\u001b[0m\u001b[32m affect the trade-off between model interpretability and computational efficiency \u001b[0m\n",
       "\u001b[32min natural language processing tasks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.54</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.54\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Adding technical terminology for specificity:** <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the effects of different attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanisms (e.g., self-attention, multi-head attention) on model performance and interpretability in deep learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neural networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Adding technical terminology for specificity:** \u001b[32m\"What are the effects of different attention \u001b[0m\n",
       "\u001b[32mmechanisms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., self-attention, multi-head attention\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on model performance and interpretability in deep learning \u001b[0m\n",
       "\u001b[32mneural networks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.52</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.52\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of attention mechanisms, batch </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">normalization, and activation functions on the generalization capabilities and robustness of deep neural networks.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of attention mechanisms, batch \u001b[0m\n",
       "\u001b[32mnormalization, and activation functions on the generalization capabilities and robustness of deep neural networks.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.49</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.49\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity:** \"What are the effects of different attention mechanisms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., self-attention, multi-head attention) on model performance and interpretability in deep learning neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity:** \"What are the effects of different attention mechanisms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., self-attention, multi-head attention\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on model performance and interpretability in deep learning neural \u001b[0m\n",
       "\u001b[32mnetworks?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3360</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3360\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Modern machine learning encoder-decoder architectures can achieve strong performance on          │\n",
       "│ sequence-                                                                                        │\n",
       "│ to-sequence tasks such as machine translation (Bahda...                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Modern machine learning encoder-decoder architectures can achieve strong performance on          │\n",
       "│ sequence-                                                                                        │\n",
       "│ to-sequence tasks such as machine translation (Bahda...                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2110.15253v1_Understanding_How_Encoder-Decoder_Architectures_At</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2110.15253v1_Understanding_How_Encoder-Decoder_Architectures_At\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3272</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3272\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 4443–4458. Association for   │\n",
       "│ Computational                                                                                    │\n",
       "│ Linguistics, 2020.                                                                               │\n",
       "│ [46] Ronny Luss, Pin-Y...                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 4443–4458. Association for   │\n",
       "│ Computational                                                                                    │\n",
       "│ Linguistics, 2020.                                                                               │\n",
       "│ [46] Ronny Luss, Pin-Y...                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2212.03513v1_Truthful_Meta-Explanations_for_Local_Interpretabil</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2212.03513v1_Truthful_Meta-Explanations_for_Local_Interpretabil\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3177</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3177\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald                                                 │\n",
       "│ Metzler. 2020. Efﬁcient transformers: A survey.                                                  │\n",
       "│ arXiv preprint arXiv:2009.06732.                                                                 │\n",
       "│ Ashish Vaswani, Noam...                                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald                                                 │\n",
       "│ Metzler. 2020. Efﬁcient transformers: A survey.                                                  │\n",
       "│ arXiv preprint arXiv:2009.06732.                                                                 │\n",
       "│ Ashish Vaswani, Noam...                                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3134</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3134\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of the architectures. In addition, to compare with previous                                      │\n",
       "│ work [5, 1] in the same setting for which these methods                                          │\n",
       "│ were conceived, we also consider V...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of the architectures. In addition, to compare with previous                                      │\n",
       "│ work [5, 1] in the same setting for which these methods                                          │\n",
       "│ were conceived, we also consider V...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2103.15679v1_Generic_Attention-model_Explainability_for_Interpr</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2103.15679v1_Generic_Attention-model_Explainability_for_Interpr\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3120</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3120\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ wider as we progress through deeper layers. This reveals that                                    │\n",
       "│ learned features are mainly locally dependent, even though self-                                 │\n",
       "│ attention is able to mo...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ wider as we progress through deeper layers. This reveals that                                    │\n",
       "│ learned features are mainly locally dependent, even though self-                                 │\n",
       "│ attention is able to mo...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The attention mechanism used in modern machine learning encoder-decoder architectures, such as   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> those mentioned in the provided research papers, is primarily based on self-attention. This      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mechanism allows the network to focus on a specific part of the input most relevant to the       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> current prediction step (Source: Document 1). Self-attention has proven to be a critical         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mechanism for achieving strong performance on sequence-to-sequence tasks and other applications  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> (Source: Document 1).                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, despite its success, an understanding of how these networks solve such tasks using      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> attention remains largely unknown. Research has shown that self-attention can learn long-range   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> dependencies, but in practice, it often focuses on short-term dependencies rather than capturing <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> longer-term dependencies (Source: Document 5). This is evident from the fact that learned        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> features are mainly locally dependent, even though self-attention is able to model long-term     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> dependencies over the full sequence (Source: Document 5).                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Additionally, some architectures, such as VisualBERT and LXMERT, combine self-attention with     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> co-attention in a Transformer encoder for two modalities. These models use relevancy propagation <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> to evaluate the quality of their explanations (Source: Document 4). The perturbation tests       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> performed on these models reveal that they are able to capture connections between input         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> modalities and demonstrate an understanding of both modalities (Source: Document 4).             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The attention mechanism has become a crucial component in modern machine learning architectures, <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> particularly in sequence-to-sequence tasks. Its ability to focus on specific parts of the input  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> data makes it an attractive mechanism for achieving strong performance. However, its             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> limitations, such as focusing on short-term dependencies rather than capturing longer-term       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> dependencies, highlight the need for further research and understanding.                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Furthermore, the use of attention mechanisms in combination with other components, such as       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> co-attention, has shown promise in certain applications. The development of more interpretable   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and explainable attention mechanisms is an active area of research, with studies exploring       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> methods such as faithfulness violation tests (Source: Document 2) and leveraging latent features <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for local explanations (Source: Document 2).                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2110.15253v1_Understanding_How_Encoder-Decoder_Architectures_At         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2212.03513v1_Truthful_Meta-Explanations_for_Local_Interpretabil         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The attention mechanism used in modern machine learning encoder-decoder architectures, such as   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m those mentioned in the provided research papers, is primarily based on self-attention. This      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mechanism allows the network to focus on a specific part of the input most relevant to the       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m current prediction step (Source: Document 1). Self-attention has proven to be a critical         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mechanism for achieving strong performance on sequence-to-sequence tasks and other applications  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m (Source: Document 1).                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, despite its success, an understanding of how these networks solve such tasks using      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m attention remains largely unknown. Research has shown that self-attention can learn long-range   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m dependencies, but in practice, it often focuses on short-term dependencies rather than capturing \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m longer-term dependencies (Source: Document 5). This is evident from the fact that learned        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m features are mainly locally dependent, even though self-attention is able to model long-term     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m dependencies over the full sequence (Source: Document 5).                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Additionally, some architectures, such as VisualBERT and LXMERT, combine self-attention with     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m co-attention in a Transformer encoder for two modalities. These models use relevancy propagation \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m to evaluate the quality of their explanations (Source: Document 4). The perturbation tests       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m performed on these models reveal that they are able to capture connections between input         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m modalities and demonstrate an understanding of both modalities (Source: Document 4).             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The attention mechanism has become a crucial component in modern machine learning architectures, \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m particularly in sequence-to-sequence tasks. Its ability to focus on specific parts of the input  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m data makes it an attractive mechanism for achieving strong performance. However, its             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m limitations, such as focusing on short-term dependencies rather than capturing longer-term       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m dependencies, highlight the need for further research and understanding.                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Furthermore, the use of attention mechanisms in combination with other components, such as       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m co-attention, has shown promise in certain applications. The development of more interpretable   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and explainable attention mechanisms is an active area of research, with studies exploring       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m methods such as faithfulness violation tests (Source: Document 2) and leveraging latent features \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for local explanations (Source: Document 2).                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2110.15253v1_Understanding_How_Encoder-Decoder_Architectures_At         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2212.03513v1_Truthful_Meta-Explanations_for_Local_Interpretabil         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It could be effective for retrieving general \n",
       "information about dropout layers in machine learning or neural networks. However, it may not yield precise results \n",
       "due to its vagueness. To improve retrievability with vector search, the query could be modified to include more \n",
       "specific technical terms or concepts.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It could be effective for retrieving general \n",
       "information about dropout layers in machine learning or neural networks. However, it may not yield precise results \n",
       "due to its vagueness. To improve retrievability with vector search, the query could be modified to include more \n",
       "specific technical terms or concepts.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What dropout layer for?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What dropout layer for?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the applications and use cases for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dropout layers in deep learning neural networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the applications and use cases for \u001b[0m\n",
       "\u001b[32mdropout layers in deep learning neural networks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.66</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.66\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between dropout layer</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">configuration (e.g., dropout rate, number of layers), neural network architecture, and optimization algorithms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., Adam, SGD) on the convergence of training objectives and model performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between dropout layer\u001b[0m\n",
       "\u001b[32mconfiguration \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., dropout rate, number of layers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, neural network architecture, and optimization algorithms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the convergence of training objectives and model performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.53</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.53\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do changes in dropout rate affect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trade-off between model overfitting prevention and training speed in deep learning architectures?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do changes in dropout rate affect the \u001b[0m\n",
       "\u001b[32mtrade-off between model overfitting prevention and training speed in deep learning architectures?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.46</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.46\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the choice of dropout rate affect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regularization strength and overfitting prevention in convolutional neural networks? What is the impact of dropout </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on the training time and accuracy of recurrent neural networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the choice of dropout rate affect the \u001b[0m\n",
       "\u001b[32mregularization strength and overfitting prevention in convolutional neural networks? What is the impact of dropout \u001b[0m\n",
       "\u001b[32mon the training time and accuracy of recurrent neural networks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.42</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.42\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of batch normalization, weight </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">decay, and L1/L2 regularization in conjunction with dropout layers on the generalization capabilities and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">robustness of deep neural networks.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of batch normalization, weight \u001b[0m\n",
       "\u001b[32mdecay, and L1/L2 regularization in conjunction with dropout layers on the generalization capabilities and \u001b[0m\n",
       "\u001b[32mrobustness of deep neural networks.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.42</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.42\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the applications and use cases for dropout </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layers in deep learning neural networks?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the applications and use cases for dropout \u001b[0m\n",
       "\u001b[32mlayers in deep learning neural networks?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4594</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4594\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ term Deep Learning is describing the procedure of performing                                     │\n",
       "│ machine learning tasks with deep artiﬁcial neural networks                                       │\n",
       "│ [15]. In reality, the best per...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ term Deep Learning is describing the procedure of performing                                     │\n",
       "│ machine learning tasks with deep artiﬁcial neural networks                                       │\n",
       "│ [15]. In reality, the best per...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4386</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4386\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ where Woutput ∈Rh2×2 is a learnable weight matrix (assuming the labels are binary, i.e., label   │\n",
       "│ zero                                                                                             │\n",
       "│ and label one) andboutput ∈R2 is the bias vector. ...                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ where Woutput ∈Rh2×2 is a learnable weight matrix (assuming the labels are binary, i.e., label   │\n",
       "│ zero                                                                                             │\n",
       "│ and label one) andboutput ∈R2 is the bias vector. ...                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2211.14144v1_Graph_Convolutional_Network-based_Feature_Selectio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2211.14144v1_Graph_Convolutional_Network-based_Feature_Selectio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4093</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4093\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ stochastic gradient descent algorithm to which the discussion in section 3.3 applies.            │\n",
       "│ Such an approach is often referred to as “mini-batch” selection ...                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ stochastic gradient descent algorithm to which the discussion in section 3.3 applies.            │\n",
       "│ Such an approach is often referred to as “mini-batch” selection ...                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2409.02668v1_Introduction_to_Machine_Learning</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2409.02668v1_Introduction_to_Machine_Learning\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4005</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4005\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 8 Of Things Not Treated                                                                          │\n",
       "│ This short introductory article is aimed at those who are new to deep learning.                  │\n",
       "│ In the interests of brevity and accessibility ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 8 Of Things Not Treated                                                                          │\n",
       "│ This short introductory article is aimed at those who are new to deep learning.                  │\n",
       "│ In the interests of brevity and accessibility ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3933</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3933\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Kriegeskorte &amp; Golan (2019) Neural network models and deep learning                              │\n",
       "│                                                                                                  │\n",
       "│ 4                                                                                                │\n",
       "│                                                                                                  │\n",
       "│ function, and to approximate many natural functions with fewer weights and...                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Kriegeskorte & Golan (2019) Neural network models and deep learning                              │\n",
       "│                                                                                                  │\n",
       "│ 4                                                                                                │\n",
       "│                                                                                                  │\n",
       "│ function, and to approximate many natural functions with fewer weights and...                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1902.04704v2_Neural_network_models_and_deep_learning_-_a_primer</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1902.04704v2_Neural_network_models_and_deep_learning_-_a_primer\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Dropout is a learning paradigm that brings additional robustness (and, maybe, reduces            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> overfitting risks) to massively parametrized predictors. It was introduced for deep learning in  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Srivastava et al. [181]. The purpose of dropout is to randomly drop hidden neurons in the GCN    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> layer and the output layer multiple times during training, which helps reduce the effect of high <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> variance in the subsequent gradient computation.                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> To achieve this, we adopt the same strategy of multiple dropouts as proposed in [15]. After      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> training the neural network based on the selected features, we randomly drop hidden neurons in   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the GCN layer and the output layer multiple times (the total number of dropoutsm is a            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> hyperparameter). In other words, we obtain multiple different dropout neural network models. The <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> technique of multiple dropouts has proved to be effectively stable and robust for deep           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning-based feature selection under the HDLSS setting [15, 41].                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> For gradient computation, we compute the gradient regarding the input weight for each dropout    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> neural network model and take the mean, i.e.,                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> G = 1/m ∑m_i=1 G_i                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> where Gi is the gradient of the empirical loss computed from the examples in the ith dropout     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> model.                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Dropout is a widely used technique in deep learning to improve the robustness and stability of   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> neural networks. By randomly dropping neurons during training, dropout helps reduce overfitting  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and improves the generalization of the network on new, unseen data. This technique has been      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> shown to be effective in various deep learning architectures, including convolutional neural     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> networks (CNNs) and graph convolutional networks (GCNs).                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition to its applications in deep learning, dropout has also been used in other areas of   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> machine learning, such as feature selection and dimensionality reduction. The idea behind        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> dropout is to introduce randomness into the training process, which helps prevent overfitting    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and improves the overall performance of the network.                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2211.14144v1_Graph_Convolutional_Network-based_Feature_Selectio         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3: https://arxiv.org/pdf/2409.02668v1_Introduction_to_Machine_Learning               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1902.04704v2_Neural_network_models_and_deep_learning_-_a_primer         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Dropout is a learning paradigm that brings additional robustness (and, maybe, reduces            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m overfitting risks) to massively parametrized predictors. It was introduced for deep learning in  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Srivastava et al. [181]. The purpose of dropout is to randomly drop hidden neurons in the GCN    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m layer and the output layer multiple times during training, which helps reduce the effect of high \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m variance in the subsequent gradient computation.                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m To achieve this, we adopt the same strategy of multiple dropouts as proposed in [15]. After      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m training the neural network based on the selected features, we randomly drop hidden neurons in   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the GCN layer and the output layer multiple times (the total number of dropoutsm is a            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m hyperparameter). In other words, we obtain multiple different dropout neural network models. The \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m technique of multiple dropouts has proved to be effectively stable and robust for deep           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning-based feature selection under the HDLSS setting [15, 41].                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m For gradient computation, we compute the gradient regarding the input weight for each dropout    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m neural network model and take the mean, i.e.,                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m G = 1/m ∑m_i=1 G_i                                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m where Gi is the gradient of the empirical loss computed from the examples in the ith dropout     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m model.                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Dropout is a widely used technique in deep learning to improve the robustness and stability of   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m neural networks. By randomly dropping neurons during training, dropout helps reduce overfitting  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and improves the generalization of the network on new, unseen data. This technique has been      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m shown to be effective in various deep learning architectures, including convolutional neural     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m networks (CNNs) and graph convolutional networks (GCNs).                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition to its applications in deep learning, dropout has also been used in other areas of   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m machine learning, such as feature selection and dimensionality reduction. The idea behind        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m dropout is to introduce randomness into the training process, which helps prevent overfitting    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and improves the overall performance of the network.                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2211.14144v1_Graph_Convolutional_Network-based_Feature_Selectio         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3: https://arxiv.org/pdf/2409.02668v1_Introduction_to_Machine_Learning               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1902.04704v2_Neural_network_models_and_deep_learning_-_a_primer         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It asks about the <span style=\"color: #008000; text-decoration-color: #008000\">'attention mechanism'</span>, which \n",
       "is a broad topic in deep learning. However, it does contain a specific technical term that can be used to retrieve \n",
       "relevant scientific content. The query's relevance to scientific research is high, and it should work well with \n",
       "vector search due to its concise nature.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It asks about the \u001b[32m'attention mechanism'\u001b[0m, which \n",
       "is a broad topic in deep learning. However, it does contain a specific technical term that can be used to retrieve \n",
       "relevant scientific content. The query's relevance to scientific research is high, and it should work well with \n",
       "vector search due to its concise nature.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What attention mechanism do?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What attention mechanism do?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the role of attention mechanisms, including </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">but not limited to, spatial attention, channel attention, and graph attention, in deep learning models for natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing tasks.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the role of attention mechanisms, including \u001b[0m\n",
       "\u001b[32mbut not limited to, spatial attention, channel attention, and graph attention, in deep learning models for natural \u001b[0m\n",
       "\u001b[32mlanguage processing tasks.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do different attention mechanisms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., additive vs. multiplicative) affect the trade-off between model interpretability and performance in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explainable AI applications?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do different attention mechanisms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., additive vs. multiplicative\u001b[0m\u001b[32m)\u001b[0m\u001b[32m affect the trade-off between model interpretability and performance in \u001b[0m\n",
       "\u001b[32mexplainable AI applications?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.51</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.51\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the effects of different attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanisms (e.g., self-attention, multi-head attention) on model performance and training stability in deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning neural networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the effects of different attention \u001b[0m\n",
       "\u001b[32mmechanisms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., self-attention, multi-head attention\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on model performance and training stability in deep \u001b[0m\n",
       "\u001b[32mlearning neural networks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.51</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.51\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the choice of attention mechanism influence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the design of recurrent neural networks? What impact does it have on the capacity to learn long-term dependencies </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and temporal relationships in sequential data?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the choice of attention mechanism influence \u001b[0m\n",
       "\u001b[32mthe design of recurrent neural networks? What impact does it have on the capacity to learn long-term dependencies \u001b[0m\n",
       "\u001b[32mand temporal relationships in sequential data?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanism design, neural network architecture, and optimization algorithms (e.g., Adam, SGD) on the convergence of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training objectives and model performance metrics in deep learning models.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between attention \u001b[0m\n",
       "\u001b[32mmechanism design, neural network architecture, and optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the convergence of \u001b[0m\n",
       "\u001b[32mtraining objectives and model performance metrics in deep learning models.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.49</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.49\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the effects of different attention mechanisms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., self-attention, multi-head attention) on model performance and training stability in deep learning neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the effects of different attention mechanisms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., self-attention, multi-head attention\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on model performance and training stability in deep learning neural \u001b[0m\n",
       "\u001b[32mnetworks?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3149</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3149\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ https://doi.org/10.1145/3194554.3194625                                                          │\n",
       "│ 1 INTRODUCTION                                                                                   │\n",
       "│ Deep learning has increasingly drawn attentions in many research                                 │\n",
       "│ fields, such as speech recogni...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ https://doi.org/10.1145/3194554.3194625                                                          │\n",
       "│ 1 INTRODUCTION                                                                                   │\n",
       "│ Deep learning has increasingly drawn attentions in many research                                 │\n",
       "│ fields, such as speech recogni...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1804.11239v1_Structured_Weight_Matrices-Based_Hardware_Accelera</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1804.11239v1_Structured_Weight_Matrices-Based_Hardware_Accelera\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3051</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3051\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and ALBERT, the number of token inputs for the model is limited to an upper bound of 512 tokens, │\n",
       "│ the LongFormer                                                                                   │\n",
       "│ model has input tokens upper bound of ...                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and ALBERT, the number of token inputs for the model is limited to an upper bound of 512 tokens, │\n",
       "│ the LongFormer                                                                                   │\n",
       "│ model has input tokens upper bound of ...                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2101.06326v2_Grid_Search_Hyperparameter_Benchmarking_of_BERT,_A</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2101.06326v2_Grid_Search_Hyperparameter_Benchmarking_of_BERT,_A\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3034</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3034\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ applications. In particular, perceptual tasks have been studied most so far.                     │\n",
       "│ However, with the set of tools presented here, we believe many more probl...                     │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ applications. In particular, perceptual tasks have been studied most so far.                     │\n",
       "│ However, with the set of tools presented here, we believe many more probl...                     │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1810.05401v2_A_Gentle_Introduction_to_Deep_Learning_in_Medical_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1810.05401v2_A_Gentle_Introduction_to_Deep_Learning_in_Medical_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.2992</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.2992\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ wider as we progress through deeper layers. This reveals that                                    │\n",
       "│ learned features are mainly locally dependent, even though self-                                 │\n",
       "│ attention is able to mo...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ wider as we progress through deeper layers. This reveals that                                    │\n",
       "│ learned features are mainly locally dependent, even though self-                                 │\n",
       "│ attention is able to mo...                                                                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.2958</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.2958\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ term Deep Learning is describing the procedure of performing                                     │\n",
       "│ machine learning tasks with deep artiﬁcial neural networks                                       │\n",
       "│ [15]. In reality, the best per...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ term Deep Learning is describing the procedure of performing                                     │\n",
       "│ machine learning tasks with deep artiﬁcial neural networks                                       │\n",
       "│ [15]. In reality, the best per...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The attention mechanism used in various deep learning models, such as BERT, ALBERT, and          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> LongFormer, is self-attention. Self-attention is a type of neural network component that allows  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the model to focus on specific parts of the input data when generating outputs.                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> According to Document 2, LongFormer has a \"sliding window approach for attention\" which scales   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> linearly based on sequence length. This suggests that LongFormer uses a self-attention mechanism <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> with a sliding window approach to focus on specific parts of the input data.                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In contrast, BERT and ALBERT use a similar self-attention mechanism but without the sliding      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> window approach (Source: Document 2).                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Self-attention has been shown to be effective in modeling long-range dependencies, as mentioned  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in Document 4. However, it may not always capture longer-term dependencies, especially for       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> acoustic features in the encoder (Source: Document 4).                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The attention mechanism used in deep learning models can also lead to issues such as vanishing   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> gradients and exploding gradients, which can make it difficult to understand how a specific      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> neuron is recognizing certain patterns (Source: Document 5). Techniques such as gradient norm    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> clipping have been developed to address these issues.                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Attention mechanisms are a crucial component of deep learning models, allowing them to focus on  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> specific parts of the input data when generating outputs. Self-attention is particularly useful  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for modeling long-range dependencies in sequential data. However, it can also lead to issues     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> such as vanishing gradients and exploding gradients, which require careful tuning and            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> regularization techniques.                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition to self-attention, other attention mechanisms have been proposed, such as channel    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> attention and spatial attention, which can be used in conjunction with self-attention to improve <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> model performance (Source: not provided).                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1804.11239v1_Structured_Weight_Matrices-Based_Hardware_Accelera         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2101.06326v2_Grid_Search_Hyperparameter_Benchmarking_of_BERT,_A         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1810.05401v2_A_Gentle_Introduction_to_Deep_Learning_in_Medical_         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The attention mechanism used in various deep learning models, such as BERT, ALBERT, and          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m LongFormer, is self-attention. Self-attention is a type of neural network component that allows  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the model to focus on specific parts of the input data when generating outputs.                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m According to Document 2, LongFormer has a \"sliding window approach for attention\" which scales   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m linearly based on sequence length. This suggests that LongFormer uses a self-attention mechanism \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m with a sliding window approach to focus on specific parts of the input data.                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In contrast, BERT and ALBERT use a similar self-attention mechanism but without the sliding      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m window approach (Source: Document 2).                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Self-attention has been shown to be effective in modeling long-range dependencies, as mentioned  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in Document 4. However, it may not always capture longer-term dependencies, especially for       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m acoustic features in the encoder (Source: Document 4).                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The attention mechanism used in deep learning models can also lead to issues such as vanishing   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m gradients and exploding gradients, which can make it difficult to understand how a specific      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m neuron is recognizing certain patterns (Source: Document 5). Techniques such as gradient norm    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m clipping have been developed to address these issues.                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Attention mechanisms are a crucial component of deep learning models, allowing them to focus on  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m specific parts of the input data when generating outputs. Self-attention is particularly useful  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for modeling long-range dependencies in sequential data. However, it can also lead to issues     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m such as vanishing gradients and exploding gradients, which require careful tuning and            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m regularization techniques.                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition to self-attention, other attention mechanisms have been proposed, such as channel    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m attention and spatial attention, which can be used in conjunction with self-attention to improve \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m model performance (Source: not provided).                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1804.11239v1_Structured_Weight_Matrices-Based_Hardware_Accelera         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2101.06326v2_Grid_Search_Hyperparameter_Benchmarking_of_BERT,_A         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1810.05401v2_A_Gentle_Introduction_to_Deep_Learning_in_Medical_         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2006.01713v1_SAN-M:_Memory_Equipped_Self-Attention_for_End-to-E         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1803.02129v1_A_Non-Technical_Survey_on_Deep_Convolutional_Neura         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It does not contain technical terms or concepts\n",
       "related to image classification, which might lead to irrelevant results. However, it is focused on retrieving \n",
       "scientific content and can be effectively retrieved with vector search.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It does not contain technical terms or concepts\n",
       "related to image classification, which might lead to irrelevant results. However, it is focused on retrieving \n",
       "scientific content and can be effectively retrieved with vector search.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: How much data needed for training models for image classification?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: How much data needed for training models for image classification?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What is the minimum amount of data required for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training convolutional neural networks (CNNs) for image classification tasks, considering factors such as dataset </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">size, class imbalance, and feature extraction?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What is the minimum amount of data required for \u001b[0m\n",
       "\u001b[32mtraining convolutional neural networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for image classification tasks, considering factors such as dataset \u001b[0m\n",
       "\u001b[32msize, class imbalance, and feature extraction?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.67</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.67\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the number of training examples influence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the performance of transfer learning models in image classification? What impact does it have on the model's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ability to generalize to unseen data?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the number of training examples influence \u001b[0m\n",
       "\u001b[32mthe performance of transfer learning models in image classification? What impact does it have on the model's \u001b[0m\n",
       "\u001b[32mability to generalize to unseen data?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between dataset size,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neural network architecture (e.g., ResNet, Inception), and optimization algorithms (e.g., Adam, SGD) on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convergence of training objectives and model performance metrics for image classification tasks.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between dataset size,\u001b[0m\n",
       "\u001b[32mneural network architecture \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., ResNet, Inception\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the \u001b[0m\n",
       "\u001b[32mconvergence of training objectives and model performance metrics for image classification tasks.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.52</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.52\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do changes in data quantity affect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trade-off between model overfitting and underfitting in image classification tasks using convolutional neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do changes in data quantity affect the \u001b[0m\n",
       "\u001b[32mtrade-off between model overfitting and underfitting in image classification tasks using convolutional neural \u001b[0m\n",
       "\u001b[32mnetworks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.46</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.46\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of dataset size, data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">augmentation techniques, and batch normalization on the performance of deep neural networks for image </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classification tasks.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of dataset size, data \u001b[0m\n",
       "\u001b[32maugmentation techniques, and batch normalization on the performance of deep neural networks for image \u001b[0m\n",
       "\u001b[32mclassification tasks.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.44</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.44\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What is the minimum amount of data required for training</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convolutional neural networks (CNNs) for image classification tasks, considering factors such as dataset size, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">class imbalance, and feature extraction?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What is the minimum amount of data required for training\u001b[0m\n",
       "\u001b[32mconvolutional neural networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for image classification tasks, considering factors such as dataset size, \u001b[0m\n",
       "\u001b[32mclass imbalance, and feature extraction?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3708</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3708\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 7.1 Convolutional Neural Networks                                                                │\n",
       "│ MatConvNet uses a special class of artiﬁcial neural networks known as Con-                       │\n",
       "│ volutional Neural Networks (CNNs), which ...                                                     │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 7.1 Convolutional Neural Networks                                                                │\n",
       "│ MatConvNet uses a special class of artiﬁcial neural networks known as Con-                       │\n",
       "│ volutional Neural Networks (CNNs), which ...                                                     │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3702</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3702\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ References                                                                                       │\n",
       "│ Abuzaid(2015). Abuzaid, F. (2015). Optimizing cpu performance for convolutional neural networks. │\n",
       "│ URL http://cs231n.stanford.edu/reports/fab...                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ References                                                                                       │\n",
       "│ Abuzaid(2015). Abuzaid, F. (2015). Optimizing cpu performance for convolutional neural networks. │\n",
       "│ URL http://cs231n.stanford.edu/reports/fab...                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3601</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3601\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ platform2. for example. The images in these datasets are already labelled,                       │\n",
       "│ hence they are ready for supervised image classiﬁcation. They are perfect t...                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ platform2. for example. The images in these datasets are already labelled,                       │\n",
       "│ hence they are ready for supervised image classiﬁcation. They are perfect t...                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2305.05601v1_Deep_Learning_and_Geometric_Deep_Learning:_an_intr</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2305.05601v1_Deep_Learning_and_Geometric_Deep_Learning:_an_intr\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3549</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3549\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ split theavailabledataintotraining, validationandtest setsat aratioof8:1:1.Theytrained           │\n",
       "│ an FNN with 18 fully-connected layers of 512 neurons each. The ...                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ split theavailabledataintotraining, validationandtest setsat aratioof8:1:1.Theytrained           │\n",
       "│ an FNN with 18 fully-connected layers of 512 neurons each. The ...                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3521</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3521\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ etal.2012a).ThecelebratedvictoryofAlexnetspearheadedarevo-                                       │\n",
       "│ lutionaryapproachofdesigningdeeperCNNswithafoundationfor                                         │\n",
       "│ the traditional convolution block ...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ etal.2012a).ThecelebratedvictoryofAlexnetspearheadedarevo-                                       │\n",
       "│ lutionaryapproachofdesigningdeeperCNNswithafoundationfor                                         │\n",
       "│ the traditional convolution block ...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2008.13611v2_Galaxy_Morphology_Classification_using_EfficientNe</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2008.13611v2_Galaxy_Morphology_Classification_using_EfficientNe\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The amount of data needed for training models for image classification can vary depending on the <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> specific model architecture and the complexity of the task. However, in general, convolutional   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> neural networks (CNNs) require a significant amount of data to learn effective features.         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> According to Document 1, CNNs are designed to handle large datasets by applying small-scale      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> linear kernels or filters across portions of their input data, rather than using a single        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> full-sized linear transformation (Source: Document 1). This approach allows the model to process <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> large images without requiring excessive computational resources.                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In practice, image classification models typically require tens of thousands to millions of      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> training examples to achieve good performance. For example, the MNIST dataset contains 60,000    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> images for training and 10,000 images for testing (Source: Document 3). The CIFAR-10 dataset, on <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the other hand, consists of 60,000 training images, 10,000 validation images, and 10,000 test    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> images (Source: Document 3).                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> It's worth noting that some models, such as those using residual blocks, can learn to recognize  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> complex patterns in smaller datasets. However, these models often require more computational     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> resources and may not generalize as well to new, unseen data.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Disagreement:</span> There is no clear consensus on the exact amount of data required for training      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> image classification models. Different models and architectures may have different requirements, <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and the optimal amount of data can depend on various factors, such as the complexity of the task <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and the quality of the data.                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In general, the amount of data required for training machine learning models depends on several  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> factors, including the complexity of the task, the quality of the data, and the computational    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> resources available. Image classification is a challenging task that requires large amounts of   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> data to learn effective features and achieve good performance. However, there are various        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> techniques and architectures that can help reduce the amount of data required, such as transfer  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning, data augmentation, and model pruning.                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2305.05601v1_Deep_Learning_and_Geometric_Deep_Learning:_an_intr         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The amount of data needed for training models for image classification can vary depending on the \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m specific model architecture and the complexity of the task. However, in general, convolutional   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m neural networks (CNNs) require a significant amount of data to learn effective features.         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m According to Document 1, CNNs are designed to handle large datasets by applying small-scale      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m linear kernels or filters across portions of their input data, rather than using a single        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m full-sized linear transformation (Source: Document 1). This approach allows the model to process \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m large images without requiring excessive computational resources.                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In practice, image classification models typically require tens of thousands to millions of      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m training examples to achieve good performance. For example, the MNIST dataset contains 60,000    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m images for training and 10,000 images for testing (Source: Document 3). The CIFAR-10 dataset, on \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the other hand, consists of 60,000 training images, 10,000 validation images, and 10,000 test    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m images (Source: Document 3).                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m It's worth noting that some models, such as those using residual blocks, can learn to recognize  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m complex patterns in smaller datasets. However, these models often require more computational     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m resources and may not generalize as well to new, unseen data.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDisagreement:\u001b[0m There is no clear consensus on the exact amount of data required for training      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m image classification models. Different models and architectures may have different requirements, \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and the optimal amount of data can depend on various factors, such as the complexity of the task \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and the quality of the data.                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In general, the amount of data required for training machine learning models depends on several  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m factors, including the complexity of the task, the quality of the data, and the computational    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m resources available. Image classification is a challenging task that requires large amounts of   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m data to learn effective features and achieve good performance. However, there are various        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m techniques and architectures that can help reduce the amount of data required, such as transfer  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning, data augmentation, and model pruning.                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2305.05601v1_Deep_Learning_and_Geometric_Deep_Learning:_an_intr         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It's focused on retrieving general information \n",
       "about backpropagation in machine learning, which makes it relevant to a scientific research database. However, the \n",
       "lack of specific technical terms or concepts might lead to irrelevant results. The query would still work well with\n",
       "vector search due to its broad relevance to the topic.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It's focused on retrieving general information \n",
       "about backpropagation in machine learning, which makes it relevant to a scientific research database. However, the \n",
       "lack of specific technical terms or concepts might lead to irrelevant results. The query would still work well with\n",
       "vector search due to its broad relevance to the topic.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What is backprop exactly?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What is backprop exactly?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What is the mathematical formulation and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computational implementation of backpropagation in neural networks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What is the mathematical formulation and \u001b[0m\n",
       "\u001b[32mcomputational implementation of backpropagation in neural networks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.49</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.49\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the role of backpropagation in training </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convolutional neural networks (CNNs) versus recurrent neural networks (RNNs), including its impact on model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture, hyperparameters, and performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the role of backpropagation in training \u001b[0m\n",
       "\u001b[32mconvolutional neural networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m versus recurrent neural networks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, including its impact on model \u001b[0m\n",
       "\u001b[32marchitecture, hyperparameters, and performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.40</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.40\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the relationship between backpropagation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">optimization algorithms (e.g., Adam, SGD), and neural network architectures (e.g., ResNet, LeNet) on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convergence of training objectives and model performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the relationship between backpropagation, \u001b[0m\n",
       "\u001b[32moptimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and neural network architectures \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., ResNet, LeNet\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the \u001b[0m\n",
       "\u001b[32mconvergence of training objectives and model performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.33</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.33\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the concept of backpropagation relate to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gradient descent algorithms? What are the key differences between batch normalization and backpropagation in deep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning models?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the concept of backpropagation relate to \u001b[0m\n",
       "\u001b[32mgradient descent algorithms? What are the key differences between batch normalization and backpropagation in deep \u001b[0m\n",
       "\u001b[32mlearning models?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.32</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.32\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways does the choice of activation function </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">affect the efficiency and accuracy of backpropagation in deep learning models?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways does the choice of activation function \u001b[0m\n",
       "\u001b[32maffect the efficiency and accuracy of backpropagation in deep learning models?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.32</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.32\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What is the mathematical formulation and computational </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implementation of backpropagation in neural networks?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What is the mathematical formulation and computational \u001b[0m\n",
       "\u001b[32mimplementation of backpropagation in neural networks?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5590</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5590\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 1.2 How does a neural network learn                                                              │\n",
       "│ 1.2.1 Traditional                                                                                │\n",
       "│ A traditional approach of optimizing the connection weights to improve the network’s accuracy    │\n",
       "│ is...                                                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 1.2 How does a neural network learn                                                              │\n",
       "│ 1.2.1 Traditional                                                                                │\n",
       "│ A traditional approach of optimizing the connection weights to improve the network’s accuracy    │\n",
       "│ is...                                                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5436</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5436\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ measured how good a network performs, by testing a network with a given dataset, over and over   │\n",
       "│ again.                                                                                           │\n",
       "│ In such a dataset, input values and the expected...                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ measured how good a network performs, by testing a network with a given dataset, over and over   │\n",
       "│ again.                                                                                           │\n",
       "│ In such a dataset, input values and the expected...                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2211.16978v1_Combining_Neuro-Evolution_of_Augmenting_Topologies\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5206</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5206\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Similar case, of not giving credit to the original inventor, involves a popular backpropagation  │\n",
       "│ learning rule that was first                                                                     │\n",
       "│ specified by statisticia...                                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Similar case, of not giving credit to the original inventor, involves a popular backpropagation  │\n",
       "│ learning rule that was first                                                                     │\n",
       "│ specified by statisticia...                                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1701.05549v1_Deep_Neural_Networks_-_A_Brief_History</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1701.05549v1_Deep_Neural_Networks_-_A_Brief_History\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4858</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4858\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ clear unterstanding of the discussed methods rather than provide an exhaustive literature        │\n",
       "│ review. In order to facilitate a concise presentation, detai...                                  │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ clear unterstanding of the discussed methods rather than provide an exhaustive literature        │\n",
       "│ review. In order to facilitate a concise presentation, detai...                                  │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2312.14849v1_Neural-network-based_regularization_methods_for_in</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2312.14849v1_Neural-network-based_regularization_methods_for_in\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4647</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4647\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 2.3. Auto-differentiation                                                                        │\n",
       "│ Automatic differentiation (AD) is a technique for obtaining                                      │\n",
       "│ the gradients of a program’s output with respect to input                                        │\n",
       "│ (Nauma...                                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 2.3. Auto-differentiation                                                                        │\n",
       "│ Automatic differentiation (AD) is a technique for obtaining                                      │\n",
       "│ the gradients of a program’s output with respect to input                                        │\n",
       "│ (Nauma...                                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2312.16192v3_A_Method_for_Auto-Differentiation_of_the_Voronoi_T</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2312.16192v3_A_Method_for_Auto-Differentiation_of_the_Voronoi_T\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Backpropagation is a supervised learning method for multilayer feed-forward neural networks that <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> uses the backpropagation algorithm to optimize connection weights and improve network accuracy.  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> According to Brownlee (2016), \"The Backpropagation algorithm is a supervised learning method for <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> multilayer feed-forward networks from the field of Artificial Neural Networks.\" The algorithm    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> measures how good a network performs by testing it with a given dataset, over and over again,    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and calculates errors using basic calculus (Sathyanarayana, 2014). In stochastic                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> backpropagation, weights are initially set to small random values to deal with the vanishing     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> gradient problem (Philipp Kr¨ahenb¨uhl, 2016).                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Backpropagation is an extension of the Perceptron's rule to many-layer networks, replacing the   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> threshold function with a differentiable sigmoid function (Document 3). This seemingly small     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> change led to an explosion in neural networks research. The algorithm has become a primary       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> application of automatic differentiation (AD), which allows training even Large Language Models  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> with billions of parameters (Naumann, 2012).                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Backpropagation is a fundamental concept in deep learning and artificial neural networks. It's a <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> widely used algorithm for optimizing connection weights to improve network accuracy. The         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> development of backpropagation can be traced back to the work of statisticians Robbins and       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Monroe (1951), who specified a stochastic approximation method, which was later popularized by   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Rumelhart, Hinton, and Williams (1986). However, it's worth noting that Werbos (1974) also       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> specified this rule for neural networks, a dozen years before Rumelhart et al. (Document 3).     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition to its application in deep learning, backpropagation has been used in various fields <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> such as physics, chemistry, and biology, where it's used for automatic differentiation (AD) to   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> obtain gradients of a program's output with respect to input (Naumann, 2012; Dold &amp; van Egmond,  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2023).                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1: https://arxiv.org/pdf/2211.16978v1                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2: https://arxiv.org/pdf/2211.16978v1                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3: https://arxiv.org/pdf/1701.05549v1                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4: https://arxiv.org/pdf/2312.14849v1                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5: https://arxiv.org/pdf/2312.16192v3                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Backpropagation is a supervised learning method for multilayer feed-forward neural networks that \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m uses the backpropagation algorithm to optimize connection weights and improve network accuracy.  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m According to Brownlee (2016), \"The Backpropagation algorithm is a supervised learning method for \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m multilayer feed-forward networks from the field of Artificial Neural Networks.\" The algorithm    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m measures how good a network performs by testing it with a given dataset, over and over again,    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and calculates errors using basic calculus (Sathyanarayana, 2014). In stochastic                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m backpropagation, weights are initially set to small random values to deal with the vanishing     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m gradient problem (Philipp Kr¨ahenb¨uhl, 2016).                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Backpropagation is an extension of the Perceptron's rule to many-layer networks, replacing the   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m threshold function with a differentiable sigmoid function (Document 3). This seemingly small     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m change led to an explosion in neural networks research. The algorithm has become a primary       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m application of automatic differentiation (AD), which allows training even Large Language Models  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m with billions of parameters (Naumann, 2012).                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Backpropagation is a fundamental concept in deep learning and artificial neural networks. It's a \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m widely used algorithm for optimizing connection weights to improve network accuracy. The         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m development of backpropagation can be traced back to the work of statisticians Robbins and       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Monroe (1951), who specified a stochastic approximation method, which was later popularized by   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Rumelhart, Hinton, and Williams (1986). However, it's worth noting that Werbos (1974) also       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m specified this rule for neural networks, a dozen years before Rumelhart et al. (Document 3).     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition to its application in deep learning, backpropagation has been used in various fields \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m such as physics, chemistry, and biology, where it's used for automatic differentiation (AD) to   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m obtain gradients of a program's output with respect to input (Naumann, 2012; Dold & van Egmond,  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2023).                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1: https://arxiv.org/pdf/2211.16978v1                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2: https://arxiv.org/pdf/2211.16978v1                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3: https://arxiv.org/pdf/1701.05549v1                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4: https://arxiv.org/pdf/2312.14849v1                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5: https://arxiv.org/pdf/2312.16192v3                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It asks about the general effect of \n",
       "regularization in machine learning or statistics, which could lead to a broad range of results. However, it does \n",
       "contain a specific technical term <span style=\"color: #008000; text-decoration-color: #008000\">'regularization'</span>, making it somewhat relevant for scientific content. The query's\n",
       "focus on retrieving information related to regularization makes it retrievable for vector search.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It asks about the general effect of \n",
       "regularization in machine learning or statistics, which could lead to a broad range of results. However, it does \n",
       "contain a specific technical term \u001b[32m'regularization'\u001b[0m, making it somewhat relevant for scientific content. The query's\n",
       "focus on retrieving information related to regularization makes it retrievable for vector search.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: Regularization prevent what?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: Regularization prevent what?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the mechanisms by which regularization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques (e.g., L1, L2, dropout) prevent overfitting and improve model generalization in machine learning?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the mechanisms by which regularization \u001b[0m\n",
       "\u001b[32mtechniques \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., L1, L2, dropout\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prevent overfitting and improve model generalization in machine learning?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How do different types of regularization (e.g., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regularization strength, type of regularization) affect the prevention of overfitting in deep neural networks? What</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is the impact on training time and accuracy when using regularization techniques?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How do different types of regularization \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., \u001b[0m\n",
       "\u001b[32mregularization strength, type of regularization\u001b[0m\u001b[32m)\u001b[0m\u001b[32m affect the prevention of overfitting in deep neural networks? What\u001b[0m\n",
       "\u001b[32mis the impact on training time and accuracy when using regularization techniques?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.61</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.61\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do changes in regularization strength </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">affect the trade-off between model generalization and training speed in deep learning architectures?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do changes in regularization strength \u001b[0m\n",
       "\u001b[32maffect the trade-off between model generalization and training speed in deep learning architectures?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.53</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.53\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of regularization, early </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stopping, and data augmentation on the prevention of overfitting and improvement of model performance in supervised</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning algorithms.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of regularization, early \u001b[0m\n",
       "\u001b[32mstopping, and data augmentation on the prevention of overfitting and improvement of model performance in supervised\u001b[0m\n",
       "\u001b[32mlearning algorithms.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regularization techniques (e.g., L1, L2), neural network architecture, and optimization algorithms (e.g., Adam, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">SGD) on the prevention of overfitting and improvement of model performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between \u001b[0m\n",
       "\u001b[32mregularization techniques \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., L1, L2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, neural network architecture, and optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, \u001b[0m\n",
       "\u001b[32mSGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the prevention of overfitting and improvement of model performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.48</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.48\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the mechanisms by which regularization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">techniques (e.g., L1, L2, dropout) prevent overfitting and improve model generalization in machine learning?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the mechanisms by which regularization \u001b[0m\n",
       "\u001b[32mtechniques \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., L1, L2, dropout\u001b[0m\u001b[32m)\u001b[0m\u001b[32m prevent overfitting and improve model generalization in machine learning?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5271</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5271\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ when a trained network performs accurately on the given data, but cannot                         │\n",
       "│ generalize well to new data. Regularization is a broad term that describes                       │\n",
       "│ at...                                                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ when a trained network performs accurately on the given data, but cannot                         │\n",
       "│ generalize well to new data. Regularization is a broad term that describes                       │\n",
       "│ at...                                                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4569</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4569\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ training. This penalty discourages excessive complexity in                                       │\n",
       "│ the model by shrinking the magnitude of the coefficients.                                        │\n",
       "│ Regularization helps prevent over...                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ training. This penalty discourages excessive complexity in                                       │\n",
       "│ the model by shrinking the magnitude of the coefficients.                                        │\n",
       "│ Regularization helps prevent over...                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2310.10368v1_Machine_learning_in_physics:_a_short_guide</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2310.10368v1_Machine_learning_in_physics:_a_short_guide\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3581</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3581\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Regularization                                                                                   │\n",
       "│ Theultimategoal of \u0000\u0000ingamodel isto generalizewell toatargetpopulationthathasnot                   │\n",
       "│ yet been“seen”bythemodel.Modelswithsu\u0000cientcapacitycan...                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Regularization                                                                                   │\n",
       "│ Theultimategoal of \u0000\u0000ingamodel isto generalizewell toatargetpopulationthathasnot                   │\n",
       "│ yet been“seen”bythemodel.Modelswithsu\u0000cientcapacitycan...                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3347</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3347\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ statistical in nature,                                                                           │\n",
       "│ • a great deal of research eﬀort has been devoted to the development                             │\n",
       "│ of practical improvements to the basic stochastic gradient...                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ statistical in nature,                                                                           │\n",
       "│ • a great deal of research eﬀort has been devoted to the development                             │\n",
       "│ of practical improvements to the basic stochastic gradient...                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3187</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3187\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Adapting Decoder-Based Language Models for Diverse Encoder Downstream Tasks                      │\n",
       "│ Alternatively, the input can be passed through                                                   │\n",
       "│ the key and value matrices,...                                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Adapting Decoder-Based Language Models for Diverse Encoder Downstream Tasks                      │\n",
       "│ Alternatively, the input can be passed through                                                   │\n",
       "│ the key and value matrices,...                                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2503.02656v1_Adapting_Decoder-Based_Language_Models_for_Diverse</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2503.02656v1_Adapting_Decoder-Based_Language_Models_for_Diverse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Regularization prevents overfitting in machine learning models.                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Overfitting occurs when a trained network performs accurately on the given data but cannot       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> generalize well to new, unseen data. Regularization techniques aim to avoid this by rewarding    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> smoothness and discouraging excessive complexity in the model (Document 1). One approach is      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> dropout, which involves randomly disabling a fraction of neurons during each training iteration  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> to prevent the network from relying too heavily on specific neurons or memorizing noise in the   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> training data (Documents 2 and 3).                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Regularization helps minimize overfitting by promoting simpler models that generalize well to    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> unseen data. Weight decay and L1 regularization are commonly used methods, which add an extra    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> term to the loss function to shrink small weights to zero or all weights by a small amount       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> (Document 3). In contrast, dropout is a widely used technique in deep learning to prevent        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> overfitting and improve generalization (Documents 2 and 5).                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Regularization techniques are essential in machine learning to prevent overfitting and ensure    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> that models generalize well to new data. Overfitting can lead to poor performance on unseen      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> data, which can have significant consequences in applications such as image recognition, natural <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> language processing, and predictive modeling.                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition to dropout, other regularization techniques include early stopping, feature          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> selection, dimensionality reduction, ensemble methods, and data augmentation (Document 2). These <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> techniques aim to address overfitting by reducing the complexity of the model or increasing its  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> capacity to generalize. By using regularization techniques, machine learning models can achieve  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> better performance on unseen data and make more accurate predictions.                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2: https://arxiv.org/pdf/2310.10368v1_Machine_learning_in_physics:_a_short_guide     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2503.02656v1_Adapting_Decoder-Based_Language_Models_for_Diverse         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Regularization prevents overfitting in machine learning models.                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Overfitting occurs when a trained network performs accurately on the given data but cannot       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m generalize well to new, unseen data. Regularization techniques aim to avoid this by rewarding    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m smoothness and discouraging excessive complexity in the model (Document 1). One approach is      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m dropout, which involves randomly disabling a fraction of neurons during each training iteration  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m to prevent the network from relying too heavily on specific neurons or memorizing noise in the   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m training data (Documents 2 and 3).                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Regularization helps minimize overfitting by promoting simpler models that generalize well to    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m unseen data. Weight decay and L1 regularization are commonly used methods, which add an extra    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m term to the loss function to shrink small weights to zero or all weights by a small amount       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m (Document 3). In contrast, dropout is a widely used technique in deep learning to prevent        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m overfitting and improve generalization (Documents 2 and 5).                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Regularization techniques are essential in machine learning to prevent overfitting and ensure    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m that models generalize well to new data. Overfitting can lead to poor performance on unseen      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m data, which can have significant consequences in applications such as image recognition, natural \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m language processing, and predictive modeling.                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition to dropout, other regularization techniques include early stopping, feature          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m selection, dimensionality reduction, ensemble methods, and data augmentation (Document 2). These \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m techniques aim to address overfitting by reducing the complexity of the model or increasing its  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m capacity to generalize. By using regularization techniques, machine learning models can achieve  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m better performance on unseen data and make more accurate predictions.                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2: https://arxiv.org/pdf/2310.10368v1_Machine_learning_in_physics:_a_short_guide     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2202.01319v1_Deep_Learning_for_Epidemiologists:_An_Introduction         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2503.02656v1_Adapting_Decoder-Based_Language_Models_for_Diverse         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and unambiguous, as it directly compares two concepts: word embeddings and sentence\n",
       "embeddings. Both terms are specific to the field of natural language processing <span style=\"font-weight: bold\">(</span>NLP<span style=\"font-weight: bold\">)</span> and are relevant to \n",
       "scientific research in this area. The query also contains technical terms, making it suitable for vector search. \n",
       "However, it could be improved by adding more context or specificity, such as <span style=\"color: #008000; text-decoration-color: #008000\">'word embedding vs sentence embedding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in NLP'</span> or <span style=\"color: #008000; text-decoration-color: #008000\">'comparison of word2vec and sentence-bert'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and unambiguous, as it directly compares two concepts: word embeddings and sentence\n",
       "embeddings. Both terms are specific to the field of natural language processing \u001b[1m(\u001b[0mNLP\u001b[1m)\u001b[0m and are relevant to \n",
       "scientific research in this area. The query also contains technical terms, making it suitable for vector search. \n",
       "However, it could be improved by adding more context or specificity, such as \u001b[32m'word embedding vs sentence embedding \u001b[0m\n",
       "\u001b[32min NLP'\u001b[0m or \u001b[32m'comparison of word2vec and sentence-bert'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: word embedding vs sentence embedding?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: word embedding vs sentence embedding?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do word embeddings and sentence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embeddings differ in their ability to capture contextual information and semantic relationships between words and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">phrases in text data?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do word embeddings and sentence \u001b[0m\n",
       "\u001b[32membeddings differ in their ability to capture contextual information and semantic relationships between words and \u001b[0m\n",
       "\u001b[32mphrases in text data?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.72</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.72\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the comparative performance of word </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embeddings (e.g., Word2Vec, GloVe) versus sentence embeddings (e.g., BERT, RoBERTa) on various natural language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing tasks, including question answering, sentiment analysis, and text classification.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the comparative performance of word \u001b[0m\n",
       "\u001b[32membeddings \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Word2Vec, GloVe\u001b[0m\u001b[32m)\u001b[0m\u001b[32m versus sentence embeddings \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., BERT, RoBERTa\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on various natural language \u001b[0m\n",
       "\u001b[32mprocessing tasks, including question answering, sentiment analysis, and text classification.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.66</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.66\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How do word embeddings differ from sentence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embeddings in terms of semantic meaning extraction? What about their applications in text classification, sentiment</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">analysis, and machine translation?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How do word embeddings differ from sentence \u001b[0m\n",
       "\u001b[32membeddings in terms of semantic meaning extraction? What about their applications in text classification, sentiment\u001b[0m\n",
       "\u001b[32manalysis, and machine translation?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.62</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.62\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the differences in representation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning and neural network architectures between word embeddings and sentence embeddings, particularly in natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing tasks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the differences in representation \u001b[0m\n",
       "\u001b[32mlearning and neural network architectures between word embeddings and sentence embeddings, particularly in natural \u001b[0m\n",
       "\u001b[32mlanguage processing tasks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.62</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.62\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the effects of pre-training word embeddings </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">versus pre-training sentence embeddings on the performance of deep learning models for natural language processing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks, including language modeling and question answering.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the effects of pre-training word embeddings \u001b[0m\n",
       "\u001b[32mversus pre-training sentence embeddings on the performance of deep learning models for natural language processing \u001b[0m\n",
       "\u001b[32mtasks, including language modeling and question answering.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.56</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.56\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the differences in representation learning and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">neural network architectures between word embeddings and sentence embeddings, particularly in natural language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">processing tasks?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the differences in representation learning and \u001b[0m\n",
       "\u001b[32mneural network architectures between word embeddings and sentence embeddings, particularly in natural language \u001b[0m\n",
       "\u001b[32mprocessing tasks?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4594</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4594\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Association for Computational Linguistics.                                                       │\n",
       "│ Kyunghyun Cho, Bart van Merriënboer, Caglar Gul-                                                 │\n",
       "│ cehre, Dzmitry Bahdanau, Fethi Bougares, Holger                                                  │\n",
       "│ Schwenk, a...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Association for Computational Linguistics.                                                       │\n",
       "│ Kyunghyun Cho, Bart van Merriënboer, Caglar Gul-                                                 │\n",
       "│ cehre, Dzmitry Bahdanau, Fethi Bougares, Holger                                                  │\n",
       "│ Schwenk, a...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4499</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4499\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of expertise for working with language data and systems. We conclude by discussing               │\n",
       "│ pertinent challenges for the NLP community which involve linguistic...                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of expertise for working with language data and systems. We conclude by discussing               │\n",
       "│ pertinent challenges for the NLP community which involve linguistic...                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2405.05966v4_Natural_Language_Processing_RELIES_on_Linguistics</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2405.05966v4_Natural_Language_Processing_RELIES_on_Linguistics\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4322</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4322\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ decrease in training time on all the datasets. On                                                │\n",
       "│ the contrary, fastText and CNN are very fast while                                               │\n",
       "│ training the NN model. The training time of such                                                 │\n",
       "│ ...                                                                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ decrease in training time on all the datasets. On                                                │\n",
       "│ the contrary, fastText and CNN are very fast while                                               │\n",
       "│ training the NN model. The training time of such                                                 │\n",
       "│ ...                                                                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2101.09009v1_Does_a_Hybrid_Neural_Network_based_Feature_Selecti</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2101.09009v1_Does_a_Hybrid_Neural_Network_based_Feature_Selecti\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4303</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4303\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Model. In A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,          │\n",
       "│ Advances in Neural Information Processing Systems, volume 36, ...                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Model. In A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,          │\n",
       "│ Advances in Neural Information Processing Systems, volume 36, ...                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4174</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4174\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of large training data by facilitating pre-trained word embeddings and offered                   │\n",
       "│ more comprehensive representations as compared to one hot vector and TF...                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ of large training data by facilitating pre-trained word embeddings and offered                   │\n",
       "│ more comprehensive representations as compared to one hot vector and TF...                       │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Word embeddings and sentence embeddings are two types of representations used in natural         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> language processing (NLP) to capture semantic relationships between words or sentences.          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Word embeddings, such as those provided by pre-trained word embeddings like BERT (Devlin et al., <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2019), represent words as vectors in a high-dimensional space. These vectors capture the         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> semantic meaning of words based on their co-occurrence patterns in large corpora (Mikolov et     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> al., 2013). Word embeddings are typically used for tasks such as text classification, sentiment  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> analysis, and language modeling.                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> On the other hand, sentence embeddings represent entire sentences or phrases as vectors.         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Sentence embeddings can be obtained using various techniques, including contrastive learning     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> (Nils Reimers and Iryna Gurevych, 2019) and in-context retrieval-Augmented language models (Ori  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Ram et al., 2023). These representations capture the semantic meaning of entire sentences or     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> phrases, which is useful for tasks such as question answering, text classification, and          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> information retrieval.                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> While both word embeddings and sentence embeddings are used in NLP, they serve different         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> purposes. Word embeddings focus on capturing the semantic meaning of individual words, whereas   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> sentence embeddings aim to capture the semantic meaning of entire sentences or phrases.          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In recent years, there has been a growing interest in using pre-trained language models for      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> various NLP tasks. These models have achieved state-of-the-art performance on many tasks,        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> including text classification, sentiment analysis, and question answering (Colin Raffel et al.,  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 2020). However, the use of these models often relies on large amounts of labeled data, which can <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> be time-consuming and expensive to obtain.                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> To address this limitation, researchers have been exploring alternative approaches, such as      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in-context retrieval-Augmented language models (Ori Ram et al., 2023) and contrastive            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning-based methods (Nils Reimers and Iryna Gurevych, 2019). These approaches aim to leverage <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> large unlabeled corpora to learn more comprehensive representations of words and sentences.      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2405.05966v4_Natural_Language_Processing_RELIES_on_Linguistics          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2101.09009v1_Does_a_Hybrid_Neural_Network_based_Feature_Selecti         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Word embeddings and sentence embeddings are two types of representations used in natural         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m language processing (NLP) to capture semantic relationships between words or sentences.          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Word embeddings, such as those provided by pre-trained word embeddings like BERT (Devlin et al., \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2019), represent words as vectors in a high-dimensional space. These vectors capture the         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m semantic meaning of words based on their co-occurrence patterns in large corpora (Mikolov et     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m al., 2013). Word embeddings are typically used for tasks such as text classification, sentiment  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m analysis, and language modeling.                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m On the other hand, sentence embeddings represent entire sentences or phrases as vectors.         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Sentence embeddings can be obtained using various techniques, including contrastive learning     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m (Nils Reimers and Iryna Gurevych, 2019) and in-context retrieval-Augmented language models (Ori  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Ram et al., 2023). These representations capture the semantic meaning of entire sentences or     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m phrases, which is useful for tasks such as question answering, text classification, and          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m information retrieval.                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m While both word embeddings and sentence embeddings are used in NLP, they serve different         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m purposes. Word embeddings focus on capturing the semantic meaning of individual words, whereas   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m sentence embeddings aim to capture the semantic meaning of entire sentences or phrases.          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In recent years, there has been a growing interest in using pre-trained language models for      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m various NLP tasks. These models have achieved state-of-the-art performance on many tasks,        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m including text classification, sentiment analysis, and question answering (Colin Raffel et al.,  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 2020). However, the use of these models often relies on large amounts of labeled data, which can \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m be time-consuming and expensive to obtain.                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m To address this limitation, researchers have been exploring alternative approaches, such as      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in-context retrieval-Augmented language models (Ori Ram et al., 2023) and contrastive            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning-based methods (Nils Reimers and Iryna Gurevych, 2019). These approaches aim to leverage \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m large unlabeled corpora to learn more comprehensive representations of words and sentences.      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2109.03888v1_Sparsity_and_Sentence_Structure_in_Encoder-Decoder         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2405.05966v4_Natural_Language_Processing_RELIES_on_Linguistics          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2101.09009v1_Does_a_Hybrid_Neural_Network_based_Feature_Selecti         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, with specific technical terms <span style=\"font-weight: bold\">(</span>transfer learning, NLP<span style=\"font-weight: bold\">)</span>. It is focused \n",
       "on retrieving scientific content related to machine learning and natural language processing. However, it may not \n",
       "be highly retrievable due to the lack of specificity in the context or application area.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, with specific technical terms \u001b[1m(\u001b[0mtransfer learning, NLP\u001b[1m)\u001b[0m. It is focused \n",
       "on retrieving scientific content related to machine learning and natural language processing. However, it may not \n",
       "be highly retrievable due to the lack of specificity in the context or application area.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What is transfer learning nlp?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What is transfer learning nlp?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Discuss the relationship between transfer learning, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">domain adaptation, and multi-task learning in NLP applications, including their advantages and challenges.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Discuss the relationship between transfer learning, \u001b[0m\n",
       "\u001b[32mdomain adaptation, and multi-task learning in NLP applications, including their advantages and challenges.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.76</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.76\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the concept of transfer learning in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural language processing (NLP) and its applications in deep learning models.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"Examine the concept of transfer learning in \u001b[0m\n",
       "\u001b[32mnatural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and its applications in deep learning models.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.76</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.76\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways does the choice of pre-training dataset</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">influence the effectiveness of transfer learning in NLP tasks? How do different datasets impact model performance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and generalizability?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways does the choice of pre-training dataset\u001b[0m\n",
       "\u001b[32minfluence the effectiveness of transfer learning in NLP tasks? How do different datasets impact model performance \u001b[0m\n",
       "\u001b[32mand generalizability?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.70</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.70\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does pre-training on a large corpus affect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance of fine-tuned NLP models? What role do transfer learning techniques play in improving model accuracy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and reducing overfitting?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does pre-training on a large corpus affect the \u001b[0m\n",
       "\u001b[32mperformance of fine-tuned NLP models? What role do transfer learning techniques play in improving model accuracy \u001b[0m\n",
       "\u001b[32mand reducing overfitting?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.69</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.69\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between transfer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning, neural network architecture (e.g., BERT, RoBERTa), and optimization algorithms (e.g., Adam, SGD) on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convergence of training objectives and NLP task performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between transfer \u001b[0m\n",
       "\u001b[32mlearning, neural network architecture \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., BERT, RoBERTa\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the \u001b[0m\n",
       "\u001b[32mconvergence of training objectives and NLP task performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.65</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.65\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"Examine the concept of transfer learning in natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing (NLP) and its applications in deep learning models.\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"Examine the concept of transfer learning in natural \u001b[0m\n",
       "\u001b[32mlanguage processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and its applications in deep learning models.\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5277</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5277\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Preprint, Preprint Alireza Salemi and Hamed Zamani                                               │\n",
       "│ [32] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,                     │\n",
       "│ Michael Matena, Yanqi ...                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Preprint, Preprint Alireza Salemi and Hamed Zamani                                               │\n",
       "│ [32] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,                     │\n",
       "│ Michael Matena, Yanqi ...                                                                        │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2410.09942v1_Learning_to_Rank_for_Multiple_Retrieval-Augmented_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2410.09942v1_Learning_to_Rank_for_Multiple_Retrieval-Augmented_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4761</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4761\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Model. In A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,          │\n",
       "│ Advances in Neural Information Processing Systems, volume 36, ...                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Model. In A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,          │\n",
       "│ Advances in Neural Information Processing Systems, volume 36, ...                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4681</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4681\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ performance  on  a  task  has  a  lot  of  promise  and  remains  under-explored  at  the        │\n",
       "│ moment.  It                                                                                      │\n",
       "│  points  out  that  there  has  been  a  lot  ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ performance  on  a  task  has  a  lot  of  promise  and  remains  under-explored  at  the        │\n",
       "│ moment.  It                                                                                      │\n",
       "│  points  out  that  there  has  been  a  lot  ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2202.07435v1_State_of_AI_Ethics_Report_(Volume_6,_February_2022</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2202.07435v1_State_of_AI_Ethics_Report_\u001b[0m\u001b[2;4;94m(\u001b[0m\u001b[2;4;94mVolume_6,_February_2022\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4486</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4486\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ proaches have been proposed, including template-                                                 │\n",
       "│ based (Becker, 2002; Van Deemter et al., 2005),                                                  │\n",
       "│ rule-based (Dušek and Jurˇcíˇcek, 2015; van Milten-                                              │\n",
       "│ b...                                                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ proaches have been proposed, including template-                                                 │\n",
       "│ based (Becker, 2002; Van Deemter et al., 2005),                                                  │\n",
       "│ rule-based (Dušek and Jurˇcíˇcek, 2015; van Milten-                                              │\n",
       "│ b...                                                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2401.01053v3_Cheetah:_Natural_Language_Generation_for_517_Afric</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2401.01053v3_Cheetah:_Natural_Language_Generation_for_517_Afric\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4326</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4326\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ ArXiv:2311.08273 .                                                                               │\n",
       "│ Kevin Clark, Urvashi Khandelwal, Omer Levy, and                                                  │\n",
       "│ Christopher D. Manning. 2019. What does BERT                                                     │\n",
       "│ look at? an analysis of BERT’s att...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ ArXiv:2311.08273 .                                                                               │\n",
       "│ Kevin Clark, Urvashi Khandelwal, Omer Levy, and                                                  │\n",
       "│ Christopher D. Manning. 2019. What does BERT                                                     │\n",
       "│ look at? an analysis of BERT’s att...                                                            │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2410.13396v2_Linguistically_Grounded_Analysis_of_Language_Model</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2410.13396v2_Linguistically_Grounded_Analysis_of_Language_Model\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Transfer learning in NLP refers to the practice of using a pre-trained model as a starting point <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for training a new model on a specific task or dataset. This approach leverages the knowledge    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and features learned by the pre-trained model on a large, diverse dataset, such as ImageNet, and <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> fine-tunes them for the new task (Source: Document 3).                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The idea is that the pre-trained model has already learned general representations of language   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> patterns, objects, and concepts, which can be adapted to specific tasks like text                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> classification, sentiment analysis, or machine translation. By fine-tuning the pre-trained model <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> on a smaller dataset related to the new task, researchers can improve its performance on that    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> task while retaining the knowledge gained from the pre-training phase (Source: Document 4).      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, it's worth noting that transfer learning is not without limitations. If there is        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> limited overlap between the new task and the pre-trained model's domain, performance may suffer  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> (Source: Document 3). Additionally, some researchers have raised concerns about the lack of      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> transparency and interpretability in transfer learning models, highlighting the need for further <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> research in this area (Source: Document 5).                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Transfer learning has gained significant attention in recent years due to its potential to       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> improve performance on tasks with limited training data. By leveraging pre-trained models,       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> researchers can reduce the amount of data required for training, making it a promising approach  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> for low-resource languages and domains.                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, transfer learning also raises important questions about the quality and diversity of    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> the pre-training datasets. For instance, some pre-trained models may have been trained on biased <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> or incomplete datasets, which can affect their performance on certain tasks (Source: Document    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> 5).                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Furthermore, the use of transfer learning has sparked debates about the ownership and            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> intellectual property rights surrounding pre-trained models. As these models become increasingly <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> popular, researchers and developers are grappling with issues related to model sharing,          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> licensing, and collaboration (Source: Document 4).                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2410.09942v1_Learning_to_Rank_for_Multiple_Retrieval-Augmented_         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2202.07435v1_State_of_AI_Ethics_Report_(Volume_6,_February_2022)        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2401.01053v3_Cheetah:_Natural_Language_Generation_for_517_Afric         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5: https://arxiv.org/pdf/2311.08273 [cs]                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Transfer learning in NLP refers to the practice of using a pre-trained model as a starting point \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for training a new model on a specific task or dataset. This approach leverages the knowledge    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and features learned by the pre-trained model on a large, diverse dataset, such as ImageNet, and \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m fine-tunes them for the new task (Source: Document 3).                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The idea is that the pre-trained model has already learned general representations of language   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m patterns, objects, and concepts, which can be adapted to specific tasks like text                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m classification, sentiment analysis, or machine translation. By fine-tuning the pre-trained model \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m on a smaller dataset related to the new task, researchers can improve its performance on that    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m task while retaining the knowledge gained from the pre-training phase (Source: Document 4).      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, it's worth noting that transfer learning is not without limitations. If there is        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m limited overlap between the new task and the pre-trained model's domain, performance may suffer  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m (Source: Document 3). Additionally, some researchers have raised concerns about the lack of      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m transparency and interpretability in transfer learning models, highlighting the need for further \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m research in this area (Source: Document 5).                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Transfer learning has gained significant attention in recent years due to its potential to       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m improve performance on tasks with limited training data. By leveraging pre-trained models,       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m researchers can reduce the amount of data required for training, making it a promising approach  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m for low-resource languages and domains.                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, transfer learning also raises important questions about the quality and diversity of    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m the pre-training datasets. For instance, some pre-trained models may have been trained on biased \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m or incomplete datasets, which can affect their performance on certain tasks (Source: Document    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m 5).                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Furthermore, the use of transfer learning has sparked debates about the ownership and            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m intellectual property rights surrounding pre-trained models. As these models become increasingly \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m popular, researchers and developers are grappling with issues related to model sharing,          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m licensing, and collaboration (Source: Document 4).                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2410.09942v1_Learning_to_Rank_for_Multiple_Retrieval-Augmented_         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2411.18947v1_ICLERB:_In-Context_Learning_Embedding_and_Reranker         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2202.07435v1_State_of_AI_Ethics_Report_(Volume_6,_February_2022)        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2401.01053v3_Cheetah:_Natural_Language_Generation_for_517_Afric         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5: https://arxiv.org/pdf/2311.08273 [cs]                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, asking about the challenges of named entity recognition. It contains \n",
       "specific technical terms <span style=\"font-weight: bold\">(</span>named entity recognition<span style=\"font-weight: bold\">)</span> and is focused on retrieving scientific content. However, it \n",
       "lacks specificity in terms of the context or domain <span style=\"font-weight: bold\">(</span>e.g., NER in NLP, bioinformatics, etc.<span style=\"font-weight: bold\">)</span>, which might limit its\n",
       "retrievability with vector search.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, asking about the challenges of named entity recognition. It contains \n",
       "specific technical terms \u001b[1m(\u001b[0mnamed entity recognition\u001b[1m)\u001b[0m and is focused on retrieving scientific content. However, it \n",
       "lacks specificity in terms of the context or domain \u001b[1m(\u001b[0me.g., NER in NLP, bioinformatics, etc.\u001b[1m)\u001b[0m, which might limit its\n",
       "retrievability with vector search.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: named entity recognition hard why?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: named entity recognition hard why?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the challenges and limitations of named </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">entity recognition (NER) in natural language processing (NLP), and why is it considered hard?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the challenges and limitations of named \u001b[0m\n",
       "\u001b[32mentity recognition \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNER\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and why is it considered hard?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.62</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.62\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the relationship between named entity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recognition, information extraction, and text summarization in the context of NLP applications, including their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strengths, weaknesses, and potential applications.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the relationship between named entity \u001b[0m\n",
       "\u001b[32mrecognition, information extraction, and text summarization in the context of NLP applications, including their \u001b[0m\n",
       "\u001b[32mstrengths, weaknesses, and potential applications.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the impact of deep learning architectures </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., CNNs, RNNs) on named entity recognition performance, including the effects of feature extraction, attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mechanisms, and optimization algorithms (e.g., Adam, SGD) on model accuracy and robustness.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the impact of deep learning architectures \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., CNNs, RNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on named entity recognition performance, including the effects of feature extraction, attention \u001b[0m\n",
       "\u001b[32mmechanisms, and optimization algorithms \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on model accuracy and robustness.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.59</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.59\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do the trade-offs between precision, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recall, and F1-score affect the difficulty of NER tasks? How can these trade-offs be optimized for different NLP </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do the trade-offs between precision, \u001b[0m\n",
       "\u001b[32mrecall, and F1-score affect the difficulty of NER tasks? How can these trade-offs be optimized for different NLP \u001b[0m\n",
       "\u001b[32mapplications?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the complexity of NER tasks affect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance of machine learning models? What are the key factors contributing to the difficulty of NER, such as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data quality, model architecture, and training algorithms?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the complexity of NER tasks affect the \u001b[0m\n",
       "\u001b[32mperformance of machine learning models? What are the key factors contributing to the difficulty of NER, such as \u001b[0m\n",
       "\u001b[32mdata quality, model architecture, and training algorithms?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.33</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.33\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the challenges and limitations of named entity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recognition (NER) in natural language processing (NLP), and why is it considered hard?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the challenges and limitations of named entity \u001b[0m\n",
       "\u001b[32mrecognition \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNER\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and why is it considered hard?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4574</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4574\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ information extraction [77], software requirements classification [62], use case                 │\n",
       "│ diagram generation and topic modeling [78, 79]. This section briefly ...                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ information extraction [77], software requirements classification [62], use case                 │\n",
       "│ diagram generation and topic modeling [78, 79]. This section briefly ...                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4523</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4523\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ B.F.: aerobert-ner: Named-entity recognition for aerospace requirements                          │\n",
       "│ engineering using bert. In: AIAA SCITECH 2023 Forum, p. 2583 (2023)                              │\n",
       "│ [98] Chow,...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ B.F.: aerobert-ner: Named-entity recognition for aerospace requirements                          │\n",
       "│ engineering using bert. In: AIAA SCITECH 2023 Forum, p. 2583 (2023)                              │\n",
       "│ [98] Chow,...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4304</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4304\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ NLP research papers following the taxonomy we                                                    │\n",
       "│ developed in § 3.1. The goal of this annotation                                                  │\n",
       "│ scheme is to annotate contribution statements                                                    │\n",
       "│ from the a...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ NLP research papers following the taxonomy we                                                    │\n",
       "│ developed in § 3.1. The goal of this annotation                                                  │\n",
       "│ scheme is to annotate contribution statements                                                    │\n",
       "│ from the a...                                                                                    │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2409.19505v1_The_Nature_of_NLP:_Analyzing_Contributions_in_NLP_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2409.19505v1_The_Nature_of_NLP:_Analyzing_Contributions_in_NLP_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4026</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4026\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 2 Event Extraction                                                                               │\n",
       "│ 2.1 Event Extraction Task Deﬁnition                                                              │\n",
       "│ As a particular form of information, event extraction involves named entity recognition (NER)    │\n",
       "│ a...                                                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 2 Event Extraction                                                                               │\n",
       "│ 2.1 Event Extraction Task Deﬁnition                                                              │\n",
       "│ As a particular form of information, event extraction involves named entity recognition (NER)    │\n",
       "│ a...                                                                                             │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2111.03212v1_An_overview_of_event_extraction_and_its_applicatio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2111.03212v1_An_overview_of_event_extraction_and_its_applicatio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3991</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3991\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ studies across distinct types of requirement engineering tasks [60, 87, 128].                    │\n",
       "│ Specifically, potential of BERT language model is harnessed to develop r...                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ studies across distinct types of requirement engineering tasks [60, 87, 128].                    │\n",
       "│ Specifically, potential of BERT language model is harnessed to develop r...                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Named entity recognition (NER) is a challenging task in natural language processing (NLP), and   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> its difficulty can be attributed to various factors. According to Document 1, NER has been       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> applied to several tasks, including software requirements classification, use case diagram       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> generation, and topic modeling [77]. The study also highlights the potential of BERT language    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> models for NER tagging of requirements, with researchers exploring the capabilities of six       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> different language models, including RoBerta, Electra, DistilBERT, MiniLM, Albert, and BERT      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> [71].                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, despite these advancements, there is still a lack of scientific studies focusing on the <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> exploration of Generative Language Models (GLMs) potential in software systems field [56–59].    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> This suggests that while GLMs have shown promise for NER tasks, further research is needed to    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> fully understand their capabilities and limitations.                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition, Document 3 provides insight into the taxonomy developed for annotating contribution <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> statements from NLP research papers. The study highlights the importance of identifying          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> contributions in various categories, including artifact creation [A.1.1 Type: Artifact]. This    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> category includes the creation of new resources such as datasets, models, or algorithms, which   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> play a crucial role in NLP research.                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Named entity recognition is a fundamental task in NLP that involves identifying and categorizing <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> named entities in unstructured text data. The difficulty of NER lies in its complexity, which    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> can be attributed to various factors, including the presence of ambiguity, context dependence,   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> and linguistic variability. While advancements in deep learning models have improved the         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> performance of NER tasks, there is still room for improvement, particularly in handling          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> out-of-vocabulary words, domain adaptation, and multi-task learning.                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The study highlights the potential of BERT language models for NER tagging, but it also          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> underscores the need for further research to fully understand their capabilities and             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> limitations. This includes exploring the use of GLMs for software systems field, which has been  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> relatively under-explored compared to other applications.                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2409.19505v1_The_Nature_of_NLP:<span style=\"font-style: italic\">Analyzing_Contributions_in_NLP</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2111.03212v1_An_overview_of_event_extraction_and_its_applicatio         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Named entity recognition (NER) is a challenging task in natural language processing (NLP), and   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m its difficulty can be attributed to various factors. According to Document 1, NER has been       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m applied to several tasks, including software requirements classification, use case diagram       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m generation, and topic modeling [77]. The study also highlights the potential of BERT language    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m models for NER tagging of requirements, with researchers exploring the capabilities of six       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m different language models, including RoBerta, Electra, DistilBERT, MiniLM, Albert, and BERT      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m [71].                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, despite these advancements, there is still a lack of scientific studies focusing on the \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m exploration of Generative Language Models (GLMs) potential in software systems field [56–59].    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m This suggests that while GLMs have shown promise for NER tasks, further research is needed to    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m fully understand their capabilities and limitations.                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition, Document 3 provides insight into the taxonomy developed for annotating contribution \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m statements from NLP research papers. The study highlights the importance of identifying          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m contributions in various categories, including artifact creation [A.1.1 Type: Artifact]. This    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m category includes the creation of new resources such as datasets, models, or algorithms, which   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m play a crucial role in NLP research.                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Named entity recognition is a fundamental task in NLP that involves identifying and categorizing \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m named entities in unstructured text data. The difficulty of NER lies in its complexity, which    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m can be attributed to various factors, including the presence of ambiguity, context dependence,   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m and linguistic variability. While advancements in deep learning models have improved the         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m performance of NER tasks, there is still room for improvement, particularly in handling          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m out-of-vocabulary words, domain adaptation, and multi-task learning.                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The study highlights the potential of BERT language models for NER tagging, but it also          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m underscores the need for further research to fully understand their capabilities and             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m limitations. This includes exploring the use of GLMs for software systems field, which has been  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m relatively under-explored compared to other applications.                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2409.19505v1_The_Nature_of_NLP:\u001b[3mAnalyzing_Contributions_in_NLP\u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2111.03212v1_An_overview_of_event_extraction_and_its_applicatio         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2412.00959v1_Generative_Language_Models_Potential_for_Requireme         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, but lacks specificity. It uses a general term <span style=\"color: #008000; text-decoration-color: #008000\">'perplexity'</span> which could\n",
       "refer to multiple concepts in NLP, such as perplexity score or perplexity measure. Adding more specific terms like \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'language model perplexity score'</span> would improve the query's clarity and relevance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, but lacks specificity. It uses a general term \u001b[32m'perplexity'\u001b[0m which could\n",
       "refer to multiple concepts in NLP, such as perplexity score or perplexity measure. Adding more specific terms like \n",
       "\u001b[32m'language model perplexity score'\u001b[0m would improve the query's clarity and relevance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: language model perplexity mean?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: language model perplexity mean?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"[Rewritten query text] What is the mathematical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition and formula for calculating language model perplexity mean in terms of probability theory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information entropy?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRewritten query text\u001b[0m\u001b[32m]\u001b[0m\u001b[32m What is the mathematical \u001b[0m\n",
       "\u001b[32mdefinition and formula for calculating language model perplexity mean in terms of probability theory and \u001b[0m\n",
       "\u001b[32minformation entropy?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.70</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.70\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does the calculation of language model perplexity</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relate to the concept of negative log likelihood (NLL) in machine learning? What are the implications of using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different metrics, such as perplexity or NLL, for evaluating language model performance?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does the calculation of language model perplexity\u001b[0m\n",
       "\u001b[32mrelate to the concept of negative log likelihood \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in machine learning? What are the implications of using \u001b[0m\n",
       "\u001b[32mdifferent metrics, such as perplexity or NLL, for evaluating language model performance?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.64</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.64\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do changes in language model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architecture (e.g., transformer vs. recurrent neural network) affect the mean perplexity of trained models? How do </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these changes impact the trade-off between fluency, coherence, and semantic accuracy?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do changes in language model \u001b[0m\n",
       "\u001b[32marchitecture \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., transformer vs. recurrent neural network\u001b[0m\u001b[32m)\u001b[0m\u001b[32m affect the mean perplexity of trained models? How do \u001b[0m\n",
       "\u001b[32mthese changes impact the trade-off between fluency, coherence, and semantic accuracy?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.61</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.61\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the relationship between language model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perplexity mean and other evaluation metrics, such as accuracy, F1-score, and ROUGE score, in assessing the quality</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and effectiveness of natural language processing models.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the relationship between language model \u001b[0m\n",
       "\u001b[32mperplexity mean and other evaluation metrics, such as accuracy, F1-score, and ROUGE score, in assessing the quality\u001b[0m\n",
       "\u001b[32mand effectiveness of natural language processing models.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.60</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.60\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"[Rewritten query text] Investigate the causal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationship between the hyperparameter tuning of language model perplexity mean and the optimization algorithms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used (e.g., Adam, SGD) in training large-scale language models, including their impact on convergence rates and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model performance metrics.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRewritten query text\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Investigate the causal \u001b[0m\n",
       "\u001b[32mrelationship between the hyperparameter tuning of language model perplexity mean and the optimization algorithms \u001b[0m\n",
       "\u001b[32mused \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m in training large-scale language models, including their impact on convergence rates and \u001b[0m\n",
       "\u001b[32mmodel performance metrics.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.55</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.55\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"[Rewritten query text] What is the mathematical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">definition and formula for calculating language model perplexity mean in terms of probability theory and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information entropy?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mRewritten query text\u001b[0m\u001b[32m]\u001b[0m\u001b[32m What is the mathematical \u001b[0m\n",
       "\u001b[32mdefinition and formula for calculating language model perplexity mean in terms of probability theory and \u001b[0m\n",
       "\u001b[32minformation entropy?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3496</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3496\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and information [5, 7–9] establish a foundational relation ship between information processing   │\n",
       "│ and thermodynamic                                                                                │\n",
       "│ principles. Kostic’s and Koczan’s rec...                                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ and information [5, 7–9] establish a foundational relation ship between information processing   │\n",
       "│ and thermodynamic                                                                                │\n",
       "│ principles. Kostic’s and Koczan’s rec...                                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3155</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3155\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ B. Modeling                                                                                      │\n",
       "│ Relativeness.W e consider that if the EoI are mentioned in                                       │\n",
       "│ a document many times, the document should receive a high                                        │\n",
       "│ score since its topic...                                                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ B. Modeling                                                                                      │\n",
       "│ Relativeness.W e consider that if the EoI are mentioned in                                       │\n",
       "│ a document many times, the document should receive a high                                        │\n",
       "│ score since its topic...                                                                         │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1810.11049v1_Towards_a_Ranking_Model_for_Semantic_Layers_over_D</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1810.11049v1_Towards_a_Ranking_Model_for_Semantic_Layers_over_D\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3129</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3129\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ BIBLIOGRAPHY 203                                                                                 │\n",
       "│ [84] Alexander Grothendieck. Formule de lefschetz et rationalité des fonctions $l$.              │\n",
       "│ 1966.                                                                                            │\n",
       "│ [85] Alexandre Grothendieck. Sur quelques p...                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ BIBLIOGRAPHY 203                                                                                 │\n",
       "│ [84] Alexander Grothendieck. Formule de lefschetz et rationalité des fonctions $l$.              │\n",
       "│ 1966.                                                                                            │\n",
       "│ [85] Alexandre Grothendieck. Sur quelques p...                                                   │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2408.07402v1_A_Quantum-Inspired_Analysis_of_Human_Disambiguatio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2408.07402v1_A_Quantum-Inspired_Analysis_of_Human_Disambiguatio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3045</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3045\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Deﬁnition 4.1. A language model over the monoidal grammar G is the following                     │\n",
       "│ family of probability distributions:                                                             │\n",
       "│ •For any preﬁx w1 ⊗...wn, a probabil...                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Deﬁnition 4.1. A language model over the monoidal grammar G is the following                     │\n",
       "│ family of probability distributions:                                                             │\n",
       "│ •For any preﬁx w1 ⊗...wn, a probabil...                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2001.02296v2_Incremental_Monoidal_Grammars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2001.02296v2_Incremental_Monoidal_Grammars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.2915</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.2915\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ If any NP-complete problem can be solved in polynomial time, then every problem in /u1D441       │\n",
       "│ /u1D443can also be solved in                                                                     │\n",
       "│ polynomial time, implying /u1D...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ If any NP-complete problem can be solved in polynomial time, then every problem in /u1D441       │\n",
       "│ /u1D443can also be solved in                                                                     │\n",
       "│ polynomial time, implying /u1D...                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The term \"perplexity\" in the context of language models refers to a measure of how well a model  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> predicts a given sequence of words. It is calculated as the negative logarithm of the            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> probability of the sequence, with lower values indicating better performance.                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In the context of language models, perplexity can be understood through the lens of entropy,     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> which measures the unpredictability or uncertainty of a random variable. The concept of entropy  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in information theory, as described by Claude Shannon, provides a mathematical framework for     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> studying and quantifying information (Source: Document 5).                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Perplexity is closely related to the idea of \"hardness\" or unpredictability of a problem, as     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> discussed in the context of computational complexity and thermodynamic principles (Source:       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Document 1). In other words, lower perplexity values indicate that the language model can better <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> predict the sequence of words, which implies a lower level of uncertainty or unpredictability.   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> The concept of perplexity is also related to the idea of \"relativeness\" in documents, as         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> discussed in Document 2. The relativeness score of a document can be defined as the number of    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> occurrences of entities mentioned in the document, divided by the total number of entities       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mentioned (Source: Document 2). This score can be used to measure the relevance of a document to <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a particular topic or entity.                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Perplexity is an important metric in natural language processing and machine learning, as it     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> provides a quantitative measure of a model's performance. In the context of language models,     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> perplexity is often used as a surrogate for understanding, with lower values indicating better   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> performance (Source: Document 3). The concept of perplexity is also related to the idea of       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> \"uncertainty\" or \"surprise\" in information theory, which provides a mathematical framework for   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> studying and quantifying information.                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition, the concept of perplexity is closely related to the idea of computational           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> complexity and thermodynamic principles. The study of perplexity can provide insights into the   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> fundamental limits of computation and the nature of uncertainty in complex systems (Source:      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Document 1).                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1810.11049v1_Towards_a_Ranking_Model_for_Semantic_Layers_over_D         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2408.07402v1_A_Quantum-Inspired_Analysis_of_Human_Disambiguatio         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4: https://arxiv.org/pdf/2001.02296v2_Incremental_Monoidal_Grammars                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The term \"perplexity\" in the context of language models refers to a measure of how well a model  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m predicts a given sequence of words. It is calculated as the negative logarithm of the            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m probability of the sequence, with lower values indicating better performance.                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In the context of language models, perplexity can be understood through the lens of entropy,     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m which measures the unpredictability or uncertainty of a random variable. The concept of entropy  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in information theory, as described by Claude Shannon, provides a mathematical framework for     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m studying and quantifying information (Source: Document 5).                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Perplexity is closely related to the idea of \"hardness\" or unpredictability of a problem, as     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m discussed in the context of computational complexity and thermodynamic principles (Source:       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Document 1). In other words, lower perplexity values indicate that the language model can better \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m predict the sequence of words, which implies a lower level of uncertainty or unpredictability.   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m The concept of perplexity is also related to the idea of \"relativeness\" in documents, as         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m discussed in Document 2. The relativeness score of a document can be defined as the number of    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m occurrences of entities mentioned in the document, divided by the total number of entities       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mentioned (Source: Document 2). This score can be used to measure the relevance of a document to \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a particular topic or entity.                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Perplexity is an important metric in natural language processing and machine learning, as it     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m provides a quantitative measure of a model's performance. In the context of language models,     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m perplexity is often used as a surrogate for understanding, with lower values indicating better   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m performance (Source: Document 3). The concept of perplexity is also related to the idea of       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \"uncertainty\" or \"surprise\" in information theory, which provides a mathematical framework for   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m studying and quantifying information.                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition, the concept of perplexity is closely related to the idea of computational           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m complexity and thermodynamic principles. The study of perplexity can provide insights into the   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m fundamental limits of computation and the nature of uncertainty in complex systems (Source:      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Document 1).                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1810.11049v1_Towards_a_Ranking_Model_for_Semantic_Layers_over_D         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2408.07402v1_A_Quantum-Inspired_Analysis_of_Human_Disambiguatio         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4: https://arxiv.org/pdf/2001.02296v2_Incremental_Monoidal_Grammars                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2401.08668v3_Thermodynamic_Perspectives_on_Computational_Comple         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, making it easy to understand. It contains the specific technical term \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'few-shot learning'</span>, which indicates a strong focus on retrieving scientific content related to machine learning \n",
       "and artificial intelligence. However, it lacks specificity in terms of the context or application area <span style=\"font-weight: bold\">(</span>e.g., image\n",
       "classification, natural language processing<span style=\"font-weight: bold\">)</span>, which might limit its ability to retrieve highly relevant results. \n",
       "Additionally, while the query is clear, it may not be optimized for vector search, as it does not contain any \n",
       "specific keywords related to text representation or embedding.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, making it easy to understand. It contains the specific technical term \n",
       "\u001b[32m'few-shot learning'\u001b[0m, which indicates a strong focus on retrieving scientific content related to machine learning \n",
       "and artificial intelligence. However, it lacks specificity in terms of the context or application area \u001b[1m(\u001b[0me.g., image\n",
       "classification, natural language processing\u001b[1m)\u001b[0m, which might limit its ability to retrieve highly relevant results. \n",
       "Additionally, while the query is clear, it may not be optimized for vector search, as it does not contain any \n",
       "specific keywords related to text representation or embedding.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: What is few shot learning?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: What is few shot learning?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: **Adding technical terminology for specificity**: <span style=\"color: #008000; text-decoration-color: #008000\">\"What are the applications and theoretical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">foundations of few-shot learning in deep learning, particularly in relation to meta-learning and neural network </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architectures?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m1\u001b[0m: **Adding technical terminology for specificity**: \u001b[32m\"What are the applications and theoretical \u001b[0m\n",
       "\u001b[32mfoundations of few-shot learning in deep learning, particularly in relation to meta-learning and neural network \u001b[0m\n",
       "\u001b[32marchitectures?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.71</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.71\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: **Decomposition into multiple sub-questions**: <span style=\"color: #008000; text-decoration-color: #008000\">\"How does few-shot learning differ from traditional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">supervised learning and unsupervised learning methods? What are the key challenges and opportunities in applying </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">few-shot learning to natural language processing tasks?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m2\u001b[0m: **Decomposition into multiple sub-questions**: \u001b[32m\"How does few-shot learning differ from traditional \u001b[0m\n",
       "\u001b[32msupervised learning and unsupervised learning methods? What are the key challenges and opportunities in applying \u001b[0m\n",
       "\u001b[32mfew-shot learning to natural language processing tasks?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.69</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.69\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: **Focusing on a specific aspect or trade-off**: <span style=\"color: #008000; text-decoration-color: #008000\">\"In what ways do different optimization algorithms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(e.g., Adam, SGD) impact the performance of few-shot learning models, particularly in terms of convergence speed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and generalization ability?\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m3\u001b[0m: **Focusing on a specific aspect or trade-off**: \u001b[32m\"In what ways do different optimization algorithms \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32me.g., Adam, SGD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m impact the performance of few-shot learning models, particularly in terms of convergence speed \u001b[0m\n",
       "\u001b[32mand generalization ability?\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.68</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.68\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: **Specifying key entities and relationships**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the causal relationship between few-shot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learning protocols (e.g., meta-learning, self-supervised learning), neural network architectures (e.g., CNNs, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RNNs), and evaluation metrics (e.g., accuracy, F1-score) on the performance of deep learning models in low-data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regimes.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m4\u001b[0m: **Specifying key entities and relationships**: \u001b[32m\"Analyze the causal relationship between few-shot \u001b[0m\n",
       "\u001b[32mlearning protocols \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., meta-learning, self-supervised learning\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, neural network architectures \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., CNNs, \u001b[0m\n",
       "\u001b[32mRNNs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and evaluation metrics \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., accuracy, F1-score\u001b[0m\u001b[32m)\u001b[0m\u001b[32m on the performance of deep learning models in low-data \u001b[0m\n",
       "\u001b[32mregimes.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Confidence: </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.62</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;33mConfidence: \u001b[0m\u001b[1;33m0.62\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">.</span> Rewrite <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: **Expanding the query with related concepts**: <span style=\"color: #008000; text-decoration-color: #008000\">\"Examine the relationship between few-shot learning, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transfer learning, and domain adaptation in deep neural networks, including case studies on image classification </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and sentiment analysis.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m\u001b[1m.\u001b[0m Rewrite \u001b[1;36m5\u001b[0m: **Expanding the query with related concepts**: \u001b[32m\"Examine the relationship between few-shot learning, \u001b[0m\n",
       "\u001b[32mtransfer learning, and domain adaptation in deep neural networks, including case studies on image classification \u001b[0m\n",
       "\u001b[32mand sentiment analysis.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Confidence: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.58</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;31mConfidence: \u001b[0m\u001b[1;31m0.58\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: multiple queries this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Query:</span> <span style=\"color: #008000; text-decoration-color: #008000\">'**Adding technical terminology for specificity**: \"What are the applications and theoretical foundations of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">few-shot learning in deep learning, particularly in relation to meta-learning and neural network architectures?\"'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mQuery:\u001b[0m \u001b[32m'**Adding technical terminology for specificity**: \"What are the applications and theoretical foundations of\u001b[0m\n",
       "\u001b[32mfew-shot learning in deep learning, particularly in relation to meta-learning and neural network architectures?\"'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: this is results length 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.5224</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.5224\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ [88] J. Ma, H. Xie, G. Han, S.-F. Chang, A. Galstyan, and W. Abd-                                │\n",
       "│ Almageed, “Partner-assisted learning for few-shot image classiﬁ-                                 │\n",
       "│ cation,” in Proceed...                                                                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ [88] J. Ma, H. Xie, G. Han, S.-F. Chang, A. Galstyan, and W. Abd-                                │\n",
       "│ Almageed, “Partner-assisted learning for few-shot image classiﬁ-                                 │\n",
       "│ cation,” in Proceed...                                                                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2202.07568v6_StratDef:_Strategic_Defense_Against_Adversarial_At</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2202.07568v6_StratDef:_Strategic_Defense_Against_Adversarial_At\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4709</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4709\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ can also be used in similar cases, where in addition to the diﬀerence in the data,               │\n",
       "│ theinputandoutputtasksarenotthesamebutonlysimilar(indomainadaptatio...                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ can also be used in similar cases, where in addition to the diﬀerence in the data,               │\n",
       "│ theinputandoutputtasksarenotthesamebutonlysimilar(indomainadaptatio...                           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4260</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4260\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Introduction to deep learning 21                                                                 │\n",
       "│ target classes (zero-shot learning), only one labelled example per class (1-shot                 │\n",
       "│ learning) or just few samples (gener...                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ Introduction to deep learning 21                                                                 │\n",
       "│ target classes (zero-shot learning), only one labelled example per class (1-shot                 │\n",
       "│ learning) or just few samples (gener...                                                          │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4069</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4069\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 8 Of Things Not Treated                                                                          │\n",
       "│ This short introductory article is aimed at those who are new to deep learning.                  │\n",
       "│ In the interests of brevity and accessibility ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ 8 Of Things Not Treated                                                                          │\n",
       "│ This short introductory article is aimed at those who are new to deep learning.                  │\n",
       "│ In the interests of brevity and accessibility ...                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">--- Result </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\"> ---</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m--- Result \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m ---\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.4012</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mScore: \u001b[0m\u001b[1;31m0.4012\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ In ICML, 2017.                                                                                   │\n",
       "│ Vitchyr Pong, Shixiang Gu, Murtaza Dalal, and Sergey Levine.                                     │\n",
       "│ Temporal difference models: Model-free deep rl for model-                                        │\n",
       "│ based control. a...                                                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────── Content Preview ─────────────────────────────────────────╮\n",
       "│ In ICML, 2017.                                                                                   │\n",
       "│ Vitchyr Pong, Shixiang Gu, Murtaza Dalal, and Sergey Levine.                                     │\n",
       "│ Temporal difference models: Model-free deep rl for model-                                        │\n",
       "│ based control. a...                                                                              │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Source: </span><span style=\"color: #7f7fff; text-decoration-color: #7f7fff; text-decoration: underline\">https://arxiv.org/pdf/1806.04640v3_Unsupervised_Meta-Learning_for_Reinforcement_Learn</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mSource: \u001b[0m\u001b[2;4;94mhttps://arxiv.org/pdf/1806.04640v3_Unsupervised_Meta-Learning_for_Reinforcement_Learn\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Total unique documents:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTotal unique documents:\u001b[0m \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating combined answer with documents context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating combined answer with documents context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Direct Answer:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Few-shot learning is a special case of learning with small datasets, where one is provided       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> either with just semantic information of the target classes (zero-shot learning), only one       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> labelled example per class (1-shot learning) or just few samples (general few-shot learning).    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> This type of learning has shown great success in many applications, such as image classification <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> [125, 111, 123], object detection [57] and segmentation [8]. Few-shot learning can also be used  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in similar cases, where in addition to the difference in the data, the input and output tasks    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> are not the same but only similar (domain adaptation), as seen in using a network trained on     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> natural images to classify medical data [4].                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, there is some disagreement regarding the definition of few-shot learning. Document 2    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> defines it as \"a special case of learning with small datasets\" without specifying the exact      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> number of samples or examples required for classification tasks [2]. In contrast, Document 3     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> mentions that approaches developed for few-shot problems have shown great success in many        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> applications, but does not explicitly define the term [3].                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Broader Context:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Few-shot learning is a subfield of machine learning that deals with learning from small amounts  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> of data. It has gained significant attention in recent years due to its potential applications   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in areas such as computer vision, natural language processing, and robotics. The key challenge   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> in few-shot learning is to learn effective representations of the data that can generalize well  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> across different classes or tasks.                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In addition to the specific definitions mentioned above, few-shot learning can also be viewed as <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> a type of meta-learning, which involves learning to adapt to new tasks or domains with limited   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> training data [5]. Meta-learning has been shown to be effective in various applications,         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> including reinforcement learning and natural language processing.                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">Sources Used:</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 1:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/2202.07568v6_StratDef:_Strategic_Defense_Against_Adversarial_At         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 2: https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 3: https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 4:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Document 5:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://arxiv.org/pdf/1806.04640v3_Unsupervised_Meta-Learning_for_Reinforcement_Learn         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mDirect Answer:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Few-shot learning is a special case of learning with small datasets, where one is provided       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m either with just semantic information of the target classes (zero-shot learning), only one       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m labelled example per class (1-shot learning) or just few samples (general few-shot learning).    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m This type of learning has shown great success in many applications, such as image classification \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m [125, 111, 123], object detection [57] and segmentation [8]. Few-shot learning can also be used  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in similar cases, where in addition to the difference in the data, the input and output tasks    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m are not the same but only similar (domain adaptation), as seen in using a network trained on     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m natural images to classify medical data [4].                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, there is some disagreement regarding the definition of few-shot learning. Document 2    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m defines it as \"a special case of learning with small datasets\" without specifying the exact      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m number of samples or examples required for classification tasks [2]. In contrast, Document 3     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m mentions that approaches developed for few-shot problems have shown great success in many        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m applications, but does not explicitly define the term [3].                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mBroader Context:\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Few-shot learning is a subfield of machine learning that deals with learning from small amounts  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m of data. It has gained significant attention in recent years due to its potential applications   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in areas such as computer vision, natural language processing, and robotics. The key challenge   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m in few-shot learning is to learn effective representations of the data that can generalize well  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m across different classes or tasks.                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In addition to the specific definitions mentioned above, few-shot learning can also be viewed as \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m a type of meta-learning, which involves learning to adapt to new tasks or domains with limited   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m training data [5]. Meta-learning has been shown to be effective in various applications,         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m including reinforcement learning and natural language processing.                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1mSources Used:\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 1:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/2202.07568v6_StratDef:_Strategic_Defense_Against_Adversarial_At         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 2: https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 3: https://arxiv.org/pdf/2003.03253v1_Introduction_to_deep_learning                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 4:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1801.05894v1_Deep_Learning:_An_Introduction_for_Applied_Mathema         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mDocument 5:                                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mhttps://arxiv.org/pdf/1806.04640v3_Unsupervised_Meta-Learning_for_Reinforcement_Learn         \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app.py\n",
    "# --- This file is your \"demo\" ---\n",
    "from langsmith import traceable\n",
    "# import os\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "from tracing import ResearchAssistant, OllamaLLM, Chroma, HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, BaseOutputParser\n",
    "from langchain.schema import Document, HumanMessage, AIMessage\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# from langchain.llms.base import BaseLLM\n",
    "\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pydantic import BaseModel, Field\n",
    "import logging\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# Initialize Rich Console\n",
    "console = Console()\n",
    "\n",
    "# Define your database path\n",
    "DB_DIR = \"../Database/Vector-DB-New\" # or \"./Database/Vector-DB-New\" depending on your folder\n",
    "\n",
    "def main(): \n",
    "    \"\"\"Main function to run the research assistant.\"\"\"\n",
    "    try:\n",
    "        # --- This block is your setup ---\n",
    "        console.print(\"[bold cyan]Initializing SageRAG Research Assistant...[/bold cyan]\")\n",
    "        \n",
    "        console.print(\"Loading embedding model...\")\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        console.print(\"Loading language model (LLaMA-3.2)...\")\n",
    "        llm = OllamaLLM(model=\"llama3.2\", temperature=0.2)\n",
    "        \n",
    "        console.print(f\"Connecting to vector database at: {DB_DIR}...\")\n",
    "        vector_db = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)\n",
    "        \n",
    "        console.print(\"[bold green]Initialization complete![/bold green]\")\n",
    "        \n",
    "        # Initialize the research assistant\n",
    "        assistant = ResearchAssistant(llm=llm, vector_db=vector_db)\n",
    "        BATCH_QUERIES = [\n",
    "            \"gpu vs cpu what to use for training?\",\n",
    "            \"What attention mechanism do?\",\n",
    "            \"What dropout layer for?\",\n",
    "            \"What attention mechanism do?\",\n",
    "            \"How much data needed for training models for image classification?\",\n",
    "            \"What is backprop exactly?\",\n",
    "            \"Regularization prevent what?\",\n",
    "            \"word embedding vs sentence embedding?\",\n",
    "            \"What is transfer learning nlp?\",\n",
    "            \"named entity recognition hard why?\",\n",
    "            \"language model perplexity mean?\",\n",
    "            \"What is few shot learning?\"\n",
    "        ]\n",
    "        \n",
    "        console.print(Panel.fit(\n",
    "            Markdown(\"# SageRAG Research Assistant\\n\\nAsk questions about scientific papers in the database.\"),\n",
    "            title=\"Welcome\",\n",
    "            border_style=\"cyan\"\n",
    "        ))\n",
    "        \n",
    "        # --- Main interaction loop ---\n",
    "        for query in BATCH_QUERIES:\n",
    "            # Ask the user whether to use memory mode\n",
    "            use_memory_input = 'n'\n",
    "            use_memory = use_memory_input.startswith('y')\n",
    "            \n",
    "            # Process the query\n",
    "            console.print(f\"\\n[bold cyan]Processing your query...[/bold cyan]\")\n",
    "            # This method is your System D pipeline\n",
    "            answer = assistant.process_query(query, use_memory=use_memory)\n",
    "            \n",
    "            # Display the final answer\n",
    "            console.print(Panel(\n",
    "                Markdown(answer),\n",
    "                title=\"Answer\",\n",
    "                border_style=\"green\",\n",
    "                width=100\n",
    "            ))\n",
    "            \n",
    "                \n",
    "    except ImportError as e:\n",
    "        console.print(f\"[bold red]Error: Missing required packages: {e}[/bold red]\")\n",
    "        console.print(\"Please install the required packages: pip install -r requirements.txt\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]An unexpected error occurred: {e}[/bold red]\")\n",
    "        import traceback\n",
    "        console.print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5584c3-6510-41aa-b5a1-e8ac1f645eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237368b-27f3-455e-9aae-0e412c32ab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbe44d-a465-45e8-a11d-5d8e51072681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557ef9d-69bb-44bb-bce2-b700a1031a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf08e83-b58e-4e73-9e48-b59928eab6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b098fb2-3134-45eb-99f4-aaa9306d132d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be0c83-cb18-490f-8486-9c354049e43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252779d-6c4c-4201-b79b-9b7690367b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6c3966-ac6d-45b2-8274-130d417c3e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Initializing SageRAG Research Assistant...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mInitializing SageRAG Research Assistant\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading embedding model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading embedding model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading language model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading language model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connecting to vector database<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connecting to vector database\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Initialization complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mInitialization complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 19:56:17,515 - SageRAG - INFO - Initializing default embedding model\n",
      "2025-11-03 19:56:22,231 - SageRAG - INFO - Research Assistant initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────────────── Welcome ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┃                                         <span style=\"font-weight: bold\">SageRAG Research Assistant</span>                                          ┃ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> Ask questions about scientific papers in the database.                                                          <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m Welcome \u001b[0m\u001b[36m───────────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┃                                         \u001b[1mSageRAG Research Assistant\u001b[0m                                          ┃ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m Ask questions about scientific papers in the database.                                                          \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Options:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mOptions:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Ask a question\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m. Ask a question\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. View conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m. View conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Clear conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m. Clear conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Go for Advanced Research\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m. Go for Advanced Research\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m. Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-5):  1\n",
      "\n",
      "[bold]Enter your query:[/bold]  gpu vs cpu for training?\n",
      "Use conversation memory? (y/n):  n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Processing your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mProcessing your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should_use_memory False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Using full query improvement pipeline...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mUsing full query improvement pipeline\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluating your query...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluating your query\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Query Rating: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">/</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mQuery Rating: \u001b[0m\u001b[1;32m4\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Explanation: The query is clear and concise, using specific technical terms <span style=\"color: #008000; text-decoration-color: #008000\">'GPU'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'CPU'</span>, which are relevant to \n",
       "the context of scientific research in machine learning or deep learning. The query is focused on retrieving \n",
       "information about the differences between GPUs and CPUs for training purposes, making it highly retrievable with \n",
       "vector search algorithms.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Explanation: The query is clear and concise, using specific technical terms \u001b[32m'GPU'\u001b[0m and \u001b[32m'CPU'\u001b[0m, which are relevant to \n",
       "the context of scientific research in machine learning or deep learning. The query is focused on retrieving \n",
       "information about the differences between GPUs and CPUs for training purposes, making it highly retrievable with \n",
       "vector search algorithms.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating improved query variations...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerating improved query variations\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">present the queries re: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "present the queries re: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Available search queries:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mAvailable search queries:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">.</span> Original: gpu vs cpu for training?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\u001b[1m.\u001b[0m Original: gpu vs cpu for training?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Confidence: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;32mConfidence: \u001b[0m\u001b[1;32m1.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Select queries to use:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSelect queries to use:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter the numbers of the queries you want to use <span style=\"font-weight: bold\">(</span>comma-separated, e.g., <span style=\"color: #008000; text-decoration-color: #008000\">'0,2,3'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Enter the numbers of the queries you want to use \u001b[1m(\u001b[0mcomma-separated, e.g., \u001b[32m'0,2,3'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Selected </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> queries for retrieval.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSelected \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m queries for retrieval.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "--------------------------------------------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "--------------------------------------------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Retrieving relevant documents...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mRetrieving relevant documents\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG123: only this is working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Retrieved </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> documents</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mRetrieved \u001b[0m\u001b[1;32m5\u001b[0m\u001b[1;32m documents\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Top retrieved documents:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mTop retrieved documents:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3935</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m. \u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3935\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Preview: The highly parallel nature of workload of real-time computer\n",
       "graphics demands high arithmetic throughput and streaming\n",
       "memory bandwidth but at the sam<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Preview: The highly parallel nature of workload of real-time computer\n",
       "graphics demands high arithmetic throughput and streaming\n",
       "memory bandwidth but at the sam\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://arxiv.org/pdf/2311.05857v1_On_the_Design_and_Analysis_of_Parallel_and_Distrib</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Source: \u001b[4;94mhttps://arxiv.org/pdf/2311.05857v1_On_the_Design_and_Analysis_of_Parallel_and_Distrib\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3691</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m. \u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3691\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Preview: is\n",
       "not\n",
       "something\n",
       "that\n",
       "you\n",
       "could\n",
       "train\n",
       "on\n",
       "a\n",
       "few\n",
       "GPU\n",
       "instances\n",
       "that\n",
       "you\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "spin\n",
       "up\n",
       "in\n",
       "the\n",
       "cloud.\n",
       "It\n",
       "requires\n",
       "access\n",
       "to\n",
       "heavy\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Preview: is\n",
       "not\n",
       "something\n",
       "that\n",
       "you\n",
       "could\n",
       "train\n",
       "on\n",
       "a\n",
       "few\n",
       "GPU\n",
       "instances\n",
       "that\n",
       "you\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "spin\n",
       "up\n",
       "in\n",
       "the\n",
       "cloud.\n",
       "It\n",
       "requires\n",
       "access\n",
       "to\n",
       "heavy\n",
       "\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://arxiv.org/pdf/2011.02787v1_The_State_of_AI_Ethics_Report_(October_2020)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Source: \u001b[4;94mhttps://arxiv.org/pdf/2011.02787v1_The_State_of_AI_Ethics_Report_\u001b[0m\u001b[4;94m(\u001b[0m\u001b[4;94mOctober_2020\u001b[0m\u001b[4;94m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3648</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m. \u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3648\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Preview: multi-GPU multicore soft real-time systems with ﬂexibility,\n",
       "predictability, and parallelism. Golyanik <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">]</span> described a\n",
       "scheduling approach based on ti<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Preview: multi-GPU multicore soft real-time systems with ﬂexibility,\n",
       "predictability, and parallelism. Golyanik \u001b[1m[\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1m]\u001b[0m described a\n",
       "scheduling approach based on ti\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Source: \u001b[4;94mhttps://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3473</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m. \u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3473\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Preview: plied to other heterogeneous computing systems that have\n",
       "a similar application execution pattern <span style=\"font-weight: bold\">(</span>each task has CPU,\n",
       "memory copy, and heterogeneous co<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Preview: plied to other heterogeneous computing systems that have\n",
       "a similar application execution pattern \u001b[1m(\u001b[0meach task has CPU,\n",
       "memory copy, and heterogeneous co\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Source: \u001b[4;94mhttps://arxiv.org/pdf/2101.10463v3_RTGPU:_Real-Time_GPU_Scheduling_of_Hard_Deadline_P\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Score: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.3437</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m. \u001b[1;31mScore: \u001b[0m\u001b[1;31m0.3437\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Preview: status\n",
       "quo\n",
       "and\n",
       "advance\n",
       "the\n",
       "interests\n",
       "of\n",
       "the\n",
       "powerful.\n",
       "What\n",
       "is\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "needed\n",
       "is\n",
       "a\n",
       "field\n",
       "that\n",
       "exposes\n",
       "and\n",
       "critiques\n",
       "systems\n",
       "that\n",
       "co<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Preview: status\n",
       "quo\n",
       "and\n",
       "advance\n",
       "the\n",
       "interests\n",
       "of\n",
       "the\n",
       "powerful.\n",
       "What\n",
       "is\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "needed\n",
       "is\n",
       "a\n",
       "field\n",
       "that\n",
       "exposes\n",
       "and\n",
       "critiques\n",
       "systems\n",
       "that\n",
       "co\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://arxiv.org/pdf/2011.02787v1_The_State_of_AI_Ethics_Report_(October_2020)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Source: \u001b[4;94mhttps://arxiv.org/pdf/2011.02787v1_The_State_of_AI_Ethics_Report_\u001b[0m\u001b[4;94m(\u001b[0m\u001b[4;94mOctober_2020\u001b[0m\u001b[4;94m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generating answer with document context...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mGenerating answer with document context\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 20:00:29,947 - SageRAG - INFO - Document relevance: Sufficient=True, Confidence=0.82\n",
      "2025-11-03 20:00:29,948 - SageRAG - INFO - Explanation: Documents 2 and 3 contain information related to training on GPU instances, which is relevant to the user's question about GPU vs CPU for training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Based on the provided context chunks, it appears that GPUs and CPUs have different strengths and <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> weaknesses when it comes to training machine learning models.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GPUs are optimized for high throughput and parallelism, making them well-suited for tasks that   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> require a lot of computational power, such as deep learning. According to Document 4, a typical  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GPU program contains three parts: the CPU segment, the host/device memory copy segment, and the  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> device code segment (GPU kernel). The GPU kernel is a single instruction multiple threads (SIMT) <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> program where many threads are grouped into one thread block and execute the same instruction on <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> different data simultaneously.                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, as mentioned in Document 5, training large-scale models requires massive amounts of     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> data and computing resources, which can be a barrier for those without access to heavy computing <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> power. The most recent GPT-3 model with 175 billion parameters cannot be trained on a few GPU    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> instances that can be spun up in the cloud.                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> On the other hand, CPUs are optimized for low latency, making them better suited for tasks that  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> require quick processing and response times. According to Document 1, GPUs tolerate considerable <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> latency in individual computations because the final images are only displayed every 16          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> milliseconds.                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Document 3 highlights the need for more flexible GPU kernel execution methods, such as temporal  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> preemption and spatial partitioning, to support multiple tasks on a single GPU. This suggests    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> that while GPUs can handle complex computations, they may not be ideal for training machine      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning models that require frequent updates or fine-tuning.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In summary, while GPUs are better suited for high-throughput parallel computing, CPUs are more   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> suitable for low-latency tasks. However, the current state of large-scale model training         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> requires access to heavy computing resources, which can be a limitation for those without        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> significant financial backing.                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Missing information:                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>There is no clear consensus on whether GPUs or CPUs are better suited for training machine    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning models.                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The context does not provide enough information to determine the optimal choice between GPUs  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and CPUs for training machine learning models.                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>More research is needed to explore the trade-offs between GPU and CPU architectures for deep  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning applications.                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Note: The answer is based on the provided context chunks, which may not be exhaustive or         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> definitive. Further research and analysis are necessary to provide a more comprehensive answer.  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m Based on the provided context chunks, it appears that GPUs and CPUs have different strengths and \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m weaknesses when it comes to training machine learning models.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GPUs are optimized for high throughput and parallelism, making them well-suited for tasks that   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m require a lot of computational power, such as deep learning. According to Document 4, a typical  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GPU program contains three parts: the CPU segment, the host/device memory copy segment, and the  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m device code segment (GPU kernel). The GPU kernel is a single instruction multiple threads (SIMT) \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m program where many threads are grouped into one thread block and execute the same instruction on \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m different data simultaneously.                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, as mentioned in Document 5, training large-scale models requires massive amounts of     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m data and computing resources, which can be a barrier for those without access to heavy computing \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m power. The most recent GPT-3 model with 175 billion parameters cannot be trained on a few GPU    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m instances that can be spun up in the cloud.                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m On the other hand, CPUs are optimized for low latency, making them better suited for tasks that  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m require quick processing and response times. According to Document 1, GPUs tolerate considerable \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m latency in individual computations because the final images are only displayed every 16          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m milliseconds.                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Document 3 highlights the need for more flexible GPU kernel execution methods, such as temporal  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m preemption and spatial partitioning, to support multiple tasks on a single GPU. This suggests    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m that while GPUs can handle complex computations, they may not be ideal for training machine      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning models that require frequent updates or fine-tuning.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In summary, while GPUs are better suited for high-throughput parallel computing, CPUs are more   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m suitable for low-latency tasks. However, the current state of large-scale model training         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m requires access to heavy computing resources, which can be a limitation for those without        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m significant financial backing.                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Missing information:                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mThere is no clear consensus on whether GPUs or CPUs are better suited for training machine    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mlearning models.                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mThe context does not provide enough information to determine the optimal choice between GPUs  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mand CPUs for training machine learning models.                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mMore research is needed to explore the trade-offs between GPU and CPU architectures for deep  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mlearning applications.                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Note: The answer is based on the provided context chunks, which may not be exhaustive or         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m definitive. Further research and analysis are necessary to provide a more comprehensive answer.  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Would you like to get an llm generated answer?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mWould you like to get an llm generated answer?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(y/n):  n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Based on the provided context chunks, it appears that GPUs and CPUs have different strengths and <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> weaknesses when it comes to training machine learning models.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GPUs are optimized for high throughput and parallelism, making them well-suited for tasks that   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> require a lot of computational power, such as deep learning. According to Document 4, a typical  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> GPU program contains three parts: the CPU segment, the host/device memory copy segment, and the  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> device code segment (GPU kernel). The GPU kernel is a single instruction multiple threads (SIMT) <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> program where many threads are grouped into one thread block and execute the same instruction on <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> different data simultaneously.                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> However, as mentioned in Document 5, training large-scale models requires massive amounts of     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> data and computing resources, which can be a barrier for those without access to heavy computing <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> power. The most recent GPT-3 model with 175 billion parameters cannot be trained on a few GPU    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> instances that can be spun up in the cloud.                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> On the other hand, CPUs are optimized for low latency, making them better suited for tasks that  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> require quick processing and response times. According to Document 1, GPUs tolerate considerable <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> latency in individual computations because the final images are only displayed every 16          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> milliseconds.                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Document 3 highlights the need for more flexible GPU kernel execution methods, such as temporal  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> preemption and spatial partitioning, to support multiple tasks on a single GPU. This suggests    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> that while GPUs can handle complex computations, they may not be ideal for training machine      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> learning models that require frequent updates or fine-tuning.                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> In summary, while GPUs are better suited for high-throughput parallel computing, CPUs are more   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> suitable for low-latency tasks. However, the current state of large-scale model training         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> requires access to heavy computing resources, which can be a limitation for those without        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> significant financial backing.                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Missing information:                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>There is no clear consensus on whether GPUs or CPUs are better suited for training machine    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning models.                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The context does not provide enough information to determine the optimal choice between GPUs  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and CPUs for training machine learning models.                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>More research is needed to explore the trade-offs between GPU and CPU architectures for deep  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning applications.                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> Note: The answer is based on the provided context chunks, which may not be exhaustive or         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> definitive. Further research and analysis are necessary to provide a more comprehensive answer.  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m Based on the provided context chunks, it appears that GPUs and CPUs have different strengths and \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m weaknesses when it comes to training machine learning models.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GPUs are optimized for high throughput and parallelism, making them well-suited for tasks that   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m require a lot of computational power, such as deep learning. According to Document 4, a typical  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m GPU program contains three parts: the CPU segment, the host/device memory copy segment, and the  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m device code segment (GPU kernel). The GPU kernel is a single instruction multiple threads (SIMT) \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m program where many threads are grouped into one thread block and execute the same instruction on \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m different data simultaneously.                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m However, as mentioned in Document 5, training large-scale models requires massive amounts of     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m data and computing resources, which can be a barrier for those without access to heavy computing \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m power. The most recent GPT-3 model with 175 billion parameters cannot be trained on a few GPU    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m instances that can be spun up in the cloud.                                                      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m On the other hand, CPUs are optimized for low latency, making them better suited for tasks that  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m require quick processing and response times. According to Document 1, GPUs tolerate considerable \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m latency in individual computations because the final images are only displayed every 16          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m milliseconds.                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Document 3 highlights the need for more flexible GPU kernel execution methods, such as temporal  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m preemption and spatial partitioning, to support multiple tasks on a single GPU. This suggests    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m that while GPUs can handle complex computations, they may not be ideal for training machine      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m learning models that require frequent updates or fine-tuning.                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m In summary, while GPUs are better suited for high-throughput parallel computing, CPUs are more   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m suitable for low-latency tasks. However, the current state of large-scale model training         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m requires access to heavy computing resources, which can be a limitation for those without        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m significant financial backing.                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Missing information:                                                                             \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mThere is no clear consensus on whether GPUs or CPUs are better suited for training machine    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mlearning models.                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mThe context does not provide enough information to determine the optimal choice between GPUs  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mand CPUs for training machine learning models.                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m • \u001b[0mMore research is needed to explore the trade-offs between GPU and CPU architectures for deep  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m \u001b[1;33m   \u001b[0mlearning applications.                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m Note: The answer is based on the provided context chunks, which may not be exhaustive or         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m definitive. Further research and analysis are necessary to provide a more comprehensive answer.  \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Options:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mOptions:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Ask a question\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m. Ask a question\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. View conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m. View conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Clear conversation history\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m. Clear conversation history\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Go for Advanced Research\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4\u001b[0m. Go for Advanced Research\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Exit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m5\u001b[0m. Exit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-5):  5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Thank you for using SageRAG Research Assistant. Goodbye!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mThank you for using SageRAG Research Assistant. Goodbye!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import os\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, BaseOutputParser\n",
    "from langchain.schema import Document, HumanMessage, AIMessage\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.chains import LLMChain\n",
    "# from langchain.llms.base import BaseLLM\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pydantic import BaseModel, Field\n",
    "import logging\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# Suppress library-specific logging\n",
    "import logging\n",
    "logging.getLogger('sentence_transformers').setLevel(logging.WARNING)\n",
    "logging.getLogger('transformers').setLevel(logging.WARNING)\n",
    "logging.getLogger('chromadb').setLevel(logging.WARNING)\n",
    "logging.getLogger('LangChainDeprecationWarning').setLevel(logging.WARNING)\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "\n",
    "# Then set up your own logging as before\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"SageRAG\")\n",
    "\n",
    "# Rich console for prettier output\n",
    "console = Console()\n",
    "\n",
    "# Enhanced output parsers with better error handling\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse output that contains a numbered list and return as a list of strings.\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse text into a list of strings.\"\"\"\n",
    "        # Updated regex to be more robust with various numbering styles\n",
    "        lines = re.findall(r\"^\\s*\\d+\\.?\\s+(.*?)$\", text, re.MULTILINE)\n",
    "        return [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"line_list\"\n",
    "\n",
    "class QueryRating(BaseModel):\n",
    "    \"\"\"Schema for query rating output.\"\"\"\n",
    "    rating: int = Field(description=\"Rating from 1-5\")\n",
    "    explanation: str = Field(description=\"Explanation for the rating\")\n",
    "\n",
    "@dataclass\n",
    "class RetrievedDocument:\n",
    "    \"\"\"Dataclass for tracking retrieved document info.\"\"\"\n",
    "    document: Document\n",
    "    score: float\n",
    "    query: str = \"\"\n",
    "    rank: int = 0\n",
    "\n",
    "class ResearchAssistant:\n",
    "    \"\"\"AI Research Assistant using RAG for scientific paper queries.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        llm: OllamaLLM, \n",
    "        vector_db: VectorStore, \n",
    "        embeddings_model: Optional[SentenceTransformer] = None,\n",
    "        relevance_threshold: float = 0.2,\n",
    "        max_docs_per_query: int = 4\n",
    "    ):\n",
    "        \"\"\"Initialize the Research Assistant with LLM and vector database.\n",
    "        \n",
    "        Args:\n",
    "            llm: The language model to use for generation\n",
    "            vector_db: Vector database for document retrieval\n",
    "            embeddings_model: Optional SentenceTransformer model for semantic similarity\n",
    "            relevance_threshold: Minimum relevance score for documents\n",
    "            max_docs_per_query: Maximum documents to use per query\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.vector_db = vector_db\n",
    "        self.relevance_threshold = relevance_threshold\n",
    "        self.max_docs_per_query = max_docs_per_query\n",
    "        \n",
    "        # Initialize sentence transformer model for semantic similarity if not provided\n",
    "        if embeddings_model is None:\n",
    "            logger.info(\"Initializing default embedding model\")\n",
    "            self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        else:\n",
    "            self.semantic_model = embeddings_model\n",
    "            \n",
    "        # Initialize memory\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        \n",
    "        # Create a retriever for direct use\n",
    "        self.retriever = vector_db.as_retriever()\n",
    "        \n",
    "        # Define parsers\n",
    "        self.json_parser = JsonOutputParser(pydantic_object=QueryRating)\n",
    "        self.list_parser = LineListOutputParser()\n",
    "        \n",
    "        logger.info(\"Research Assistant initialized successfully\")\n",
    "    \n",
    "    def rate_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Rates the query and gives an explanation.\n",
    "        \n",
    "        Args:\n",
    "            query: The user's query to be evaluated\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing rating and explanation\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are an intelligent assistant trained to evaluate search queries for a scientific research database.\n",
    "        Given the following query: \"{query}\"\n",
    "        \n",
    "        1. Rate the query on a scale of 1 (very poor) to 5 (excellent) based on:\n",
    "           - Clarity: Is the query clear and unambiguous?\n",
    "           - Specificity: Does it contain specific technical terms or concepts?\n",
    "           - Relevance: Is it focused on retrieving scientific content?\n",
    "           - Retrievability: Will it work well with vector search?\n",
    "        \n",
    "        2. Provide a short explanation for the rating (what makes it effective or ineffective).\n",
    "        \n",
    "        Respond in JSON format:\n",
    "        {{\n",
    "          \"rating\": <number between 1-5>,\n",
    "          \"explanation\": \"<your explanation>\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        chain: Runnable = prompt | self.llm | self.json_parser\n",
    "        \n",
    "        try:\n",
    "            return chain.invoke({\"query\": query})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error rating query: {e}\")\n",
    "            # Fallback response if parsing fails\n",
    "            return {\n",
    "                \"rating\": 3, \n",
    "                \"explanation\": \"Unable to rate query properly. Consider adding more specific terms.\"\n",
    "            }\n",
    "\n",
    "    \n",
    "    def suggest_rewrites(self, query: str, chat_history: Optional[List] = None) -> List[str]:\n",
    "        \"\"\"Returns rephrased versions of the query optimized for retrieval.\n",
    "        \n",
    "        Args:\n",
    "            query: Original query to rewrite\n",
    "            chat_history: Optional conversation history for context\n",
    "            \n",
    "        Returns:\n",
    "            List of rewritten queries\n",
    "        \"\"\"\n",
    "        history_context = \"\"\n",
    "        if chat_history:\n",
    "            history_context = \"Consider this conversation context when rewriting the query:\\n\"\n",
    "            for message in chat_history[-3:]:  # Use only last 3 messages for brevity\n",
    "                if hasattr(message, \"content\"):\n",
    "                    role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                    history_context += f\"{role}: {message.content}\\n\"\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"history_context\"],\n",
    "            template=\"\"\"You are an AI assistant specializing in scientific research queries.\n",
    "        {history_context}\n",
    "        TASK: Create 5 alternative versions of the user's question that will help improve retrieval from a scientific paper database.\n",
    "        Original question: {question}\n",
    "\n",
    "        For each alternative version:\n",
    "        Write a COMPLETE, EXECUTABLE query (not just a description)\n",
    "        Make each version meaningfully different while preserving the core information need\n",
    "        Include the ACTUAL REWRITTEN QUESTION text\n",
    "\n",
    "        FORMAT YOUR RESPONSE EXACTLY LIKE THIS EXAMPLE:\n",
    "\n",
    "        Original question: batch size affect what?\n",
    "        1. Rewrite 1: [Short description of the rewrite strategy]: \"[Rewritten query text]\"\n",
    "\n",
    "        Here is one of the high-quality examples provided in the prompt to guide the model:\n",
    "        1. Rewrite 1: Adding technical terminology for specificity: \"What are the effects of batch size on model convergence and optimization in deep learning neural networks?\"\n",
    "        2. Rewrite 2: Decomposition into multiple sub-questions: \"How does the batch size parameter influence the performance of stochastic gradient descent algorithms? What impact does it have on the training time and accuracy of machine learning models?\" \n",
    "        3. Rewrite 3: Expanding the query with related concepts: \"Examine the effects of batch size, mini-batch size, and data partitioning on the generalization capabilities and robustness of deep neural networks.\"\n",
    "        4. Rewrite 4: Focusing on a specific aspect or trade-off: \"In what ways do changes in batch size affect the trade-off between model training speed and accuracy in deep learning architectures?\"\n",
    "        5. Rewrite 5: Specifying key entities and relationships: \"Analyze the causal relationship between batch size, neural network architecture, and optimization algorithms (e.g., Adam, SGD) on the convergence of training objectives and model performance metrics.\"\n",
    "\n",
    "        Now, for the question \"{question}\", provide 5 complete, executable rewritten queries following the exact format above. Each rewrite must include the full rewritten question text, not just a description of how to rewrite it.\n",
    "\n",
    "        \"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            result = (prompt | self.llm | self.list_parser).invoke({\n",
    "                \"question\": query,\n",
    "                \"history_context\": history_context\n",
    "            })\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error suggesting rewrites: {e}\")\n",
    "            # Return a minimal set of rewrites if parsing fails\n",
    "            return [\n",
    "                query,  # Original query\n",
    "                f\"research about {query}\",\n",
    "                f\"papers discussing {query}\"\n",
    "            ]\n",
    "    def compute_confidence(self, original: str, rewritten: str) -> float:\n",
    "        \"\"\"Computes semantic similarity between original and rewritten queries.\n",
    "        \n",
    "        Args:\n",
    "            original: Original query\n",
    "            rewritten: Rewritten version\n",
    "            \n",
    "        Returns:\n",
    "            Similarity score between 0-1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            vec_orig = self.semantic_model.encode(original, convert_to_tensor=True)\n",
    "            vec_rewrite = self.semantic_model.encode(rewritten, convert_to_tensor=True)\n",
    "            return float(util.pytorch_cos_sim(vec_orig, vec_rewrite).item())\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error computing similarity: {e}\")\n",
    "            return 0.6  # Default reasonable value\n",
    "    \n",
    "    def score_queries(self, original: str, queries: List[str]) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Scores and sorts rephrased queries by confidence.\n",
    "        \n",
    "        Args:\n",
    "            original: Original query\n",
    "            queries: List of rewritten queries\n",
    "            \n",
    "        Returns:\n",
    "            List of (query, score) tuples sorted by score\n",
    "        \"\"\"\n",
    "        scored = [(q, self.compute_confidence(original, q)) for q in queries]\n",
    "        return sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    def present_query_options(self, original: str, queries: List[str]) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Presents the original and rewritten queries with confidence scores.\n",
    "        \n",
    "        Args:\n",
    "            original: Original query\n",
    "            queries: List of rewritten queries\n",
    "            \n",
    "        Returns:\n",
    "            List of (query, score) tuples including original query\n",
    "        \"\"\"\n",
    "        # Add original query at the top\n",
    "        scored_queries = [(\"Original: \" + original, 1.0)]\n",
    "        \n",
    "        # Add scored rewritten queries\n",
    "        rewritten_scores = self.score_queries(original, queries)\n",
    "        for i, (query, score) in enumerate(rewritten_scores, 1):\n",
    "            if \"Query:\" in query:\n",
    "                parts = query.split(\"Query:\")\n",
    "                # Format with Query on a new line and bold\n",
    "                formatted_query = f\"{parts[0]}\\n[bold]Query:[/bold]{parts[1]}\"\n",
    "                scored_queries.append((f\"Rewrite {i}: {formatted_query}\", score))\n",
    "            else:\n",
    "                scored_queries.append((f\"Rewrite {i}: {query}\", score))\n",
    "            \n",
    "        # Display options in a nice format\n",
    "        console.print(\"\\n[bold cyan]Available search queries:[/bold cyan]\")\n",
    "        for i, (query, score) in enumerate(scored_queries):\n",
    "            confidence_color = \"green\" if score > 0.8 else \"yellow\" if score > 0.6 else \"red\"\n",
    "            console.print(f\"[bold]{i}.[/bold] {query}\")\n",
    "            console.print(f\"   [bold {confidence_color}]Confidence: {score:.2f}[/bold {confidence_color}]\")\n",
    "            \n",
    "        return scored_queries\n",
    "    \n",
    "    \n",
    "    def retrieve_documents(\n",
    "        self, \n",
    "        queries: List[str], \n",
    "        k: int = 5\n",
    "    ) -> Tuple[List[RetrievedDocument], Dict[str, List[RetrievedDocument]]]:\n",
    "        \"\"\"Retrieves documents using multiple queries, preserving query information.\n",
    "        \n",
    "        Args:\n",
    "            queries: List of queries to retrieve documents for\n",
    "            k: Number of documents to retrieve per query\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (all unique documents, query->documents mapping)\n",
    "        \"\"\"\n",
    "        all_docs: List[RetrievedDocument] = []\n",
    "        unique_content = set()\n",
    "        query_docs_map: Dict[str, List[RetrievedDocument]] = {}\n",
    "        \n",
    "        # Retrieve docs for each query\n",
    "        for query in queries:\n",
    "            console.print(f\"\\n[bold blue]Query:[/bold blue] '{query}'\")\n",
    "            \n",
    "            try:\n",
    "                results = self.vector_db.similarity_search_with_relevance_scores(query, k=k)\n",
    "                print(\"LOG123: this is results length\",len(results))\n",
    "                docs_for_query: List[RetrievedDocument] = []\n",
    "                \n",
    "                for i, (doc, score) in enumerate(results, 1):\n",
    "                    # Create retrieved document object\n",
    "                    retrieved_doc = RetrievedDocument(\n",
    "                        document=doc,\n",
    "                        score=score,\n",
    "                        query=query,\n",
    "                        rank=i\n",
    "                    )\n",
    "                    \n",
    "                    # Display result info\n",
    "                    score_color = \"green\" if score > 0.8 else \"yellow\" if score > 0.6 else \"red\"\n",
    "                    console.print(f\"[bold]--- Result {i} ---[/bold]\")\n",
    "                    console.print(f\"[bold {score_color}]Score: {score:.4f}[/bold {score_color}]\")\n",
    "                    \n",
    "                    # Show document preview\n",
    "                    preview = doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content\n",
    "                    console.print(Panel(preview, title=\"Content Preview\", width=100))\n",
    "                    \n",
    "                    # Show metadata if available\n",
    "                    if hasattr(doc, 'metadata') and doc.metadata:\n",
    "                        source = doc.metadata.get('source', 'Unknown')\n",
    "                        console.print(f\"[dim]Source: {source}[/dim]\")\n",
    "                    \n",
    "                    # Add to results for this query\n",
    "                    docs_for_query.append(retrieved_doc)\n",
    "                    \n",
    "                    # Only add unique documents to overall collection\n",
    "                    if doc.page_content not in unique_content:\n",
    "                        unique_content.add(doc.page_content)\n",
    "                        all_docs.append(retrieved_doc)\n",
    "                query_docs_map[query] = docs_for_query\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving documents for query '{query}': {e}\")\n",
    "                console.print(f\"[bold red]Error retrieving documents for query: {query}[/bold red]\")\n",
    "        \n",
    "        console.print(f\"\\n[bold green]Total unique documents:[/bold green] {len(all_docs)}\")\n",
    "        return all_docs, query_docs_map\n",
    "\n",
    "    def rerank_docs(self, query: str, docs: List[RetrievedDocument]) -> List[RetrievedDocument]:\n",
    "        \"\"\"Reranks documents based on semantic similarity to the query.\n",
    "        \n",
    "        Args:\n",
    "            query: Query to compare documents against\n",
    "            docs: List of retrieved documents\n",
    "            \n",
    "        Returns:\n",
    "            Reranked list of documents with updated scores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            query_embedding = self.semantic_model.encode(query, convert_to_tensor=True)\n",
    "            reranked = []\n",
    "            \n",
    "            for doc in docs:\n",
    "                doc_embedding = self.semantic_model.encode(doc.document.page_content, convert_to_tensor=True)\n",
    "                new_score = float(util.pytorch_cos_sim(query_embedding, doc_embedding).item())\n",
    "                \n",
    "                # Create new RetrievedDocument with updated score\n",
    "                reranked_doc = RetrievedDocument(\n",
    "                    document=doc.document,\n",
    "                    score=new_score,\n",
    "                    query=doc.query,\n",
    "                    rank=0  # Will be updated after sorting\n",
    "                )\n",
    "                reranked.append(reranked_doc)\n",
    "            \n",
    "            # Sort by score and update ranks\n",
    "            reranked.sort(key=lambda x: x.score, reverse=True)\n",
    "            for i, doc in enumerate(reranked, 1):\n",
    "                doc.rank = i\n",
    "                \n",
    "            return reranked\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reranking documents: {e}\")\n",
    "            return docs  # Return original documents if reranking fails\n",
    "    \n",
    "    def can_answer_without_retrieval(self, question: str) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"Determines if a question can be answered directly from memory without retrieval.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (can_answer, answer_if_available)\n",
    "        \"\"\"\n",
    "        # Get chat history from memory if available\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        if not chat_history:\n",
    "            return False, None\n",
    "            \n",
    "        # Create the prompt to check if we can answer directly from the conversation\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are an AI assistant helping with a scientific research conversation.\n",
    "        Given the following conversation history and a new question, determine if the question:\n",
    "        1. Can be answered directly based ONLY on the conversation history (like \"what was my previous question?\")\n",
    "        2. Does NOT require retrieving new information from scientific papers\n",
    "        \n",
    "        If both conditions are true, provide the answer. Otherwise, respond with \"NEEDS_RETRIEVAL\".\n",
    "        \n",
    "        Conversation History:\n",
    "        {chat_history}\n",
    "        \n",
    "        New Question: {question}\n",
    "        \n",
    "        Your assessment (answer directly or respond with \"NEEDS_RETRIEVAL\"):\n",
    "        \"\"\")\n",
    "        \n",
    "        # Format the chat history for context\n",
    "        history_str = \"\"\n",
    "        for message in chat_history[-5:]:  # Use only last 5 messages for brevity\n",
    "            if hasattr(message, \"content\"):\n",
    "                role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                history_str += f\"{role}: {message.content}\\n\"\n",
    "        \n",
    "        try:\n",
    "            # Ask the LLM if this can be answered without retrieval\n",
    "            response = self.llm.invoke(\n",
    "                prompt.format(chat_history=history_str, question=question)\n",
    "            )\n",
    "            \n",
    "            # If the response is \"NEEDS_RETRIEVAL\", we need to use retrieval\n",
    "            if \"NEEDS_RETRIEVAL\" in response:\n",
    "                return False, None\n",
    "            else:\n",
    "                logger.info(\"Question can be answered from conversation history\")\n",
    "                return True, response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error determining if retrieval needed: {e}\")\n",
    "            return False, None  \n",
    "    \n",
    "    def generate_final_answer(\n",
    "        self, \n",
    "        question: str, \n",
    "        docs: List[RetrievedDocument], \n",
    "        max_docs: int = 5\n",
    "    ) -> str:\n",
    "        \"\"\"Generates the final answer from retrieved documents with LLM fallback.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            docs: List of retrieved documents\n",
    "            max_docs: Maximum number of documents to include\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        # First, evaluate if the documents are sufficient\n",
    "        is_sufficient, confidence = self.evaluate_document_relevance(question, docs)\n",
    "        \n",
    "        # If documents are insufficient, use LLM fallback\n",
    "        if not is_sufficient or confidence < 0.4:  # Adjust threshold as needed\n",
    "            console.print(\"[yellow]Retrieved documents insufficient. Using LLM fallback...[/yellow]\")\n",
    "            return self.generate_llm_answer(question)\n",
    "        \n",
    "        # Otherwise, continue with RAG as before\n",
    "        # Get chat history from memory if available\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        # Create chat history string for context if available\n",
    "        chat_context = \"\"\n",
    "        if chat_history:\n",
    "            chat_context = \"Previous conversation:\\n\"\n",
    "            for message in chat_history[-3:]:  # Use last 3 messages for context\n",
    "                if hasattr(message, \"content\"):\n",
    "                    role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                    chat_context += f\"{role}: {message.content}\\n\"\n",
    "                \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\", \"chat_history\"],\n",
    "            template=\"\"\"You are a helpful scientific research assistant analyzing scientific papers. \n",
    "            Use the following retrieved context chunks to answer the user's question thoroughly.\n",
    "            \n",
    "            Guidelines:\n",
    "            - Focus on providing accurate information from the papers\n",
    "            - Synthesize information across documents when appropriate\n",
    "            - Cite the sources of information in your answer (e.g., \"According to Document 1...\")\n",
    "            - If the information isn't in the context, indicate what's missing rather than making up information\n",
    "            - If the context contains conflicting information, highlight the disagreement and possible reasons\n",
    "            - Maintain scientific accuracy above all else\n",
    "            \n",
    "            {chat_history}\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Answer:\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Format document content with metadata\n",
    "        context_pieces = []\n",
    "        for i, doc in enumerate(docs[:max_docs]):\n",
    "            chunk = f\"Document {i+1} [Relevance: {doc.score:.2f}]:\\n{doc.document.page_content}\"\n",
    "            \n",
    "            # Add metadata if available\n",
    "            if hasattr(doc.document, 'metadata') and doc.document.metadata:\n",
    "                source = doc.document.metadata.get('source', 'Unknown')\n",
    "                chunk += f\"\\nSource: {source}\"\n",
    "                \n",
    "            context_pieces.append(chunk)\n",
    "            \n",
    "        context = \"\\n\\n---\\n\\n\".join(context_pieces)\n",
    "        \n",
    "        try:\n",
    "            # Generate answer\n",
    "            answer = (prompt | self.llm).invoke({\n",
    "                \"question\": question, \n",
    "                \"context\": context,\n",
    "                \"chat_history\": chat_context\n",
    "            })\n",
    "            \n",
    "            # Save the QA pair to memory\n",
    "            self.memory.chat_memory.add_messages([\n",
    "                HumanMessage(content=question),\n",
    "                AIMessage(content=answer)\n",
    "            ])\n",
    "            \n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating answer: {e}\")\n",
    "            return \"I'm sorry, I encountered an error while generating your answer. Please try rephrasing your question.\"\n",
    "    \n",
    "    def generate_combined_answer(\n",
    "        self, \n",
    "        question: str, \n",
    "        query_results: Dict[str, List[RetrievedDocument]]\n",
    "    ) -> str:\n",
    "        \"\"\"Generates a combined answer from multiple query results with LLM fallback.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            query_results: Dictionary mapping queries to retrieved documents\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        # Combine all relevant documents from different queries\n",
    "        all_docs = []\n",
    "        for query, docs in query_results.items():\n",
    "            all_docs.extend(docs[:self.max_docs_per_query])\n",
    "        \n",
    "        # Evaluate if the documents are sufficient\n",
    "        is_sufficient, confidence = self.evaluate_document_relevance(question, all_docs)\n",
    "        \n",
    "        # If documents are insufficient, use LLM fallback\n",
    "        if not is_sufficient or confidence < 0.2:  # Adjust threshold as needed\n",
    "            console.print(\"[yellow]Retrieved documents insufficient. Using LLM fallback...[/yellow]\")\n",
    "            return self.generate_llm_answer(question)\n",
    "        \n",
    "        # Get chat history from memory if available\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        # Create chat history string for context if available\n",
    "        chat_context = \"\"\n",
    "        if chat_history:\n",
    "            chat_context = \"Previous conversation:\\n\"\n",
    "            for message in chat_history[-3:]:  # Use last 3 messages for context\n",
    "                if hasattr(message, \"content\"):\n",
    "                    role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                    chat_context += f\"{role}: {message.content}\\n\"\n",
    "        \n",
    "        # Combine all context sections\n",
    "        all_context_sections = []\n",
    "        \n",
    "        for query, docs in query_results.items():\n",
    "            # Use only the top N documents for each query\n",
    "            docs_for_query = docs[:self.max_docs_per_query]\n",
    "            if docs_for_query:\n",
    "                all_context_sections.append(f\"Results for query: '{query}'\")\n",
    "                for i, doc in enumerate(docs_for_query, 1):\n",
    "                    section = f\"Document {i} [Relevance: {doc.score:.2f}]:\\n{doc.document.page_content}\"\n",
    "                    \n",
    "                    # Add metadata if available\n",
    "                    if hasattr(doc.document, 'metadata') and doc.document.metadata:\n",
    "                        source = doc.document.metadata.get('source', 'Unknown')\n",
    "                        section += f\"\\nSource: {source}\"\n",
    "                        \n",
    "                    all_context_sections.append(section)\n",
    "        \n",
    "        # Join all context sections\n",
    "        combined_context = \"\\n\\n---\\n\\n\".join(all_context_sections)\n",
    "        \n",
    "        # Create a prompt that emphasizes synthesizing information across different query results\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"context\", \"chat_history\"],\n",
    "            template=\"\"\"You are a helpful scientific research assistant analyzing scientific papers. \n",
    "            The user's question has been reformulated in several ways, and each formulation returned different documents.\n",
    "            \n",
    "            Guidelines:\n",
    "            - Synthesize information across ALL retrieved documents to provide a comprehensive answer\n",
    "            - Compare and contrast findings from different sources\n",
    "            - Highlight the most relevant information from each source\n",
    "            - Cite the specific documents you're referencing (e.g., \"According to the paper in Document 3...\")\n",
    "            - If information conflicts across sources, explain the different perspectives\n",
    "            - If the information isn't in the context, indicate what's missing\n",
    "            - Maintain scientific accuracy above all else\n",
    "            \n",
    "            {chat_history}\n",
    "            \n",
    "            Context from multiple query formulations:\n",
    "            {context}\n",
    "            \n",
    "            Original Question: {question}\n",
    "            \n",
    "            Answer:\"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Generate answer\n",
    "            answer = (prompt | self.llm).invoke({\n",
    "                \"question\": question, \n",
    "                \"context\": combined_context,\n",
    "                \"chat_history\": chat_context\n",
    "            })\n",
    "            \n",
    "            # Save the QA pair to memory\n",
    "            self.memory.chat_memory.add_messages([\n",
    "                HumanMessage(content=question),\n",
    "                AIMessage(content=answer)\n",
    "            ])\n",
    "            \n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating combined answer: {e}\")\n",
    "            return \"I'm sorry, I encountered an error while generating your answer. Please try rephrasing your question.\"\n",
    "            \n",
    "    def evaluate_document_relevance(self, question: str, docs: List[RetrievedDocument]) -> Tuple[bool, float]:\n",
    "        \"\"\"Evaluates whether documents are sufficient to answer the question.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            docs: List of retrieved documents\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (is_sufficient, confidence_score)\n",
    "        \"\"\"\n",
    "        if not docs:\n",
    "            return False, 0.0\n",
    "            \n",
    "        # If all docs have very low scores, they're likely not relevant\n",
    "        avg_score = sum(doc.score for doc in docs) / len(docs)\n",
    "        \n",
    "        # Create a prompt to evaluate document relevance\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "        You are evaluating whether a set of retrieved documents contains information that can help \n",
    "        to answer a user's question.\n",
    "        \n",
    "        User Question: {question}\n",
    "        \n",
    "        Retrieved Information:\n",
    "        {doc_summaries}\n",
    "        \n",
    "        Please analyze whether the retrieved documents is somewhere related to the question and can in a way contribute or provide some sources and information.\n",
    "        Respond with a JSON object:\n",
    "        {{\n",
    "          \"is_relevant\": true/false,\n",
    "          \"confidence\": <number between 0-1>,\n",
    "          \"explanation\": \"<brief explanation>\"\n",
    "        }}\n",
    "        \n",
    "        Only respond with the JSON object.\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create short summaries of each document\n",
    "        doc_summaries = []\n",
    "        for i, doc in enumerate(docs[:3]):  # Use top 3 docs for evaluation\n",
    "            summary = doc.document.page_content[:200] + \"...\" if len(doc.document.page_content) > 200 else doc.document.page_content\n",
    "            doc_summaries.append(f\"Document {i+1} [Score: {doc.score:.2f}]: {summary}\")\n",
    "        \n",
    "        doc_summaries_text = \"\\n\\n\".join(doc_summaries)\n",
    "        \n",
    "        try:\n",
    "            # Parse the LLM response as JSON\n",
    "            response = self.llm.invoke(\n",
    "                prompt.format(question=question, doc_summaries=doc_summaries_text)\n",
    "            )\n",
    "            \n",
    "            # Extract JSON from the response\n",
    "            json_match = re.search(r'\\{.*\\}', response.replace('\\n', ' '), re.DOTALL)\n",
    "            if json_match:\n",
    "                result = json.loads(json_match.group(0))\n",
    "                is_sufficient = result.get(\"is_relevant\", False)\n",
    "                confidence = result.get(\"confidence\", 0.0)\n",
    "                \n",
    "                logger.info(f\"Document relevance: Sufficient={is_sufficient}, Confidence={confidence}\")\n",
    "                logger.info(f\"Explanation: {result.get('explanation', 'No explanation provided')}\")\n",
    "                \n",
    "                return is_sufficient, confidence\n",
    "            else:\n",
    "                # If JSON parsing fails, use heuristics based on average score\n",
    "                return avg_score > self.relevance_threshold, avg_score\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating document relevance: {e}\")\n",
    "            # Fall back to using avg score\n",
    "            return avg_score > self.relevance_threshold, avg_score\n",
    "\n",
    "    def generate_llm_answer(self, question: str) -> str:\n",
    "        \"\"\"Generates an answer directly from the LLM when documents aren't sufficient.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        # Get chat history from memory if available\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        # Create chat history string for context if available\n",
    "        chat_context = \"\"\n",
    "        if chat_history:\n",
    "            chat_context = \"Previous conversation:\\n\"\n",
    "            for message in chat_history[-3:]:  # Use last 3 messages for context\n",
    "                if hasattr(message, \"content\"):\n",
    "                    role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                    chat_context += f\"{role}: {message.content}\\n\"\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"chat_history\"],\n",
    "            template=\"\"\"You are a helpful scientific research assistant. \n",
    "            \n",
    "            The user has asked a question, but we couldn't find relevant documents in our scientific database.\n",
    "            Since this appears to be a question you can answer from your general knowledge, please provide\n",
    "            a helpful response.\n",
    "            \n",
    "            Guidelines:\n",
    "            - Be clear that you're answering from general knowledge rather than specific papers\n",
    "            - Provide accurate, factual information\n",
    "            - If the question is about a very specialized scientific topic that requires references to papers,\n",
    "              indicate that you lack specific citations but can provide general information\n",
    "            - If it's a basic concept, provide a thorough explanation\n",
    "            \n",
    "            {chat_history}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Answer:\"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Generate answer\n",
    "            answer = (prompt | self.llm).invoke({\n",
    "                \"question\": question,\n",
    "                \"chat_history\": chat_context\n",
    "            })\n",
    "            \n",
    "            # Save the QA pair to memory\n",
    "            self.memory.chat_memory.add_messages([\n",
    "                HumanMessage(content=question),\n",
    "                AIMessage(content=answer)\n",
    "            ])\n",
    "            \n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating LLM answer: {e}\")\n",
    "            return \"I'm sorry, I couldn't find relevant information in my scientific database and encountered an error trying to provide a general answer. Please try rephrasing your question.\"\n",
    "    \n",
    "    def ask_with_memory(self, question: str, num_results: int = 5) -> str:\n",
    "        \"\"\"Uses conversation memory to process follow-up questions.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            num_results: Number of results to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # First, check if this is a question we can answer directly from memory\n",
    "            can_direct_answer, direct_answer = self.can_answer_without_retrieval(question)\n",
    "            if can_direct_answer:\n",
    "                console.print(\"[bold green]Question can be answered directly from conversation history...[/bold green]\")\n",
    "                # Save the QA pair to memory manually\n",
    "                self.memory.chat_memory.add_messages([\n",
    "                    HumanMessage(content=question),\n",
    "                    AIMessage(content=direct_answer)\n",
    "                ])\n",
    "                return direct_answer\n",
    "# Otherwise, use the full query improvement pipeline\n",
    "            \n",
    "            # Step 1: Rate the query\n",
    "            console.print(\"\\n[bold cyan]Evaluating your query (with memory context)...[/bold cyan]\")\n",
    "            rating_result = self.rate_query(question)\n",
    "            \n",
    "            rating_color = \"green\" if rating_result['rating'] >= 4 else \"yellow\" if rating_result['rating'] >= 3 else \"red\"\n",
    "            console.print(f\"[bold {rating_color}]Query Rating: {rating_result['rating']}/5[/bold {rating_color}]\")\n",
    "            console.print(f\"Explanation: {rating_result['explanation']}\")\n",
    "            console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            \n",
    "            # Step 2: Suggest rewrites if the rating is less than perfect\n",
    "            rewritten_queries = []\n",
    "            if rating_result[\"rating\"] < 5:\n",
    "                console.print(\"[bold cyan]Generating improved query variations...[/bold cyan]\")\n",
    "                # Get chat history for context in rewrites\n",
    "                chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "                rewritten_queries = self.suggest_rewrites(question, chat_history)\n",
    "                console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            \n",
    "            # Step 3: Present options to the user\n",
    "            query_options = self.present_query_options(question, rewritten_queries)\n",
    "            console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            \n",
    "            # Step 4: Get user selection\n",
    "            console.print(\"[bold cyan]Select queries to use:[/bold cyan]\")\n",
    "            console.print(\"Enter the numbers of the queries you want to use (comma-separated, e.g., '0,2,3')\")\n",
    "            selected_indices_input = input(\"> \")\n",
    "            \n",
    "            try:\n",
    "                selected_indices = [int(idx.strip()) for idx in selected_indices_input.split(\",\")]\n",
    "            except ValueError:\n",
    "                console.print(\"[bold red]Invalid input. Using original query only.[/bold red]\")\n",
    "                selected_indices = [0]  # Default to original query\n",
    "            \n",
    "            # Get the selected queries\n",
    "            selected_queries = []\n",
    "            for idx in selected_indices:\n",
    "                if idx == 0:  # Original query\n",
    "                    selected_queries.append(question)\n",
    "                elif 0 < idx <= len(rewritten_queries):  # Rewritten query\n",
    "                    query_text = rewritten_queries[idx-1]\n",
    "                    selected_queries.append(query_text)\n",
    "            \n",
    "            if not selected_queries:\n",
    "                console.print(\"[bold red]No valid queries selected. Using original query.[/bold red]\")\n",
    "                selected_queries = [question]\n",
    "                \n",
    "            console.print(f\"\\n[bold green]Selected {len(selected_queries)} queries for retrieval.[/bold green]\")\n",
    "            console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            \n",
    "            # Step 5: Retrieve documents\n",
    "            console.print(\"[bold cyan]Retrieving relevant documents...[/bold cyan]\")\n",
    "            \n",
    "            if len(selected_queries) > 1:\n",
    "                # If multiple queries were selected, use the multi-query approach\n",
    "                docs, query_docs_map = self.retrieve_documents(selected_queries, k=num_results)\n",
    "                \n",
    "                # Generate a combined answer\n",
    "                console.print(\"\\n[bold cyan]Generating combined answer with conversation+docs context...[/bold cyan]\")\n",
    "                answer = self.generate_combined_answer(question, query_docs_map)\n",
    "            else:\n",
    "                # If only one query was selected, use the standard approach\n",
    "                try:\n",
    "                    retrieved_docs = []\n",
    "                    results = self.vector_db.similarity_search_with_relevance_scores(selected_queries[0], k=num_results)\n",
    "                    \n",
    "                    for i, (doc, score) in enumerate(results, 1):\n",
    "                        retrieved_docs.append(RetrievedDocument(\n",
    "                            document=doc,\n",
    "                            score=score,\n",
    "                            query=selected_queries[0],\n",
    "                            rank=i\n",
    "                        ))\n",
    "                    \n",
    "                    console.print(f\"[bold green]Retrieved {len(retrieved_docs)} documents[/bold green]\")\n",
    "                    \n",
    "                    # Show previews of the retrieved documents\n",
    "                    console.print(\"\\n[bold cyan]Top retrieved documents:[/bold cyan]\")\n",
    "                    for i, doc in enumerate(retrieved_docs[:5], 1):\n",
    "                        score_color = \"green\" if doc.score > 0.8 else \"yellow\" if doc.score > 0.6 else \"red\"\n",
    "                        console.print(f\"{i}. [bold {score_color}]Score: {doc.score:.4f}[/bold {score_color}]\")\n",
    "                        \n",
    "                        preview = doc.document.page_content[:150] + \"...\" if len(doc.document.page_content) > 150 else doc.document.page_content\n",
    "                        console.print(f\"   Preview: {preview}\")\n",
    "                        \n",
    "                        if hasattr(doc.document, 'metadata') and doc.document.metadata:\n",
    "                            console.print(f\"   Source: {doc.document.metadata.get('source', 'Unknown')}\")\n",
    "                    \n",
    "                    # Generate answer with memory context\n",
    "                    console.print(\"\\n[bold cyan]Generating answer with conversation + doc context...[/bold cyan]\")\n",
    "                    answer = self.generate_final_answer(question, retrieved_docs)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error in retrieval: {e}\")\n",
    "                    return f\"I'm sorry, I encountered an error while retrieving documents: {str(e)}\"\n",
    "            \n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in ask_with_memory: {e}\")\n",
    "            return f\"I'm sorry, I encountered an error while processing your question: {str(e)}\"\n",
    "\n",
    "    def search_with_query_feedback(self, query: str, num_results: int = 5) -> str:\n",
    "        \"\"\"Main pipeline that processes a query and returns an answer.\"\"\"\n",
    "        # Step 1: Rate the query\n",
    "        console.print(\"\\n[bold cyan]Evaluating your query...[/bold cyan]\")\n",
    "        rating_result = self.rate_query(query)\n",
    "            \n",
    "        rating_color = \"green\" if rating_result['rating'] >= 4 else \"yellow\" if rating_result['rating'] >= 3 else \"red\"\n",
    "        console.print(f\"[bold {rating_color}]Query Rating: {rating_result['rating']}/5[/bold {rating_color}]\")\n",
    "        console.print(f\"Explanation: {rating_result['explanation']}\")\n",
    "        console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "            \n",
    "        # Step 2: Suggest rewrites if the rating is less than perfect\n",
    "        rewritten_queries = []\n",
    "        if rating_result[\"rating\"] < 5:\n",
    "            console.print(\"[bold cyan]Generating improved query variations...[/bold cyan]\")\n",
    "            rewritten_queries = self.suggest_rewrites(query)\n",
    "            console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        # Step 3: Present options to the user\n",
    "        query_options = self.present_query_options(query, rewritten_queries)\n",
    "        console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        \n",
    "        # Step 4: Get user selection\n",
    "        console.print(\"[bold cyan]Select queries to use:[/bold cyan]\")\n",
    "        console.print(\"Enter the numbers of the queries you want to use (comma-separated, e.g., '0,2,3')\")\n",
    "        selected_indices_input = input(\"> \")\n",
    "            \n",
    "        try:\n",
    "            selected_indices = [int(idx.strip()) for idx in selected_indices_input.split(\",\")]\n",
    "        except ValueError:\n",
    "            console.print(\"[bold red]Invalid input. Using original query only.[/bold red]\")\n",
    "            selected_indices = [0]  # Default to original query\n",
    "        \n",
    "        # Get the selected queries\n",
    "        selected_queries = []\n",
    "        for idx in selected_indices:\n",
    "            if idx == 0:  # Original query\n",
    "                selected_queries.append(query)\n",
    "            elif 0 < idx <= len(rewritten_queries):  # Rewritten query\n",
    "                query_text = rewritten_queries[idx-1]\n",
    "                selected_queries.append(query_text)\n",
    "                \n",
    "        if not selected_queries:\n",
    "            console.print(\"[bold red]No valid queries selected. Using original query.[/bold red]\")\n",
    "            selected_queries = [query]\n",
    "            \n",
    "        console.print(f\"\\n[bold green]Selected {len(selected_queries)} queries for retrieval.[/bold green]\")\n",
    "        console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        \n",
    "        # Step 5: Retrieve documents\n",
    "        console.print(\"[bold cyan]Retrieving relevant documents...[/bold cyan]\")\n",
    "        \n",
    "        if len(selected_queries) > 1:\n",
    "            # If multiple queries were selected, use the multi-query approach\n",
    "            print(\"LOG123: multiple queries this is working\")\n",
    "            docs, query_docs_map = self.retrieve_documents(selected_queries, k=num_results)\n",
    "            # Generate a combined answer\n",
    "            console.print(\"\\n[bold cyan]Generating combined answer with documents context...[/bold cyan]\")\n",
    "            answer = self.generate_combined_answer(query, query_docs_map)\n",
    "        else:\n",
    "            # If only one query was selected, use the standard approach\n",
    "            print(\"LOG123: only this is working\")\n",
    "            try:\n",
    "                retrieved_docs = []\n",
    "                results = self.vector_db.similarity_search_with_relevance_scores(selected_queries[0], k=num_results)\n",
    "                \n",
    "                for i, (doc, score) in enumerate(results, 1):\n",
    "                    retrieved_docs.append(RetrievedDocument(\n",
    "                        document=doc,\n",
    "                        score=score,\n",
    "                        query=selected_queries[0],\n",
    "                        rank=i\n",
    "                    ))\n",
    "                \n",
    "                console.print(f\"[bold green]Retrieved {len(retrieved_docs)} documents[/bold green]\")\n",
    "                \n",
    "                # Show previews of the retrieved documents\n",
    "                console.print(\"\\n[bold cyan]Top retrieved documents:[/bold cyan]\")\n",
    "                for i, doc in enumerate(retrieved_docs[:5], 1):\n",
    "                    score_color = \"green\" if doc.score > 0.8 else \"yellow\" if doc.score > 0.6 else \"red\"\n",
    "                    console.print(f\"{i}. [bold {score_color}]Score: {doc.score:.4f}[/bold {score_color}]\")\n",
    "                    \n",
    "                    preview = doc.document.page_content[:150] + \"...\" if len(doc.document.page_content) > 150 else doc.document.page_content\n",
    "                    console.print(f\"   Preview: {preview}\")\n",
    "                    \n",
    "                    if hasattr(doc.document, 'metadata') and doc.document.metadata:\n",
    "                        console.print(f\"   Source: {doc.document.metadata.get('source', 'Unknown')}\")\n",
    "                \n",
    "                # Generate answer with memory context\n",
    "                console.print(\"\\n[bold cyan]Generating answer with document context...[/bold cyan]\")\n",
    "                answer = self.generate_final_answer(query, retrieved_docs)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in retrieval: {e}\")\n",
    "                return f\"I'm sorry, I encountered an error while retrieving documents: {str(e)}\"\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def process_query(self, query: str, use_memory: bool = False, num_results: int = 5) -> str:\n",
    "        \"\"\"Main entry point that decides whether to use memory or the full pipeline.\n",
    "        \n",
    "        Args:\n",
    "            query: User's question\n",
    "            use_memory: Whether to explicitly use memory mode\n",
    "            num_results: Number of results to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Generated answer\n",
    "        \"\"\"\n",
    "        # Check if this might be a follow-up question that should use memory\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        should_use_memory = use_memory and (chat_history and self._is_likely_followup(query))\n",
    "        print(\"should_use_memory\",should_use_memory)\n",
    "        if should_use_memory:\n",
    "            console.print(\"[bold cyan]Using conversation memory to process this query...[/bold cyan]\")\n",
    "            return self.ask_with_memory(query, num_results)\n",
    "        else:\n",
    "            console.print(\"[bold cyan]Using full query improvement pipeline...[/bold cyan]\")\n",
    "            return self.search_with_query_feedback(query, num_results)\n",
    "    \n",
    "    def _is_likely_followup(self, query: str) -> bool:\n",
    "        \"\"\"Heuristically determines if a query is likely a follow-up question.\n",
    "        \n",
    "        Args:\n",
    "            query: User's question\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating if this is likely a follow-up\n",
    "        \"\"\"\n",
    "        # Look for pronouns, references, and questions that seem to refer to previous context\n",
    "        followup_indicators = [\n",
    "            # Pronouns\n",
    "            \"it\", \"this\", \"that\", \"they\", \"them\", \"these\", \"those\",\n",
    "            # Reference terms\n",
    "            \"previous\", \"earlier\", \"above\", \"mentioned\", \"last\", \"former\",\n",
    "            # Follow-up phrases\n",
    "            \"what about\", \"how about\", \"tell me more\", \"elaborate\", \"clarify\", \"explain further\",\n",
    "            \"can you expand\", \"additionally\", \"furthermore\", \"also\", \"related to that\",\n",
    "            # Short questions that likely need context\n",
    "            \"why\", \"how does\", \"can you explain\", \"what does\", \"what is\", \"who is\"\n",
    "        ]\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Check for any of the indicators\n",
    "        if any(indicator in query_lower for indicator in followup_indicators):\n",
    "            return True\n",
    "            \n",
    "        # # Check for very short queries (likely follow-ups)\n",
    "        # if len(query.split()) < 4:\n",
    "        #     return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        \"\"\"Clears the conversation memory.\"\"\"\n",
    "        self.memory.clear()\n",
    "        console.print(\"[bold green]Conversation memory cleared.[/bold green]\")\n",
    "        \n",
    "    def get_chat_history(self) -> str:\n",
    "        \"\"\"Returns the formatted chat history.\n",
    "        \n",
    "        Returns:\n",
    "            String representation of chat history\n",
    "        \"\"\"\n",
    "        chat_history = self.memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        \n",
    "        if not chat_history:\n",
    "            return \"No conversation history.\"\n",
    "            \n",
    "        history_str = \"\"\n",
    "        for i, message in enumerate(chat_history):\n",
    "            if hasattr(message, \"content\"):\n",
    "                role = \"Human\" if isinstance(message, HumanMessage) else \"Assistant\"\n",
    "                history_str += f\"{role}: {message.content}\\n\\n\"\n",
    "                \n",
    "        return history_str\n",
    "\n",
    "    def Load_query(self, query):\n",
    "        \"\"\"\n",
    "        Load research papers from arXiv based on the given query and store them in the temporary database.\n",
    "        Returns the top 3 papers information.\n",
    "        \"\"\"\n",
    "        console.print(f\"[bold cyan]Searching arXiv for papers related to:[/bold cyan] {query}\")\n",
    "        \n",
    "        try:\n",
    "            # Use the working ArxivLoader from langchain_community\n",
    "            loader = ArxivLoader(\n",
    "                query=query,\n",
    "                load_max_docs=3,  # Get top 3 papers\n",
    "                load_all_available_meta=True\n",
    "            )\n",
    "            \n",
    "            documents = loader.load()\n",
    "            console.print(f\"[green]Found {len(documents)} relevant papers[/green]\")\n",
    "            \n",
    "            # Download PDFs for more complete content\n",
    "            enhanced_docs = self.download_pdf_content(documents)\n",
    "            \n",
    "            # Store documents in temporary database\n",
    "            paper_ids = self.StoreInDB(enhanced_docs)\n",
    "            \n",
    "            # Display basic information about the loaded papers\n",
    "            self.display_paper_summaries(enhanced_docs)\n",
    "            \n",
    "            return paper_ids\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]Error loading papers: {str(e)}[/bold red]\")\n",
    "            # # Fall back to simulated papers if needed\n",
    "            # if self.allow_fallback:\n",
    "            #     console.print(\"[yellow]Using fallback data for demonstration purposes.[/yellow]\")\n",
    "            #     return self.create_fallback_papers(query)\n",
    "            return []\n",
    "    \n",
    "    def download_pdf_content(self, documents):\n",
    "        \"\"\"\n",
    "        Enhance documents by downloading the full PDF content when available.\n",
    "        \"\"\"\n",
    "        enhanced_docs = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            try:\n",
    "                # Get metadata\n",
    "                metadata = doc.metadata\n",
    "                title = metadata.get(\"Title\", \"Untitled\")\n",
    "                console.print(f\"[cyan]Processing paper: {title}[/cyan]\")\n",
    "                \n",
    "                # Try to find arXiv ID from page content\n",
    "                arxiv_id = None\n",
    "                match = re.search(r'arXiv:(\\d{4}\\.\\d{5})', doc.page_content)\n",
    "                \n",
    "                if match:\n",
    "                    arxiv_id = match.group(1)\n",
    "                else:\n",
    "                    # Try to extract from Entry ID\n",
    "                    entry_id = metadata.get(\"Entry ID\", \"\")\n",
    "                    id_match = re.search(r'abs/(\\d{4}\\.\\d{5})', entry_id)\n",
    "                    if id_match:\n",
    "                        arxiv_id = id_match.group(1)\n",
    "                \n",
    "                if arxiv_id:\n",
    "                    # Generate PDF URL\n",
    "                    pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "                    console.print(f\"[cyan]Found PDF URL: {pdf_url}[/cyan]\")\n",
    "                    \n",
    "                    # Create temp directory if it doesn't exist\n",
    "                    temp_dir = \"./temp_pdfs\"\n",
    "                    os.makedirs(temp_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Download PDF\n",
    "                    pdf_filename = f\"{temp_dir}/{arxiv_id}.pdf\"\n",
    "                    \n",
    "                    # Check if file already exists\n",
    "                    if not os.path.exists(pdf_filename):\n",
    "                        console.print(f\"[cyan]Downloading PDF...[/cyan]\")\n",
    "                        response = requests.get(pdf_url, timeout=30)\n",
    "                        with open(pdf_filename, 'wb') as f:\n",
    "                            f.write(response.content)\n",
    "                    \n",
    "                    # Load PDF content\n",
    "                    console.print(f\"[cyan]Extracting content from PDF...[/cyan]\")\n",
    "                    pdf_loader = PyPDFLoader(pdf_filename)\n",
    "                    pdf_docs = pdf_loader.load()\n",
    "                    \n",
    "                    # Create enhanced document with PDF content\n",
    "                    full_content = doc.page_content + \"\\n\\n\" + \"\\n\\n\".join([pdf_doc.page_content for pdf_doc in pdf_docs])\n",
    "                    \n",
    "                    # Update metadata with PDF info\n",
    "                    updated_metadata = metadata.copy()\n",
    "                    updated_metadata[\"pdf_url\"] = pdf_url\n",
    "                    updated_metadata[\"pdf_path\"] = pdf_filename\n",
    "                    updated_metadata[\"pdf_pages\"] = len(pdf_docs)\n",
    "                    \n",
    "                    enhanced_doc = Document(page_content=full_content, metadata=updated_metadata)\n",
    "                    enhanced_docs.append(enhanced_doc)\n",
    "                    \n",
    "                else:\n",
    "                    # If PDF can't be found, use original document\n",
    "                    console.print(f\"[yellow]Could not extract arXiv ID for {title}. Using abstract only.[/yellow]\")\n",
    "                    enhanced_docs.append(doc)\n",
    "            \n",
    "            except Exception as e:\n",
    "                console.print(f\"[yellow]Error enhancing document: {str(e)}. Using abstract only.[/yellow]\")\n",
    "                enhanced_docs.append(doc)\n",
    "        \n",
    "        return enhanced_docs\n",
    "    \n",
    "    def StoreInDB(self, documents):\n",
    "        \"\"\"\n",
    "        Store loaded documents in the temporary vector database.\n",
    "        Returns list of document IDs.\n",
    "        \"\"\"\n",
    "        paper_ids = []\n",
    "        \n",
    "        console.print(\"[bold cyan]Storing papers in temporary database...[/bold cyan]\")\n",
    "        \n",
    "        try:\n",
    "            # Split documents into chunks for better retrieval\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000, \n",
    "                chunk_overlap=200\n",
    "            )\n",
    "            \n",
    "            for doc in documents:\n",
    "                # Create document chunks\n",
    "                chunks = text_splitter.split_documents([doc])\n",
    "                \n",
    "                # Create unique ID for the paper\n",
    "                paper_id = f\"paper_{uuid.uuid4().hex[:8]}\"\n",
    "                paper_ids.append(paper_id)\n",
    "                \n",
    "                # Add metadata to each chunk and sanitize it\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    # Create clean metadata dictionary\n",
    "                    clean_metadata = {\n",
    "                        \"paper_id\": paper_id,\n",
    "                        \"chunk_id\": i,\n",
    "                        \"title\": doc.metadata.get(\"Title\", \"Untitled\"),\n",
    "                        \"authors\": doc.metadata.get(\"Authors\", \"Unknown\"),\n",
    "                        \"published\": doc.metadata.get(\"Published\", \"Unknown\")\n",
    "                    }\n",
    "                    \n",
    "                    # Ensure all values are valid types (str, int, float, bool)\n",
    "                    for key, value in clean_metadata.items():\n",
    "                        if value is None:\n",
    "                            clean_metadata[key] = \"None\"  # Convert None to string\n",
    "                        elif not isinstance(value, (str, int, float, bool)):\n",
    "                            clean_metadata[key] = str(value)  # Convert complex types to string\n",
    "                    \n",
    "                    # Replace existing metadata with clean version\n",
    "                    chunk.metadata = clean_metadata\n",
    "                \n",
    "                # Add to vector database\n",
    "                self.vector_db.add_documents(chunks)\n",
    "            \n",
    "            # Persist the temporary database\n",
    "            self.vector_db.persist()\n",
    "            console.print(f\"[green]Successfully stored {len(documents)} papers in database[/green]\")\n",
    "            # Fixed typo from 'onsole' to 'console' and removed debug line\n",
    "            return paper_ids\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]Error storing documents: {str(e)}[/bold red]\")\n",
    "            return []\n",
    "    \n",
    "    def display_paper_summaries(self, documents):\n",
    "        \"\"\"Display a summary of each loaded paper.\"\"\"\n",
    "        console.print(\"\\n[bold cyan]Loaded Papers:[/bold cyan]\")\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            title = doc.metadata.get(\"Title\", \"Untitled\")\n",
    "            authors = doc.metadata.get(\"Authors\", \"Unknown\")\n",
    "            published = doc.metadata.get(\"Published\", \"Unknown\")\n",
    "            \n",
    "            console.print(f\"\\n[bold]{i+1}. {title}[/bold]\")\n",
    "            console.print(f\"   Authors: {authors}\")\n",
    "            console.print(f\"   Published: {published}\")\n",
    "            \n",
    "            # Generate a brief summary of the paper\n",
    "            summary = self.generate_paper_summary(doc)\n",
    "            console.print(f\"   Summary: {summary}\")\n",
    "    \n",
    "    def generate_paper_summary(self, document):\n",
    "        \"\"\"Generate a concise summary of a paper using the LLM.\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            Generate a concise 5-sentence summary of the following research paper:\n",
    "            \n",
    "            Title: {document.metadata.get('Title', 'Untitled')}\n",
    "            Abstract: {document.page_content[:500]}...\n",
    "            \n",
    "            Summary:\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.llm.predict(prompt)\n",
    "            return response.strip()\n",
    "        except:\n",
    "            return \"Summary not available.\"\n",
    "    \n",
    "    def query_temp_database(self, query, paper_ids=None, k=5):\n",
    "        \"\"\"\n",
    "        Query the temporary database with the given query.\n",
    "        \n",
    "        Args:\n",
    "            query: The query string\n",
    "            paper_ids: Optional list of paper IDs to restrict the search to\n",
    "            k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of relevant document chunks\n",
    "        \"\"\"\n",
    "        console.print(f\"[bold cyan]Searching temporary database for:[/bold cyan] {query}\")\n",
    "        \n",
    "        try:\n",
    "            # Create filter for specific papers if provided\n",
    "            filter_dict = None\n",
    "            if paper_ids:\n",
    "                filter_dict = {\"paper_id\": {\"$in\": paper_ids}}\n",
    "            \n",
    "            # Query the vector database\n",
    "            search_results = self.vector_db.similarity_search(\n",
    "                query=query,\n",
    "                k=k,\n",
    "                filter=filter_dict\n",
    "            )\n",
    "            \n",
    "            console.print(f\"[green]Found {len(search_results)} relevant sections[/green]\")\n",
    "            return search_results\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]Error querying database: {str(e)}[/bold red]\")\n",
    "            return []\n",
    "    \n",
    "    def answer_research_question(self, query, context_docs=None):\n",
    "        \"\"\"\n",
    "        Answer a research question using context from the temporary database.\n",
    "        \n",
    "        Args:\n",
    "            query: The research question\n",
    "            context_docs: Optional pre-retrieved context documents\n",
    "            \n",
    "        Returns:\n",
    "            Detailed answer to the research question\n",
    "        \"\"\"\n",
    "        # If context not provided, retrieve it\n",
    "        if not context_docs:\n",
    "            context_docs = self.query_temp_database(query, k=5)\n",
    "        \n",
    "        if not context_docs:\n",
    "            return \"I couldn't find relevant information to answer your question.\"\n",
    "        \n",
    "        # Prepare context\n",
    "        context_text = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(context_docs)])\n",
    "        \n",
    "        # Prepare sources\n",
    "        sources = []\n",
    "        for doc in context_docs:\n",
    "            paper_title = doc.metadata.get(\"title\", \"Unknown Title\")\n",
    "            authors = doc.metadata.get(\"authors\", \"Unknown Authors\")\n",
    "            source = f\"- {paper_title} by {authors}\"\n",
    "            if source not in sources:\n",
    "                sources.append(source)\n",
    "        \n",
    "        # Generate the answer\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful research assistant. Answer the following question based on the provided research paper extracts.\n",
    "        \n",
    "        Question: {query}\n",
    "        \n",
    "        Here are relevant extracts from research papers:\n",
    "        {context_text}\n",
    "        \n",
    "        Provide a comprehensive answer, citing specific information from the papers.\n",
    "        Make sure to organize your response clearly and highlight key insights.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            answer = self.llm.predict(prompt)\n",
    "            \n",
    "            # Add sources at the end\n",
    "            final_answer = f\"{answer}\\n\\nSources:\\n\" + \"\\n\".join(sources)\n",
    "            return final_answer\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Error generating answer: {str(e)}\"\n",
    "\n",
    "\n",
    "def main():    \n",
    "    \"\"\"Main function to run the research assistant.\"\"\"\n",
    "    try:\n",
    "        from langchain_community.llms import OpenAI\n",
    "        from langchain_community.vectorstores import Chroma\n",
    "        from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "        \n",
    "        # Check for API key\n",
    "        if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "            console.print(\"[bold red]ERROR: OPENAI_API_KEY environment variable not set.[/bold red]\")\n",
    "            console.print(f\"Please set your API key with: export OPENAI_API_KEY={os.environ['OPENAI_API_KEY']}\")\n",
    "            return\n",
    "            \n",
    "        # Load models and vector database\n",
    "        console.print(\"[bold cyan]Initializing SageRAG Research Assistant...[/bold cyan]\")\n",
    "        \n",
    "        console.print(\"Loading embedding model...\")\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        console.print(\"Loading language model...\")\n",
    "        llm = OllamaLLM(model=\"llama3.2\", temperature=0.2, top_p=0.9)\n",
    "        \n",
    "        console.print(\"Connecting to vector database...\")\n",
    "\n",
    "        vector_db = Chroma(persist_directory= DB_DIR, embedding_function=embeddings)\n",
    "        \n",
    "        console.print(\"[bold green]Initialization complete![/bold green]\")\n",
    "        \n",
    "        # Initialize the research assistant\n",
    "        assistant = ResearchAssistant(llm=llm, vector_db=vector_db)\n",
    "        print(assistant.vector_db._collection.count())\n",
    "        # Display welcome message\n",
    "        console.print(Panel.fit(\n",
    "            Markdown(\"# SageRAG Research Assistant\\n\\nAsk questions about scientific papers in the database.\"),\n",
    "            title=\"Welcome\",\n",
    "            border_style=\"cyan\"\n",
    "        ))\n",
    "        \n",
    "        # Main interaction loop\n",
    "        while True:\n",
    "            console.print(\"\\n[bold cyan]Options:[/bold cyan]\")\n",
    "            console.print(\"1. Ask a question\")\n",
    "            console.print(\"2. View conversation history\")\n",
    "            console.print(\"3. Clear conversation history\")\n",
    "            console.print(\"4. Go for Advanced Research\")\n",
    "            console.print(\"5. Exit\")\n",
    "            \n",
    "            choice = input(\"\\nEnter your choice (1-5): \").strip()\n",
    "            \n",
    "            if choice == \"1\":\n",
    "                query = input(f\"\\n[bold]Enter your query:[/bold] \")\n",
    "                if not query.strip():\n",
    "                    console.print(f\"[yellow]Empty query. Please try again.[/yellow]\")\n",
    "                    continue\n",
    "                    \n",
    "                # Ask the user whether to use memory mode or full pipeline\n",
    "                use_memory_input = input(\"Use conversation memory? (y/n): \").lower()\n",
    "                use_memory = use_memory_input.startswith('y')\n",
    "                \n",
    "                # Process the query\n",
    "                console.print(f\"\\n[bold cyan]Processing your query...[/bold cyan]\")\n",
    "                answer = assistant.process_query(query, use_memory=use_memory)\n",
    "                \n",
    "                # Display the final answer nicely formatted\n",
    "                console.print(Panel(\n",
    "                    Markdown(answer),\n",
    "                    title=\"Answer\",\n",
    "                    border_style=\"green\",\n",
    "                    width=100\n",
    "                ))\n",
    "\n",
    "                console.print(\"\\n[bold cyan]Would you like to get an llm generated answer?[/bold cyan]\")\n",
    "                llm_answer = input(\"(y/n): \").lower()\n",
    "                llm_answer = llm_answer.startswith('y')\n",
    "                if(llm_answer):\n",
    "                    answer = assistant.generate_llm_answer(query)\n",
    "                \n",
    "                # Display the final answer nicely formatted\n",
    "                console.print(Panel(\n",
    "                    Markdown(answer),\n",
    "                    title=\"Answer\",\n",
    "                    border_style=\"green\",\n",
    "                    width=100\n",
    "                ))\n",
    "            # elif choice ==\"6\":\n",
    "                \n",
    "                \n",
    "            elif choice == \"2\":\n",
    "                history = assistant.get_chat_history()\n",
    "                console.print(Panel(\n",
    "                    history if history else \"No conversation history.\",\n",
    "                    title=\"Conversation History\",\n",
    "                    border_style=\"blue\"\n",
    "                ))\n",
    "                \n",
    "            elif choice == \"3\":\n",
    "                assistant.clear_memory()\n",
    "\n",
    "            elif choice == \"4\":\n",
    "                query = input(f\"\\n[bold]Enter your query:[/bold] \")\n",
    "                if not query.strip():\n",
    "                    console.print(f\"[yellow]Empty query. Please try again.[/yellow]\")\n",
    "                    continue\n",
    "                \n",
    "                # Initialize the adv research assistant\n",
    "                vector_db_temp = Chroma(persist_directory= \"./tempDB\", embedding_function=embeddings)\n",
    "                advAssistant = ResearchAssistant(llm=llm, vector_db=vector_db_temp)\n",
    "                # Process the query\n",
    "                console.print(f\"\\n[bold cyan]Processing your query...[/bold cyan]\")\n",
    "                # Step 1: Rate the query\n",
    "                console.print(\"\\n[bold cyan]Evaluating your query (with memory context)...[/bold cyan]\")\n",
    "                rating_result = advAssistant.rate_query(query)\n",
    "                \n",
    "                rating_color = \"green\" if rating_result['rating'] >= 4 else \"yellow\" if rating_result['rating'] >= 3 else \"red\"\n",
    "                console.print(f\"[bold {rating_color}]Query Rating: {rating_result['rating']}/5[/bold {rating_color}]\")\n",
    "                console.print(f\"Explanation: {rating_result['explanation']}\")\n",
    "                console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                \n",
    "                # Step 2: Suggest rewrites if the rating is less than perfect\n",
    "                rewritten_queries = []\n",
    "                if rating_result[\"rating\"] < 5:\n",
    "                    console.print(\"[bold cyan]Generating improved query variations...[/bold cyan]\")\n",
    "                    rewritten_queries = advAssistant.suggest_rewrites(query)\n",
    "                    console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                \n",
    "                # Step 3: Present options to the user\n",
    "                query_options = advAssistant.present_query_options(query, rewritten_queries)\n",
    "                console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                \n",
    "                # Step 4: Get user selection\n",
    "                console.print(\"[bold cyan]Select queries to use:[/bold cyan]\")\n",
    "                console.print(\"Enter the query you want to use (comma-separated, e.g., '0,2,3')\")\n",
    "                selected_index = input(\"> \")\n",
    "                try:\n",
    "                    idx = int(selected_index)\n",
    "                    if idx == 0:  # Original query\n",
    "                        selected_query = query\n",
    "                    elif 0 < idx <= len(rewritten_queries):  # Rewritten query\n",
    "                        selected_query = rewritten_queries[idx-1]\n",
    "                    else:\n",
    "                        console.print(\"[yellow]Invalid selection. Using original query.[/yellow]\")\n",
    "                        selected_query = query\n",
    "                except ValueError:\n",
    "                    console.print(\"[yellow]Invalid input. Using original query.[/yellow]\")\n",
    "                    selected_query = query\n",
    "                \n",
    "                # Step 5: Load papers based on selected query\n",
    "                paper_ids = advAssistant.Load_query(selected_query)\n",
    "                \n",
    "                if paper_ids:\n",
    "                    # Step 6: Interactive research loop\n",
    "                    console.print(advAssistant.vector_db)\n",
    "                    while True:\n",
    "                        research_question = input(\"\\n[bold]Ask a question about these papers (or type 'exit' to return):[/bold] \")\n",
    "                        if research_question.lower() in ['exit', 'quit', 'back']:\n",
    "                            break\n",
    "                        if not research_question.strip():\n",
    "                            console.print(f\"[yellow]Empty query. Please try again.[/yellow]\")\n",
    "                            continue\n",
    "                            \n",
    "                        # Ask the user whether to use memory mode or full pipeline\n",
    "                        use_memory_input = input(\"Use conversation memory? (y/n): \").lower()\n",
    "                        use_memory = use_memory_input.startswith('y')\n",
    "                        \n",
    "                        # Process the query\n",
    "                        console.print(f\"\\n[bold cyan]Processing your query...[/bold cyan]\")\n",
    "                        answer = advAssistant.process_query(research_question, use_memory=use_memory)\n",
    "                        \n",
    "                        # Display the final answer nicely formatted\n",
    "                        console.print(Panel(\n",
    "                            Markdown(answer),\n",
    "                            title=\"Answer\",\n",
    "                            border_style=\"green\",\n",
    "                            width=100\n",
    "                        ))\n",
    "                else:\n",
    "                    console.print(\"[yellow]No papers were loaded. Please try a different query.[/yellow]\")\n",
    "                            \n",
    "                print(advAssistant.vector_db._collection.count())\n",
    "            elif choice == \"5\":\n",
    "                console.print(\"[bold green]Thank you for using SageRAG Research Assistant. Goodbye![/bold green]\")\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                console.print(\"[yellow]Invalid choice. Please enter a number from 1-4.[/yellow]\")\n",
    "                \n",
    "    except ImportError as e:\n",
    "        console.print(f\"[bold red]Error: Missing required packages: {e}[/bold red]\")\n",
    "        console.print(\"Please install the required packages with pip:\")\n",
    "        console.print(\"pip install langchain langchain_community sentence-transformers rich openai chromadb\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]An unexpected error occurred: {e}[/bold red]\")\n",
    "        import traceback\n",
    "        console.print(traceback.format_exc())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891c5b9-5059-4502-90a4-b09026f31836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
